{"id_list": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44], "nodes": [{"frequency": 2, "group": 0, "nodeName": "CiteSeer", "id": 0}, {"frequency": 4, "group": 0, "nodeName": "DBLP", "id": 1}, {"frequency": 1, "group": 0, "nodeName": "Johnson_County,_Kansas", "id": 2}, {"frequency": 1, "group": 0, "nodeName": "Hui_Li", "id": 3}, {"frequency": 1, "group": 0, "nodeName": "Metasearch_engine", "id": 4}, {"frequency": 1, "group": 0, "nodeName": "Multimedia", "id": 5}, {"frequency": 10, "group": 0, "nodeName": "Dirichlet_distribution", "id": 6}, {"frequency": 26, "group": 0, "nodeName": "Latent_Dirichlet_allocation", "id": 7}, {"frequency": 1, "group": 0, "nodeName": "Dual_polyhedron", "id": 8}, {"frequency": 4, "group": 0, "nodeName": "Iraq_War", "id": 9}, {"frequency": 11, "group": 0, "nodeName": "George_W._Bush", "id": 10}, {"frequency": 6, "group": 0, "nodeName": "Dick_Cheney", "id": 11}, {"frequency": 3, "group": 0, "nodeName": "Colin_Powell", "id": 12}, {"frequency": 5, "group": 0, "nodeName": "Gulf_War", "id": 13}, {"frequency": 1, "group": 0, "nodeName": "Report_to_Congress_on_the_Situation_in_Iraq", "id": 14}, {"frequency": 17, "group": 0, "nodeName": "Gibbs_sampling", "id": 15}, {"frequency": 2, "group": 0, "nodeName": "Monte_Carlo_method", "id": 16}, {"frequency": 1, "group": 0, "nodeName": "Digital-to-analog_converter", "id": 17}, {"frequency": 1, "group": 0, "nodeName": "Proposition", "id": 18}, {"frequency": 2, "group": 0, "nodeName": "North_Dakota", "id": 19}, {"frequency": 1, "group": 0, "nodeName": "Trans_World_Airlines", "id": 20}, {"frequency": 1, "group": 0, "nodeName": "Metropolis\u2013Hastings_algorithm", "id": 21}, {"frequency": 1, "group": 0, "nodeName": "Holotype", "id": 22}, {"frequency": 1, "group": 0, "nodeName": "Artificial_intelligence", "id": 23}, {"frequency": 1, "group": 0, "nodeName": "Weka_(machine_learning)", "id": 24}, {"frequency": 1, "group": 0, "nodeName": "Support_vector_machine", "id": 25}, {"frequency": 1, "group": 0, "nodeName": "Probabilistic_latent_semantic_analysis", "id": 26}, {"frequency": 4, "group": 1, "nodeName": "Central_processing_unit", "id": 27}, {"frequency": 1, "group": 1, "nodeName": "Bayesian_inference", "id": 28}, {"frequency": 1, "group": 1, "nodeName": "Web_navigation", "id": 29}, {"frequency": 1, "group": 1, "nodeName": "New_Jersey", "id": 30}, {"frequency": 1, "group": 1, "nodeName": "Algorithm", "id": 31}, {"frequency": 1, "group": 1, "nodeName": "Z-machine", "id": 32}, {"frequency": 1, "group": 1, "nodeName": "ZK_(framework)", "id": 33}, {"frequency": 8, "group": 1, "nodeName": "The_New_York_Times", "id": 34}, {"frequency": 12, "group": 1, "nodeName": "PubMed", "id": 35}, {"frequency": 1, "group": 1, "nodeName": "Foreach_loop", "id": 36}, {"frequency": 1, "group": 1, "nodeName": "Machine_learning", "id": 37}, {"frequency": 1, "group": 1, "nodeName": "University_of_California,_Irvine", "id": 38}, {"frequency": 4, "group": 1, "nodeName": "Enron", "id": 39}, {"frequency": 2, "group": 1, "nodeName": "Linear_discriminant_analysis", "id": 40}, {"frequency": 1, "group": 1, "nodeName": "United_Kingdom", "id": 41}, {"frequency": 1, "group": 1, "nodeName": "Time_(magazine)", "id": 42}, {"frequency": 1, "group": 1, "nodeName": "Hierarchical_Dirichlet_process", "id": 43}, {"frequency": 1, "group": 1, "nodeName": "Pachinko_allocation", "id": 44}], "links": [{"pure_titles": ["A Latent Topic Model for Complete Entity Resolution"], "target": 35, "weight": 1, "value": 1, "source": 41, "sentences": [{"title": "A Latent Topic Model for Complete Entity Resolution", "sentence": "Running LDA or FastLDA on PubMed with K = 2000 and K = 4000 topics requires on the order of 100- 200 GB of memory, well beyond the limit of typical workstations."}]}, {"pure_titles": ["A Latent Topic Model for Complete Entity Resolution", "A Latent Topic Model for Complete Entity Resolution", "A Latent Topic Model for Complete Entity Resolution", "A Latent Topic Model for Complete Entity Resolution", "A Latent Topic Model for Complete Entity Resolution"], "target": 7, "weight": 5, "value": 5, "source": 6, "sentences": [{"title": "A Latent Topic Model for Complete Entity Resolution", "sentence": "While it is only a Dirichlet distribution over words in the LDA, a topic is represented by two Dirichlet distributions in the LDA-dual, one over words and the other over author names."}, {"title": "A Latent Topic Model for Complete Entity Resolution", "sentence": "To apply to documents containing author names as well as words, we extend LDA in our model by adding the third assumption  every topic is a Dirichlet distribution over all author names."}, {"title": "A Latent Topic Model for Complete Entity Resolution", "sentence": "Dirichlet distribution In the LDA model <8> and the LDA-dual model, we obtain a mixture of topics, denoted by , by drawing a sample from a Dirichlet distribution p(|) = ("}, {"title": "A Latent Topic Model for Complete Entity Resolution", "sentence": "Proposition 1: Suppose D is a corpus of D documents, Z is a total topic assignment of D, and  is a Dirichlet prior vector in the LDA-dual model."}, {"title": "A Latent Topic Model for Complete Entity Resolution", "sentence": "The LDA model is equivalent to the following generative process for words and documents: For each of Nj words in document j 1. sample a topic zij  Multinomial(j) 2. sample a word xij  Multinomial(zij ) where the parameters of the multinomials for topics in a document j and words in a topic k have Dirichlet priors."}]}, {"pure_titles": ["A Latent Topic Model for Complete Entity Resolution"], "target": 7, "weight": 1, "value": 1, "source": 29, "sentences": [{"title": "A Latent Topic Model for Complete Entity Resolution", "sentence": "LDA models have also been increasingly applied to problems involving very large text corpora: Buntine <4>, Mimno and McCallum <12> and Newman et al <15> have all used the LDA model to automatically generate topic models for millions of documents and used these models as the basis for automated indexing and faceted Web browsing."}]}, {"pure_titles": ["A Latent Topic Model for Complete Entity Resolution"], "target": 20, "weight": 1, "value": 1, "source": 19, "sentences": [{"title": "A Latent Topic Model for Complete Entity Resolution", "sentence": "In Formulas (4), (5) and (6), D, T , W, A, Nd and Md are constants."}]}, {"pure_titles": ["A Latent Topic Model for Complete Entity Resolution"], "target": 7, "weight": 1, "value": 1, "source": 38, "sentences": [{"title": "A Latent Topic Model for Complete Entity Resolution", "sentence": "With the goal of repeatability, we have made our LDA and FastLDA code publicly available at http:// www.ics.uci.edu/ iporteou/ fastlda and the four data sets at the UCI Machine Learning Repository, http:// archive.ics.uci.edu/ml/ machine-learningdatabases/ bag-of-words/."}]}, {"pure_titles": ["A Latent Topic Model for Complete Entity Resolution"], "target": 10, "weight": 1, "value": 1, "source": 22, "sentences": [{"title": "A Latent Topic Model for Complete Entity Resolution", "sentence": "For example, George Bush(2) means topic 2 is assigned to the author name George Bush."}]}, {"pure_titles": ["A Latent Topic Model for Complete Entity Resolution"], "target": 15, "weight": 1, "value": 1, "source": 40, "sentences": [{"title": "A Latent Topic Model for Complete Entity Resolution", "sentence": "In this paper, we have described a method for increasing the speed of LDA Gibbs sampling while providing exactly equivalent samples, thus retaining all the optimality guarantees associated with the original LDA algorithm."}]}, {"pure_titles": ["A Latent Topic Model for Complete Entity Resolution", "A Latent Topic Model for Complete Entity Resolution"], "target": 16, "weight": 2, "value": 2, "source": 15, "sentences": [{"title": "A Latent Topic Model for Complete Entity Resolution", "sentence": "In this paper, we use Gibbs sampling <13><18><21><20>, a Monte Carlo simulation algorithm, to estimate parameters of the LDA-dual model."}, {"title": "A Latent Topic Model for Complete Entity Resolution", "sentence": "Based on the LDA model, <12> employed Gibbs Sampling, a Monte Carlo method <16><19><20><18>, to discover topics in a corpus."}]}, {"pure_titles": ["A Latent Topic Model for Complete Entity Resolution"], "target": 35, "weight": 1, "value": 1, "source": 40, "sentences": [{"title": "A Latent Topic Model for Complete Entity Resolution", "sentence": "The K = 2000 and K = 4000 topic models of PubMed were computed on a supercomputer using 256 processors using the parallel AD-LDA algorithm <14>."}]}, {"pure_titles": ["A Latent Topic Model for Complete Entity Resolution"], "target": 33, "weight": 1, "value": 1, "source": 32, "sentences": [{"title": "A Latent Topic Model for Complete Entity Resolution", "sentence": ".ZK, such that Z1  Z2  ."}]}, {"pure_titles": ["A Latent Topic Model for Complete Entity Resolution"], "target": 11, "weight": 1, "value": 1, "source": 14, "sentences": [{"title": "A Latent Topic Model for Complete Entity Resolution", "sentence": "Document #2 includes one citation under George W. Bush: 2.1 George W. Bush, and D. Cheney: The Iraq report."}]}, {"pure_titles": ["A Latent Topic Model for Complete Entity Resolution"], "target": 19, "weight": 1, "value": 1, "source": 6, "sentences": [{"title": "A Latent Topic Model for Complete Entity Resolution", "sentence": "where t is the tth component of vector , T is the number of topics, Nd is the number of words in document d, Md is the number of author names in document d, ndt is the number of times topic t is assigned to words in document d according to topic assignment Z, and mdt is the number of times topic t is assigned to author names in document d according to Z. Proposition 2: Suppose D is a corpus, D(w) is the collection of words in D, Z(w) is a partial topic assignment of D for words, and  is a Dirichlet prior vector in the LDA-dual model."}]}, {"pure_titles": ["A Latent Topic Model for Complete Entity Resolution", "A Latent Topic Model for Complete Entity Resolution"], "target": 1, "weight": 2, "value": 2, "source": 0, "sentences": [{"title": "A Latent Topic Model for Complete Entity Resolution", "sentence": "In bibliographies like DBLP and Citeseer, there are three kinds of entity-name problems that need to be solved."}, {"title": "A Latent Topic Model for Complete Entity Resolution", "sentence": "Bibliography websites like DBLP <1> and Citeseer provide much convenience for scientists and researchers to search or browse the citations of papers."}]}, {"pure_titles": ["A Latent Topic Model for Complete Entity Resolution"], "target": 1, "weight": 1, "value": 1, "source": 3, "sentences": [{"title": "A Latent Topic Model for Complete Entity Resolution", "sentence": "But citations under Guohui Li and those under Guo-Hui Li appear in separate web pages in DBLP."}]}, {"pure_titles": ["A Latent Topic Model for Complete Entity Resolution", "A Latent Topic Model for Complete Entity Resolution", "A Latent Topic Model for Complete Entity Resolution", "A Latent Topic Model for Complete Entity Resolution"], "target": 7, "weight": 4, "value": 4, "source": 35, "sentences": [{"title": "A Latent Topic Model for Complete Entity Resolution", "sentence": "We compared execution times of LDA and FastLDA using four data sets: NIPS full papers (from books.nips.cc), Enron emails (from www.cs.cmu.edu/enron), NYTimes news articles (from ldc.upenn.edu), and PubMed abstracts (from www.pubmed.gov)."}, {"title": "A Latent Topic Model for Complete Entity Resolution", "sentence": "Running LDA on the NYTimes data set using K = 1600 topics can take more than a week on a typical high-end desktop computer, and running LDA on the PubMed data set using K = 4000 topics would take months, and would require memory well beyond typical desktop computers."}, {"title": "A Latent Topic Model for Complete Entity Resolution", "sentence": "Running LDA or FastLDA on PubMed with K = 2000 and K = 4000 topics requires on the order of 100- 200 GB of memory, well beyond the limit of typical workstations."}, {"title": "A Latent Topic Model for Complete Entity Resolution", "sentence": "Therefore, we estimated speedup on PubMed using a 250,000 document subset of the entire collection, but running LDA and FastLDA initialized with the parameters from the aforementioned burned-in model that was computed using the entire PubMed corpus of 8.2 million documents."}]}, {"pure_titles": ["A Latent Topic Model for Complete Entity Resolution", "A Latent Topic Model for Complete Entity Resolution", "A Latent Topic Model for Complete Entity Resolution", "A Latent Topic Model for Complete Entity Resolution"], "target": 15, "weight": 4, "value": 4, "source": 6, "sentences": [{"title": "A Latent Topic Model for Complete Entity Resolution", "sentence": "The method of Metropolis-Hasting within Gibbs <17> is employed to sample Dirichlet prior vectors."}, {"title": "A Latent Topic Model for Complete Entity Resolution", "sentence": "In the example in Section II-C, after learning the model by Gibbs sampling, model parameters could be as follows."}, {"title": "A Latent Topic Model for Complete Entity Resolution", "sentence": "We then proposed an improved process to learn the model from a corpus by Gibbs sampling, including Dirichlet priors in the sampling."}, {"title": "A Latent Topic Model for Complete Entity Resolution", "sentence": "Fast Collapsed Gibbs Sampling For Latent Dirichlet Allocation"}]}, {"pure_titles": ["A Latent Topic Model for Complete Entity Resolution"], "target": 23, "weight": 1, "value": 1, "source": 10, "sentences": [{"title": "A Latent Topic Model for Complete Entity Resolution", "sentence": "By Formula (13), we obtain the matrix , the topics distributions over author names in A (i is for topic i): George Bush George W. Bush D. Cheney C. Powell"}]}, {"pure_titles": ["A Latent Topic Model for Complete Entity Resolution"], "target": 1, "weight": 1, "value": 1, "source": 2, "sentences": [{"title": "A Latent Topic Model for Complete Entity Resolution", "sentence": "In Figure 1 (left), all 23 citations with the full name Michael Johnson are listed in a single web page at the DBLP website."}]}, {"pure_titles": ["A Latent Topic Model for Complete Entity Resolution", "A Latent Topic Model for Complete Entity Resolution"], "target": 39, "weight": 2, "value": 2, "source": 7, "sentences": [{"title": "A Latent Topic Model for Complete Entity Resolution", "sentence": "For the NIPS and Enron data sets, we timed the execution of LDA and FastLDA for 500 iterations of the Gibbs sampler, i.e., 500 sweeps through the entire corpus."}, {"title": "A Latent Topic Model for Complete Entity Resolution", "sentence": "The CPU time for FastLDA is significantly less than the CPU time for LDA for both the NIPS and Enron data sets."}]}, {"pure_titles": ["A Latent Topic Model for Complete Entity Resolution"], "target": 39, "weight": 1, "value": 1, "source": 15, "sentences": [{"title": "A Latent Topic Model for Complete Entity Resolution", "sentence": "For the NIPS and Enron data sets, we timed the execution of LDA and FastLDA for 500 iterations of the Gibbs sampler, i.e., 500 sweeps through the entire corpus."}]}, {"pure_titles": ["A Latent Topic Model for Complete Entity Resolution", "A Latent Topic Model for Complete Entity Resolution", "A Latent Topic Model for Complete Entity Resolution", "A Latent Topic Model for Complete Entity Resolution", "A Latent Topic Model for Complete Entity Resolution", "A Latent Topic Model for Complete Entity Resolution", "A Latent Topic Model for Complete Entity Resolution"], "target": 15, "weight": 7, "value": 7, "source": 7, "sentences": [{"title": "A Latent Topic Model for Complete Entity Resolution", "sentence": "<7><12> used Gibbs Sampling for the LDA model."}, {"title": "A Latent Topic Model for Complete Entity Resolution", "sentence": "In this paper we introduce a novel collapsed Gibbs sampling method for the widely used latent Dirichlet allocation (LDA) model."}, {"title": "A Latent Topic Model for Complete Entity Resolution", "sentence": "Conventional Gibbs sampling schemes for LDA require O(K) operations per sample where K is the number of topics in the model."}, {"title": "A Latent Topic Model for Complete Entity Resolution", "sentence": "Since the original introduction of the LDA model, the technique has been broadly applied in machine learning and data mining, particularly in text analysis and computer vision, with the Gibbs sampling algorithm in common use."}, {"title": "A Latent Topic Model for Complete Entity Resolution", "sentence": "We describe the details of this bound along with our algorithm in Section 4, after first reviewing the standard LDA model and Gibbs sampling."}, {"title": "A Latent Topic Model for Complete Entity Resolution", "sentence": "Among these, Latent Dirichlet Allocation and Gibbs sampling are perhaps the most widely used model and inference algorithm."}, {"title": "A Latent Topic Model for Complete Entity Resolution", "sentence": "In this paper, we have described a method for increasing the speed of LDA Gibbs sampling while providing exactly equivalent samples, thus retaining all the optimality guarantees associated with the original LDA algorithm."}]}, {"pure_titles": ["A Latent Topic Model for Complete Entity Resolution"], "target": 18, "weight": 1, "value": 1, "source": 6, "sentences": [{"title": "A Latent Topic Model for Complete Entity Resolution", "sentence": "where t is the tth component of vector , T is the number of topics, Nd is the number of words in document d, Md is the number of author names in document d, ndt is the number of times topic t is assigned to words in document d according to topic assignment Z, and mdt is the number of times topic t is assigned to author names in document d according to Z. Proposition 2: Suppose D is a corpus, D(w) is the collection of words in D, Z(w) is a partial topic assignment of D for words, and  is a Dirichlet prior vector in the LDA-dual model."}]}, {"pure_titles": ["A Latent Topic Model for Complete Entity Resolution"], "target": 16, "weight": 1, "value": 1, "source": 7, "sentences": [{"title": "A Latent Topic Model for Complete Entity Resolution", "sentence": "In this paper, we use Gibbs sampling <13><18><21><20>, a Monte Carlo simulation algorithm, to estimate parameters of the LDA-dual model."}]}, {"pure_titles": ["A Latent Topic Model for Complete Entity Resolution"], "target": 15, "weight": 1, "value": 1, "source": 17, "sentences": [{"title": "A Latent Topic Model for Complete Entity Resolution", "sentence": "And then we obtain the posterior distribution for Gibbs Sampling, the joint probability of Z, ,  and  given a corpus: p(Z, , , |D) = p() p() p() p(Z|) p(D(w)|Z(w), ) p(D(a)|Z(a), )/ p(D)."}]}, {"pure_titles": ["A Latent Topic Model for Complete Entity Resolution", "A Latent Topic Model for Complete Entity Resolution"], "target": 7, "weight": 2, "value": 2, "source": 15, "sentences": [{"title": "A Latent Topic Model for Complete Entity Resolution", "sentence": "In this paper, we use Gibbs sampling <13><18><21><20>, a Monte Carlo simulation algorithm, to estimate parameters of the LDA-dual model."}, {"title": "A Latent Topic Model for Complete Entity Resolution", "sentence": "For the NIPS and Enron data sets, we timed the execution of LDA and FastLDA for 500 iterations of the Gibbs sampler, i.e., 500 sweeps through the entire corpus."}]}, {"pure_titles": ["A Latent Topic Model for Complete Entity Resolution"], "target": 44, "weight": 1, "value": 1, "source": 43, "sentences": [{"title": "A Latent Topic Model for Complete Entity Resolution", "sentence": "In particular we expect the method to work well for other varieties of topic model, such as the Hierarchical Dirichlet Process <18> and Pachinko allocation <11>, which have a sampling step similar to LDA."}]}, {"pure_titles": ["A Latent Topic Model for Complete Entity Resolution"], "target": 30, "weight": 1, "value": 1, "source": 6, "sentences": [{"title": "A Latent Topic Model for Complete Entity Resolution", "sentence": "The LDA model is equivalent to the following generative process for words and documents: For each of Nj words in document j 1. sample a topic zij  Multinomial(j) 2. sample a word xij  Multinomial(zij ) where the parameters of the multinomials for topics in a document j and words in a topic k have Dirichlet priors."}]}, {"pure_titles": ["A Latent Topic Model for Complete Entity Resolution", "A Latent Topic Model for Complete Entity Resolution"], "target": 7, "weight": 2, "value": 2, "source": 34, "sentences": [{"title": "A Latent Topic Model for Complete Entity Resolution", "sentence": "We compared execution times of LDA and FastLDA using four data sets: NIPS full papers (from books.nips.cc), Enron emails (from www.cs.cmu.edu/enron), NYTimes news articles (from ldc.upenn.edu), and PubMed abstracts (from www.pubmed.gov)."}, {"title": "A Latent Topic Model for Complete Entity Resolution", "sentence": "Running LDA on the NYTimes data set using K = 1600 topics can take more than a week on a typical high-end desktop computer, and running LDA on the PubMed data set using K = 4000 topics would take months, and would require memory well beyond typical desktop computers."}]}, {"pure_titles": ["A Latent Topic Model for Complete Entity Resolution"], "target": 5, "weight": 1, "value": 1, "source": 4, "sentences": [{"title": "A Latent Topic Model for Complete Entity Resolution", "sentence": "Multimedia Metasearch Engines."}]}, {"pure_titles": ["A Latent Topic Model for Complete Entity Resolution"], "target": 27, "weight": 1, "value": 1, "source": 35, "sentences": [{"title": "A Latent Topic Model for Complete Entity Resolution", "sentence": "While the measured CPU times were for a subset of PubMed, the speedup results we show hold for FastLDA running on the entire collection, since the topics used were those learned for the entire 8.2 million documents."}]}, {"pure_titles": ["A Latent Topic Model for Complete Entity Resolution", "A Latent Topic Model for Complete Entity Resolution", "A Latent Topic Model for Complete Entity Resolution", "A Latent Topic Model for Complete Entity Resolution", "A Latent Topic Model for Complete Entity Resolution", "A Latent Topic Model for Complete Entity Resolution", "A Latent Topic Model for Complete Entity Resolution", "A Latent Topic Model for Complete Entity Resolution"], "target": 35, "weight": 8, "value": 8, "source": 34, "sentences": [{"title": "A Latent Topic Model for Complete Entity Resolution", "sentence": "We compared execution times of LDA and FastLDA using four data sets: NIPS full papers (from books.nips.cc), Enron emails (from www.cs.cmu.edu/enron), NYTimes news articles (from ldc.upenn.edu), and PubMed abstracts (from www.pubmed.gov)."}, {"title": "A Latent Topic Model for Complete Entity Resolution", "sentence": "The NYTimes and PubMed collections are relatively large, and therefore useful for demonstrating the potential benefits of FastLDA."}, {"title": "A Latent Topic Model for Complete Entity Resolution", "sentence": "While the NIPS and Enron data sets are moderately sized, and thus useful for conducting parameter studies, the NYTimes and PubMed data sets are relatively large."}, {"title": "A Latent Topic Model for Complete Entity Resolution", "sentence": "Running LDA on the NYTimes data set using K = 1600 topics can take more than a week on a typical high-end desktop computer, and running LDA on the PubMed data set using K = 4000 topics would take months, and would require memory well beyond typical desktop computers."}, {"title": "A Latent Topic Model for Complete Entity Resolution", "sentence": "For the NYTimes and PubMed data sets, we used a slightly different method to measure speedup, because of the considerably larger size of these data sets compared to NIPS and Enron."}, {"title": "A Latent Topic Model for Complete Entity Resolution", "sentence": "FastLDA was initialized with parameters from an already burned-in model for NYTimes and PubMed."}, {"title": "A Latent Topic Model for Complete Entity Resolution", "sentence": "The number of topics are: NIPS K = 400, 800, Enron K = 400, 800, NYTimes K = 800, 1600 and PubMed K = 2000, 4000, with the speedup for the larger number of topics shown in the black bar on the right of each pair."}, {"title": "A Latent Topic Model for Complete Entity Resolution", "sentence": "On the two huge data sets, NYTimes and PubMed, FastLDA shows a consistent 5.7 to 7.5 speedup."}]}, {"pure_titles": ["A Latent Topic Model for Complete Entity Resolution"], "target": 36, "weight": 1, "value": 1, "source": 34, "sentences": [{"title": "A Latent Topic Model for Complete Entity Resolution", "sentence": "The NYTimes and PubMed collections are relatively large, and therefore useful for demonstrating the potential benefits of FastLDA."}]}, {"pure_titles": ["A Latent Topic Model for Complete Entity Resolution", "A Latent Topic Model for Complete Entity Resolution", "A Latent Topic Model for Complete Entity Resolution"], "target": 7, "weight": 3, "value": 3, "source": 27, "sentences": [{"title": "A Latent Topic Model for Complete Entity Resolution", "sentence": "For the PubMed collection of over 8 million documents with a required computation time of 6 CPU months for LDA, our speedup of 5.7 can save 5 CPU months of computation."}, {"title": "A Latent Topic Model for Complete Entity Resolution", "sentence": "The CPU time for FastLDA is significantly less than the CPU time for LDA for both the NIPS and Enron data sets."}, {"title": "A Latent Topic Model for Complete Entity Resolution", "sentence": "Figure 6 shows the same results, this time displayed as speedup, i.e. the y-axis is the CPU Time for LDA divided by the CPU Time for FastLDA."}]}, {"pure_titles": ["A Latent Topic Model for Complete Entity Resolution"], "target": 14, "weight": 1, "value": 1, "source": 10, "sentences": [{"title": "A Latent Topic Model for Complete Entity Resolution", "sentence": "Document #2 includes one citation under George W. Bush: 2.1 George W. Bush, and D. Cheney: The Iraq report."}]}, {"pure_titles": ["A Latent Topic Model for Complete Entity Resolution"], "target": 42, "weight": 1, "value": 1, "source": 27, "sentences": [{"title": "A Latent Topic Model for Complete Entity Resolution", "sentence": "Figure 6 shows the same results, this time displayed as speedup, i.e. the y-axis is the CPU Time for LDA divided by the CPU Time for FastLDA."}]}, {"pure_titles": ["A Latent Topic Model for Complete Entity Resolution"], "target": 7, "weight": 1, "value": 1, "source": 37, "sentences": [{"title": "A Latent Topic Model for Complete Entity Resolution", "sentence": "With the goal of repeatability, we have made our LDA and FastLDA code publicly available at http:// www.ics.uci.edu/ iporteou/ fastlda and the four data sets at the UCI Machine Learning Repository, http:// archive.ics.uci.edu/ml/ machine-learningdatabases/ bag-of-words/."}]}, {"pure_titles": ["A Latent Topic Model for Complete Entity Resolution", "A Latent Topic Model for Complete Entity Resolution", "A Latent Topic Model for Complete Entity Resolution", "A Latent Topic Model for Complete Entity Resolution", "A Latent Topic Model for Complete Entity Resolution", "A Latent Topic Model for Complete Entity Resolution"], "target": 11, "weight": 6, "value": 6, "source": 10, "sentences": [{"title": "A Latent Topic Model for Complete Entity Resolution", "sentence": "Document #1 includes three citations under George Bush: 1.1 George Bush, and D. Cheney: The Iraq war."}, {"title": "A Latent Topic Model for Complete Entity Resolution", "sentence": "Document #2 includes one citation under George W. Bush: 2.1 George W. Bush, and D. Cheney: The Iraq report."}, {"title": "A Latent Topic Model for Complete Entity Resolution", "sentence": "The author name list A = <George Bush, George W. Bush, D. Cheney, C. Powell> with size A = 4."}, {"title": "A Latent Topic Model for Complete Entity Resolution", "sentence": "Topic assignment for Document #1: 1.1 George Bush(2), D. Cheney(1): Iraq(1) war(2)."}, {"title": "A Latent Topic Model for Complete Entity Resolution", "sentence": "Topic assignment for Document #2: 2.1 George W. Bush(1), D. Cheney(1): Iraq(1) report(1)."}, {"title": "A Latent Topic Model for Complete Entity Resolution", "sentence": "By Formula (13), we obtain the matrix , the topics distributions over author names in A (i is for topic i): George Bush George W. Bush D. Cheney C. Powell"}]}, {"pure_titles": ["A Latent Topic Model for Complete Entity Resolution"], "target": 7, "weight": 1, "value": 1, "source": 26, "sentences": [{"title": "A Latent Topic Model for Complete Entity Resolution", "sentence": "<8> pointed out a limitation of the pLSI model  providing no probabilistic model at the level of document, and then proposed Latent Dirichlet Allocation (LDA), a generative probabilistic model, with the latent variable topic introduced."}]}, {"pure_titles": ["A Latent Topic Model for Complete Entity Resolution", "A Latent Topic Model for Complete Entity Resolution", "A Latent Topic Model for Complete Entity Resolution", "A Latent Topic Model for Complete Entity Resolution"], "target": 13, "weight": 4, "value": 4, "source": 10, "sentences": [{"title": "A Latent Topic Model for Complete Entity Resolution", "sentence": "1.2 George Bush, and C. Powell: The Gulf war."}, {"title": "A Latent Topic Model for Complete Entity Resolution", "sentence": "1.3 George Bush: The Gulf report."}, {"title": "A Latent Topic Model for Complete Entity Resolution", "sentence": "1.2 George Bush(2), C. Powell(2): Gulf(2) war(1)."}, {"title": "A Latent Topic Model for Complete Entity Resolution", "sentence": "1.3 George Bush(1): Gulf(2) report(2)."}]}, {"pure_titles": ["A Latent Topic Model for Complete Entity Resolution"], "target": 30, "weight": 1, "value": 1, "source": 7, "sentences": [{"title": "A Latent Topic Model for Complete Entity Resolution", "sentence": "The LDA model is equivalent to the following generative process for words and documents: For each of Nj words in document j 1. sample a topic zij  Multinomial(j) 2. sample a word xij  Multinomial(zij ) where the parameters of the multinomials for topics in a document j and words in a topic k have Dirichlet priors."}]}, {"pure_titles": ["A Latent Topic Model for Complete Entity Resolution"], "target": 36, "weight": 1, "value": 1, "source": 35, "sentences": [{"title": "A Latent Topic Model for Complete Entity Resolution", "sentence": "The NYTimes and PubMed collections are relatively large, and therefore useful for demonstrating the potential benefits of FastLDA."}]}, {"pure_titles": ["A Latent Topic Model for Complete Entity Resolution"], "target": 11, "weight": 1, "value": 1, "source": 23, "sentences": [{"title": "A Latent Topic Model for Complete Entity Resolution", "sentence": "By Formula (13), we obtain the matrix , the topics distributions over author names in A (i is for topic i): George Bush George W. Bush D. Cheney C. Powell"}]}, {"pure_titles": ["A Latent Topic Model for Complete Entity Resolution"], "target": 38, "weight": 1, "value": 1, "source": 37, "sentences": [{"title": "A Latent Topic Model for Complete Entity Resolution", "sentence": "With the goal of repeatability, we have made our LDA and FastLDA code publicly available at http:// www.ics.uci.edu/ iporteou/ fastlda and the four data sets at the UCI Machine Learning Repository, http:// archive.ics.uci.edu/ml/ machine-learningdatabases/ bag-of-words/."}]}, {"pure_titles": ["A Latent Topic Model for Complete Entity Resolution", "A Latent Topic Model for Complete Entity Resolution"], "target": 39, "weight": 2, "value": 2, "source": 35, "sentences": [{"title": "A Latent Topic Model for Complete Entity Resolution", "sentence": "For the NYTimes and PubMed data sets, we used a slightly different method to measure speedup, because of the considerably larger size of these data sets compared to NIPS and Enron."}, {"title": "A Latent Topic Model for Complete Entity Resolution", "sentence": "The number of topics are: NIPS K = 400, 800, Enron K = 400, 800, NYTimes K = 800, 1600 and PubMed K = 2000, 4000, with the speedup for the larger number of topics shown in the black bar on the right of each pair."}]}, {"pure_titles": ["A Latent Topic Model for Complete Entity Resolution", "A Latent Topic Model for Complete Entity Resolution"], "target": 39, "weight": 2, "value": 2, "source": 34, "sentences": [{"title": "A Latent Topic Model for Complete Entity Resolution", "sentence": "For the NYTimes and PubMed data sets, we used a slightly different method to measure speedup, because of the considerably larger size of these data sets compared to NIPS and Enron."}, {"title": "A Latent Topic Model for Complete Entity Resolution", "sentence": "The number of topics are: NIPS K = 400, 800, Enron K = 400, 800, NYTimes K = 800, 1600 and PubMed K = 2000, 4000, with the speedup for the larger number of topics shown in the black bar on the right of each pair."}]}, {"pure_titles": ["A Latent Topic Model for Complete Entity Resolution"], "target": 7, "weight": 1, "value": 1, "source": 41, "sentences": [{"title": "A Latent Topic Model for Complete Entity Resolution", "sentence": "Running LDA or FastLDA on PubMed with K = 2000 and K = 4000 topics requires on the order of 100- 200 GB of memory, well beyond the limit of typical workstations."}]}, {"pure_titles": ["A Latent Topic Model for Complete Entity Resolution"], "target": 7, "weight": 1, "value": 1, "source": 40, "sentences": [{"title": "A Latent Topic Model for Complete Entity Resolution", "sentence": "In this paper, we have described a method for increasing the speed of LDA Gibbs sampling while providing exactly equivalent samples, thus retaining all the optimality guarantees associated with the original LDA algorithm."}]}, {"pure_titles": ["A Latent Topic Model for Complete Entity Resolution"], "target": 25, "weight": 1, "value": 1, "source": 24, "sentences": [{"title": "A Latent Topic Model for Complete Entity Resolution", "sentence": "We compare two classifiers  the decision tree algorithm C4.5 and support vector machines (SVMs) in the Weka machine learning package <28>."}]}, {"pure_titles": ["A Latent Topic Model for Complete Entity Resolution"], "target": 7, "weight": 1, "value": 1, "source": 8, "sentences": [{"title": "A Latent Topic Model for Complete Entity Resolution", "sentence": "THE LDA-DUAL MODEL"}]}, {"pure_titles": ["A Latent Topic Model for Complete Entity Resolution"], "target": 28, "weight": 1, "value": 1, "source": 7, "sentences": [{"title": "A Latent Topic Model for Complete Entity Resolution", "sentence": "Blei et al <3> introduced the LDA model within a general Bayesian framework and developed a variational algorithm for learning the model from data."}]}, {"pure_titles": ["A Latent Topic Model for Complete Entity Resolution"], "target": 21, "weight": 1, "value": 1, "source": 15, "sentences": [{"title": "A Latent Topic Model for Complete Entity Resolution", "sentence": "Therefore, we employ the method of Metropolis-Hastings within Gibbs <17>, <19>."}]}, {"pure_titles": ["A Latent Topic Model for Complete Entity Resolution"], "target": 13, "weight": 1, "value": 1, "source": 9, "sentences": [{"title": "A Latent Topic Model for Complete Entity Resolution", "sentence": "The vocabulary W = <Gulf, Iraq, report, war> with size W = 4."}]}, {"pure_titles": ["A Latent Topic Model for Complete Entity Resolution", "A Latent Topic Model for Complete Entity Resolution", "A Latent Topic Model for Complete Entity Resolution"], "target": 11, "weight": 3, "value": 3, "source": 9, "sentences": [{"title": "A Latent Topic Model for Complete Entity Resolution", "sentence": "Document #1 includes three citations under George Bush: 1.1 George Bush, and D. Cheney: The Iraq war."}, {"title": "A Latent Topic Model for Complete Entity Resolution", "sentence": "Topic assignment for Document #1: 1.1 George Bush(2), D. Cheney(1): Iraq(1) war(2)."}, {"title": "A Latent Topic Model for Complete Entity Resolution", "sentence": "Topic assignment for Document #2: 2.1 George W. Bush(1), D. Cheney(1): Iraq(1) report(1)."}]}, {"pure_titles": ["A Latent Topic Model for Complete Entity Resolution", "A Latent Topic Model for Complete Entity Resolution", "A Latent Topic Model for Complete Entity Resolution"], "target": 10, "weight": 3, "value": 3, "source": 9, "sentences": [{"title": "A Latent Topic Model for Complete Entity Resolution", "sentence": "Document #1 includes three citations under George Bush: 1.1 George Bush, and D. Cheney: The Iraq war."}, {"title": "A Latent Topic Model for Complete Entity Resolution", "sentence": "Topic assignment for Document #1: 1.1 George Bush(2), D. Cheney(1): Iraq(1) war(2)."}, {"title": "A Latent Topic Model for Complete Entity Resolution", "sentence": "Topic assignment for Document #2: 2.1 George W. Bush(1), D. Cheney(1): Iraq(1) report(1)."}]}, {"pure_titles": ["A Latent Topic Model for Complete Entity Resolution"], "target": 39, "weight": 1, "value": 1, "source": 27, "sentences": [{"title": "A Latent Topic Model for Complete Entity Resolution", "sentence": "The CPU time for FastLDA is significantly less than the CPU time for LDA for both the NIPS and Enron data sets."}]}, {"pure_titles": ["A Latent Topic Model for Complete Entity Resolution"], "target": 42, "weight": 1, "value": 1, "source": 7, "sentences": [{"title": "A Latent Topic Model for Complete Entity Resolution", "sentence": "Figure 6 shows the same results, this time displayed as speedup, i.e. the y-axis is the CPU Time for LDA divided by the CPU Time for FastLDA."}]}, {"pure_titles": ["A Latent Topic Model for Complete Entity Resolution", "A Latent Topic Model for Complete Entity Resolution"], "target": 13, "weight": 2, "value": 2, "source": 12, "sentences": [{"title": "A Latent Topic Model for Complete Entity Resolution", "sentence": "1.2 George Bush, and C. Powell: The Gulf war."}, {"title": "A Latent Topic Model for Complete Entity Resolution", "sentence": "1.2 George Bush(2), C. Powell(2): Gulf(2) war(1)."}]}, {"pure_titles": ["A Latent Topic Model for Complete Entity Resolution", "A Latent Topic Model for Complete Entity Resolution", "A Latent Topic Model for Complete Entity Resolution"], "target": 10, "weight": 3, "value": 3, "source": 12, "sentences": [{"title": "A Latent Topic Model for Complete Entity Resolution", "sentence": "1.2 George Bush, and C. Powell: The Gulf war."}, {"title": "A Latent Topic Model for Complete Entity Resolution", "sentence": "The author name list A = <George Bush, George W. Bush, D. Cheney, C. Powell> with size A = 4."}, {"title": "A Latent Topic Model for Complete Entity Resolution", "sentence": "1.2 George Bush(2), C. Powell(2): Gulf(2) war(1)."}]}, {"pure_titles": ["A Latent Topic Model for Complete Entity Resolution"], "target": 11, "weight": 1, "value": 1, "source": 12, "sentences": [{"title": "A Latent Topic Model for Complete Entity Resolution", "sentence": "The author name list A = <George Bush, George W. Bush, D. Cheney, C. Powell> with size A = 4."}]}, {"pure_titles": ["A Latent Topic Model for Complete Entity Resolution"], "target": 15, "weight": 1, "value": 1, "source": 31, "sentences": [{"title": "A Latent Topic Model for Complete Entity Resolution", "sentence": "Given the current state of all but one variable zij , the conditional probability and the superscript ij indicates that the corresponding datum has been excluded in the count summations Nwkj .An iteration of Gibbs sampling proceeds by drawing a sample for zij according to (1) for each word i in each document j. A sample is typically accomplished by first calculating the normalization constant Z, then sampling zij according to its normalized probability; see Algorithm 3.1."}]}, {"pure_titles": ["A Latent Topic Model for Complete Entity Resolution"], "target": 19, "weight": 1, "value": 1, "source": 18, "sentences": [{"title": "A Latent Topic Model for Complete Entity Resolution", "sentence": "where t is the tth component of vector , T is the number of topics, Nd is the number of words in document d, Md is the number of author names in document d, ndt is the number of times topic t is assigned to words in document d according to topic assignment Z, and mdt is the number of times topic t is assigned to author names in document d according to Z. Proposition 2: Suppose D is a corpus, D(w) is the collection of words in D, Z(w) is a partial topic assignment of D for words, and  is a Dirichlet prior vector in the LDA-dual model."}]}], "papers": [{"id": 0, "title": "A Latent Topic Model for Complete Entity Resolution"}, {"id": 1, "title": "A Latent Topic Model for Complete Entity Resolution"}]}