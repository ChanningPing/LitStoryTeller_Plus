{"id_list": [0, 1, 2, 3, 4], "nodes": [{"frequency": 2, "group": 0, "nodeName": "Expectation\u2013maximization_algorithm", "id": 0}, {"frequency": 9, "group": 0, "nodeName": "Expectation_propagation", "id": 1}, {"frequency": 5, "group": 0, "nodeName": "Text_Retrieval_Conference", "id": 2}, {"frequency": 1, "group": 0, "nodeName": "Monte_Carlo_method", "id": 3}, {"frequency": 1, "group": 0, "nodeName": "Holotype", "id": 4}], "links": [{"pure_titles": ["ExpectationPropagation for the Generative Aspect Model", "ExpectationPropagation for the Generative Aspect Model", "ExpectationPropagation for the Generative Aspect Model", "ExpectationPropagation for the Generative Aspect Model", "ExpectationPropagation for the Generative Aspect Model"], "target": 1, "weight": 5, "value": 5, "source": 2, "sentences": [{"title": "ExpectationPropagation for the Generative Aspect Model", "sentence": "In Sec- tions 6.2 and 6.3 the methods are then compared using doc- ument collections taken from TREC data, where it is seen that Expectation-Propagation attains lower test set perplex- ity."}, {"title": "ExpectationPropagation for the Generative Aspect Model", "sentence": "In order to compare variational inference and Expectation- Propagation on more realistic data, a corpus was created by mixing together TREC documents on known topics."}, {"title": "ExpectationPropagation for the Generative Aspect Model", "sentence": "To compare VB and EP on real data having a mixture of aspects, this section considers documents from the TREC interactive collection (Over, 2001)."}, {"title": "ExpectationPropagation for the Generative Aspect Model", "sentence": "As for the controlled TREC data, EP achieves a lower per- plexity, and has aspects that are more balanced compared to those obtained using VB."}, {"title": "ExpectationPropagation for the Generative Aspect Model", "sentence": "Exper- iments on TREC data show that Expectation-Propagation achieves lower test set perplexity."}]}, {"pure_titles": ["ExpectationPropagation for the Generative Aspect Model"], "target": 1, "weight": 1, "value": 1, "source": 4, "sentences": [{"title": "ExpectationPropagation for the Generative Aspect Model", "sentence": "Figure 3 shows the test set perplexities for VB and EP; the perplexity for the EP-trained model is consistently lower than the perplexity of the VB-trained model."}]}, {"pure_titles": ["ExpectationPropagation for the Generative Aspect Model"], "target": 3, "weight": 1, "value": 1, "source": 1, "sentences": [{"title": "ExpectationPropagation for the Generative Aspect Model", "sentence": "Laplaces method using a softmax transformation, vari- ational inference, and two different Monte Carlo algo- rithms."}]}, {"pure_titles": ["ExpectationPropagation for the Generative Aspect Model", "ExpectationPropagation for the Generative Aspect Model"], "target": 1, "weight": 2, "value": 2, "source": 0, "sentences": [{"title": "ExpectationPropagation for the Generative Aspect Model", "sentence": "An extension of Expectation- Propagation is used for inference and then em- bedded in an EM algorithm for learning."}, {"title": "ExpectationPropagation for the Generative Aspect Model", "sentence": "The dot-dash vertical line is the result of applying EM using EP and is closest to the true maximum."}]}], "papers": [{"id": 0, "title": "ExpectationPropagation for the Generative Aspect Model"}]}