{"paragraph_scenes_info": [{"x": 2, "text": "Our research shows how to extract, visualize, and explore informative regions on very large 2D landscape images, 3D volumetric datasets, high-dimensional volumetric mouse brain datasets with thousands of spatially-mapped gene expression profiles, and geospatial trajectories that evolve over time.The contribution of this dissertation include: (1) We introduce a sliding-window saliency model that discovers regions of user interest in very large images; (2) We develop visual segmentation of intensity-gradient histograms to identify meaningful components from volumetric datasets; (3) We extract boundary surfaces from a wealth of volumetric gene expression mouse brain profiles to personalize the reference brain atlas; (4) We show how to efficiently cluster geospatial trajectories by mapping each sequence of locations to a high-dimensional point with the kernel distance framework."}, {"x": 5, "text": "Big data challenges our capacity to turn data into knowledge for advancing science, engineering, and medicine.This dissertation aims to show that the exploration process of big data can be assisted by integrating machine learning with visualization.We specifically show how users can efficiently identify the regions of interest in datasets by coupling visualization and knowledge discovery.In this dissertation, we analyze and visualize scientific datasets of increasing dimensions, such as spatially large 2D images, 3D volumetric medical and climate datasets, high-dimensional volumetric brain datasets with thousands of spatially-mapped gene expression profiles, and geospatial trajectories that evolve over time."}, {"x": 6, "text": "The advances in computing and acquisition allow us to acquire, process, and store massive amounts of raw data.However, our ability to comprehend the data remains unchanged.Machine learning and visualization can offer help in understanding large datasets in two ways.First, machine learning discovers information from raw data by recognizing patterns, anomalies, and relationships.This artificial intelligence approach reduces the vast amount of data to more manageable knowledge and information.Sec- ond, visualization presents the raw data in a visual form for effective user comprehension.Visual representation enhances user cognition and reasoning on the abstract data.User interactions facilitate feedback between machine learning and visualization."}, {"x": 7, "text": "This dissertation shows how machine learning can assist in visual exploration of two, three and multi-dimensional scientific datasets, along with temporal evolution.On very large 2D multi-gigapixel landscape images, we show that our approach of progres- sive elicitation of salient regions is fast and allows rapid identification of regions of inter- est.On 3D volumetric datasets, our approach mimics user exploration behavior by analyzing the intensity-gradient histogram with the normalized-cut multilevel segmentation technique.The resulting segments lead users to discover volumetric regions of interests.We extract gene expression surfaces of different anatomical brain structures from thou- sands of spatially-mapped gene expression profiles of mouse brains.We also show how to efficiently cluster and detect communities in time-varying geospatial trajectories by using the approximate kernel distance framework."}, {"x": 8, "text": "1.1 The Big Data Challenge"}, {"x": 9, "text": "Big data has its origins in scientific disciplines, such as astronomy, to medical dis- cplines, such as genomics, to consumer applications, such as Internet transactions and social networks.The Large Hadron Collider (LHC) generates 15 petabytes of high en- ergy particle experiments data annually <17>.The Sloan Digital Sky Survey (SDSS)<153> has gathered 140 terabytes of optical astronomy images since 2000, its successor, the Large Synoptic Survey Telescope (LSST) <61>, is designed to capture 30 terabytes every night with its 3200 megapixel camera.The Expanded Very Large Array (EVLA) <125> radio telescopes are producing 1.2 terabytes of data everyday.Computational methods have played an instrumental role in genomics research.The cost of genomic sequencing has been rapid falling from $100,000, at the completion of the first human genome in 2001, to a few thousand dollars <106> now.This trend is outgrowing the Moores law and it implies the data can outgrow our computing power in this area.The 1000 Genome Project <148> hosts 130 terabytes of genomics data to provide us a better view on human genetic variation.The Cancer Genome Atlas <107> sequences genomes of tumors and normal pair tissues at a rate of 20 terabytes per month.The Allen Brain Atlas <74> pro- vides a 600 terabytes data archive of how thousands of genes are expressed in different parts of mouse and human brains."}, {"x": 13, "text": "Information and Semantics Challenge: Visualization of machine-analyzed data helps users understand the data faster.Identifying informative regions in datasets that match human expectations is an ambitious challenge.We iterate the analysis and visualization with user interactions, such that users can provide valuable semantic inputs to improve the information discovery process."}, {"x": 14, "text": "In this dissertation, we address each of these challenges progressively from 2D im- ages and 3D volumes to datasets with thousands of dimensions and time-varying geospa- tial locations.The next sections outline the results and the contributions."}, {"x": 15, "text": "1.2 Saliency-Assisted Navigation of Very Large Landscape Images"}, {"x": 18, "text": "We show that our approach of progressive elicitation is fast and allows rapid iden- tification of regions of interest.Unlike previous work in this area, our approach is scal- able and computationally reasonable on very large images.We validate the results of our approach by comparing them to user-tagged regions of interest on several very large landscape images from the Internet."}, {"x": 19, "text": "1.3 Hierarchical Exploration of Volumes using Multilevel Segmentation of the Intensity-Gradient Histograms"}, {"x": 20, "text": "Visual exploration of volumetric datasets to discover the embedded features and spatial structures is a challenging and tedious task.We present a semi-automatic ap- proach to this problem that works by visually segmenting the intensity-gradient 2D his- togram of a volumetric dataset into an exploration hierarchy <57>.Our approach mimics user exploration behavior by analyzing the histogram with the normalized-cut multilevel segmentation technique.Unlike previous work in this area, our technique segments the histogram into a reasonable set of intuitive components that are mutually exclusive and collectively exhaustive.We use information-theoretic measures of the volumetric data segments to guide the exploration.This provides a data-driven coarse-to-fine hierarchy for a user to interactively navigate the volume in a meaningful manner."}, {"x": 21, "text": "1.4 Personalizing the Brain Atlas through Gene Expression Correlates"}, {"x": 22, "text": "We introduce a data-driven approach to personalize the brain atlas with multiple gene expression profiles <55>.Segmentation of brain volumes is a challenging problem"}, {"x": 23, "text": "Learn an expression Personalize the reference surface Retrieve gene expression profiles surface from the genes with the gene expression surface that often requires fitting a reference atlas with boundaries of the brain structures to a brain volume.Figure 1.3 shows a data-driven approach for extracting these structural boundaries from a wealth of spatially-mapped gene expression scalar fields.We first re- trieve genes that are highly correlated with a brain structure of interest.Then, we apply tensor voting to identify a surface with coherent directions that spans the peaks of the gene expression gradients.This 3D surface represents the gene expression boundaries around the brain structure of interest.We visualize the difference between this genetic boundary and the reference atlas.We also compute a deformation that maps the reference atlas to the gene expression surface.This data-driven deformation allows us to personalize the reference brain atlas according to coherent structures in multiple volumetric gene expres- sion profiles.Our experimental results compare a variety of gene expression surfaces to the gene expression profiles and the reference brain structures."}, {"x": 24, "text": "1.5 Fast Trajectory Clustering using the Kernel Distance"}, {"x": 25, "text": "We present a novel approach for clustering geospatial trajectories by the approxi- mate kernel distance <54>.Computing a distance between two trajectories is a tradition- ally challenging problem, due to the quadratic distance computations between points in the two trajectories.The approximate kernel distance method projects point sets, curves, and surfaces to high-dimensional feature vectors for similarity comparison.In this work, we show how to map each trajectory to a high dimensional point with this framework in O(nlgn) for clustering applications.This is very attractive as it allows conventional point-based data mining algorithms to be applied to geospatial trajectories.We present (1) a new technique to cluster geospatial trajectories with an approximate kernel distance, (2) we show how to combine this approach with k-means clustering and operate in a streaming fashion which we can update the feature vectors dynamically as the new points arrive, (3) we also show how to combine the approximate kernel distance framework with community detection methods to automatically discover unevenly distributed clusters of various shapes, and (4) our performance studies show efficient scaling up of this method to process very large datasets with hundreds of thousands of trajectories and tens of mil- lions points within a few minutes.Figure 1.4 shows five clusters of 464K San Francisco taxi trajectories."}, {"x": 28, "text": "Visual Knowledge Discovery: We use visual approaches to identify regions of interest from visual datasets and provide guided explorations.We simulate the zooming process on very large images by using a sliding window to compute saliency and then visualize the details of a multi-gigapixel image on megapixel displays.On 3D volumetric datasets, we mimic user behaviors by visually segmenting the intensity-gradient histogram of vol- ume datasets.Our work on spatially-mapped gene expression profiles extracts expression surfaces from thousands of gene expression profiles.Clustering similar trajectories geo- metrically discovers visually similar patterns in time-varying geospatial trajectories."}, {"x": 29, "text": "Data Scalability: We show our visual information discovery can be implemented in a scalable fashion.For spatially large 2D images, we implement sliding-window image saliency computation in an out-of-core fashion on GPUs.We observe that meaningful volumetric segments can be found in the intensity-gradient histogram of a 3D dataset.This 2D histogram is independent of the volume size, thus allowing us to process a large amount of data.We use parallelizable and GPU-friendly techniques, such as tensor voting and isosurface algorithms, to extract expression surfaces from spatially-mapped volumet- ric gene expression profiles.We enable efficient clustering of time-varying geospatial tra- jectories by mapping a sequence of points onto a high-dimensional point through random projections.This mapping allows us to apply some highly scalable point-based clustering and community detection algorithms to hundreds of thousands of trajectories within a few minutes."}, {"x": 30, "text": "Interaction and Visualization: We provide efficient visualization and exploration mech- anisms for users to associate their knowledge with the data.We visualize small informa- tive regions on very large images and allow users to interactively refine the results.Users hierarchically explore machine segmented components in a volume dataset.We use a sur- face representation to visualize many coherently expressed genes within a user-specified anatomical brain structure.Clusters and communities of geospatial trajectories allow users to visually identify patterns and spot anomalies."}, {"x": 43, "text": "There is a rich history of data analysis for visual summarization and identification of information-rich subspaces for effective visual presentation.We next present a few exam- ple of how salience is defined and used for visual datasets to enhance their depiction.No- table advances on 3D datasets include defining saliency for polygonal meshes <94>, com- paring it to human eye movements <85>, and illuminating meshes based on saliency <93>.Howlett et al.<51> use eye-tracking data to identify salient features on meshes and carry outuserstudiestovalidatetheirfindings.Kimetal.presentandvalidatesaliency-based enhancement operators to guide visual attention in volume visualization <83> and geomet- ric meshes <84>."}, {"x": 44, "text": "Machiraju et al.<104> present a system to detect contextually significant multiscale features in very large datasets directly in the wavelet domain and visualize them pro- gressively.Bordoloi and Shen <12> select informative views of volumetric data based on saliency defined using entropy measures.Viola et al.<163> determine the most ex- pressive view for a selected region of interest in a volume using mutual information.Bruckner and Mo ller <14> use isosurface similarity maps based on mutual information to automatically select the most salient isosurfaces.Saliency-based summarization of time-varying datasets has been carried out for videos <26> and molecular dynamics sim- ulations <123>.Wiebel et al.<168> identify salience with the vortices that originate from walls in three-dimensional time-dependent vector fields and track their evolution using generalized streak lines.More recently, Information contents of datasets have been ex- tensively used to compact representations and visualizations.Ja nicke <66, 65> and Chen <64> use evaluate information content to better visualize flows.Kim and JaJa <81> con- struct isosurfaces from entropy-based octrees."}, {"x": 46, "text": "2.4 Transfer Function Design"}, {"x": 47, "text": "Transfer functions directly influence the visualization by assigning optical proper- ties such as color and opacity to voxels.Previous work has devoted a lot of effort on transfer function generation.Pfister et al.<126> present a survey of different approaches to transfer function design.Traditionally, a transfer function maps voxels to colors and opacity according to a 1D function of the scalar values.Subsequent work has consid- ered multiple attributes and has involved the design of transfer functions using multiple dimensions.Fujishiro et al.<38> and Zhou et al.<177> analyze the topology of the scalar field to generate transfer functions.Tzeng et al.<160> paint on the volume data to design high-dimensional transfer functions.Sereda et al.<141> compute LH histograms to detect material boundaries and transfer functions.Salama et al.<137> include abstract semantic attributes to assist in domain-specific visualization design.Correa and Ma <23, 24> have recently incorporate size and visibility into transfer functions.Ruiz et al.<135> generate automatic transfer functions based on information divergences."}, {"x": 48, "text": "A popular transfer function attribute is the derivatives of the scalar field, often the gradient of the intensity.Kindlmann and Durkin <86> use the derivatives to show better separation of materials and boundaries.Kniss et al.<87> use fixed shape widgets to in- teractively design 2D transfer functions.Roettger et al.<131> create transfer functions by clustering the 2D volume histogram according to the spatial connectivity of the volume dataset.Users interact with a 1D histogram to manipulate the 2D non-parametric seg- ments in Maciejewski et al.s system <105>.Instead of the volume histograms, Selver and Gu zelic  <140> initialize the transfer function by fitting radial basis functions to the histograms of the image slices in a volume dataset.Most recently, Wang et al.<167> learn a Gaussian Mixture Model from the volumetric scalar field and use the resulting ellipses to compose transfer functions."}, {"x": 49, "text": "In Chapter 4, we show how to automatically identify segments of interest from the intensity-gradient histograms.We organize these segments from coarse to fine to facilitate the exploration process.Our segments are non-parametric and tightly cover the feature space.Users can interact with these segments directly on the intensity-gradient histograms."}, {"x": 51, "text": "Separating 2D images and 3D volumes into meaningful regions is a long-standing and challenging problem.Here we present a small subset of recent results from the vast literature on this topic.Freixenet et al.<37> survey different approaches to segment 2D images.Mean-shift image segmentation <22> treats the image as probability distribution and finds the segmentation according to local maxima.Graph-based segmentation ap- proaches model the pixels as nodes and the image as a connected graph and then they par- tition the graph to solve the segmentation problem.Felzenszwalb and Huttenlocher <32> use a boundary predicate and a greedy algorithm to segment images.Sharon et al.<142> introduce an algebraic multigrid inspired segmentation algorithm."}, {"x": 52, "text": "3D volume segmentation is a natural extension to the 2D image segmentation prob- lem.Huang and Ma <52> apply the region-growing technique to segment volumes.Sher- bondy et al.<143> use programmable graphics hardware to accelerate volume segmenta- tion.Tzeng and Ma <161> cluster volume datasets with the ISODATA algorithm.Seg- mentation of various organs from medical images is an important application.Level-set methods <7, 178> have been used to segment 3D brain images.Grady et al.<44> apply random-walk segmentation to detect organs from medical volumes.2-point and N-point correlation function features <68, 110> have been used to classify 3D tissue im- ages.Fuller et al.<39> use support-vector machines to segment retinal layers.Janoos et al.<69, 70> segment, reconstruct, and visualize dendritic spines in 3D from optical mi- croscopy imaging.The advances in visual computing technologies have enabled segmen- tation and visualization of neurons <49, 164> in brains.Computer segmentation systems are often guided by user interactions <115>.Bartz et al.<9> use a seed point to segment the bronchi in the lungs.Prassni et al.<128> incorporate user guidance to minimize the uncertainties in the brain segmentation.Kniss et al.<88> use supervised manifold distance on brain image segmentation."}, {"x": 53, "text": "3D volume segmentation is a natural extension to the 2D image segmentation prob- lem.Huang and Ma <52> apply the region growing technique to volume segmenta- tion.Sherbondy et al.<143> accelerate volume segmentation with programmable graphics hardware.Segmentation of organs from medical data is a prime application of volume segmentation.Grady et al.<44> apply random walk segmentation to detect organs from medical volumes.Fuller et al.<39> use support-vector machines to segment retinal layers.Many systems incorporate user guidance to perform interactive segmentation.Bartz et al.<9> use a seeded point to segment the bronchi in the lungs.Prassni et al.<128> incor- porate user guidance to minimize the uncertainties in the segmentation.Kniss et al.<88> use supervised manifold distance to segment volume data.Torsney-Weir et al.<158> esti- mate visual responses to guide the search for the image segmentation parameters."}, {"x": 54, "text": "In Chapter 4, we use the popular normalized-cut approach <144> to directly segment the intensity-gradient histogram of a volume data and construct the transfer function.The normalized-cut approach to 2D image segmentation has been extensively used for a variety of applications and it has been mapped on a variety of architectures including multi-core and many-core GPUs <53>."}, {"x": 55, "text": "2.5.1 Atlas-based Segmentation of Brain Images"}, {"x": 56, "text": "Segmentation of brain images <34> is an important topic in medical imaging.Atlas- based techniques attempt to register an annotated brain atlas to an input image.The challenge is in devising methods that deform the atlas to fit a single image.Cabezas et al.<16> present a recent survey on atlas-based segmentation of MR brain images.When multiple brain atlases are available, selecting the best atlas to fit a particular image is also of interest <48, 132, 170>.Evans et al.<31> construct a blurred atlas from hundreds of MR brain images.Ju et al.have proposed a geometric framework <76> for landmark-and- atlas-based segmentation <10, 78> on the in situ hybridization gene expression images of mouse brains.In this work, we present a method to extract 3D boundaries of a given brain structure from multiple gene expression profiles."}, {"x": 57, "text": "2.5.2 Extracting 3D Surfaces from Scalar Fields"}, {"x": 58, "text": "Lorensen and Cline <101> introduced the classical marching cubes algorithm for constructing contour surfaces from a scalar field at a given iso-value.It has been a chal- lenge to locate good iso-surfaces in volumetric scalar fields.Bajaj et al.<8> present the contour spectrum tool for users to select iso-values.Kindlmann and Durkin <86> use scalar field gradients to identify better separation of materials and boundaries.Tang and Medioni <154> show how to use tensor voting to extract surfaces from noisy point clouds and scalar fields.Sereda et al.<141> introduce LH histograms to detect material bound- aries.Bruckner and Mo ller <15> compute a similarity map of iso-surfaces to determine a good iso-value."}, {"x": 59, "text": "2.6 Clustering Moving Objects"}, {"x": 63, "text": "Discovering groups of moving objects has also been an active research area.Gud- mundsson et al.<45> find fixed-radius circular flocks of moving objects with a quadtree.Jeung et al.<72> relax the fixed-radius requirement and discover convoys that are together in consecutive timesteps by filtering and simplifying the trajectories.Li et al.<97> find swarms that are together in non-consecutive timesteps by using forward-backing pruning to reduce the search space.Giannotti et al.<42> discover the frequently visited regions of interest from trajectories.Nanni and Pedreschi <112> cluster trajectories with a focus on time.Pelekis et al.<124> cluster uncertain trajectories.Tang et al.<156> find travel companions from streaming trajectories.Zheng et al.<174> use a density-based approach to detect gathering patterns."}, {"x": 64, "text": "Zheng et al.have collected a huge dataset of GPS trajectories <175>, including thousands of taxi trajectories for improving driving directions <172>.More recently, they have released a new system for taxi ridesharing <103>.Zheng and Zhou <176> have edited a book on computing with spatial trajectories."}, {"x": 65, "text": "2.7 Approximating Complex Distances"}, {"x": 67, "text": "This approach has been widely used in machine learning <130, 139> to find non-linear classifiers and underlying subspace manifolds.Similarly, the kernel distance method uses a lifting map to project data points into a higher dimensional space and computes the distances there.This method has been used for comparing point sets, curves, and surfaces.Vaillant and Glaunes <162> have used this method to compare surfaces of human face meshes.Joshi et al.<75> have established the bounds for the lifting map requirement.They have also shown how to select a coreset of points and how to estimate translation and rotation to align two different point sets."}, {"x": 68, "text": "Comparing distributions has received significant attention in the machine learning, data mining and computer vision communities.One of the popular distance functions to compare distributions and weighted point sets in general is the Earth Mover Distance (EMD).EMD has been popularized by the computer vision community for comparing histograms in content-based image and video retrieval <134>.Yet computing the Earth movers distance requires solving a transportation optimization problem with the O(n3) Hungarian algorithm.Many approximation techniques have been proposed.Ling and Okada <99> empirically show that EMD can be computed in O(n2) time with L1 distance.Shirdhonkar and Jacobs <145> compute an approximation to the EMD in O(n) time by using the sum of the absolute weighted wavelet coefficients of the difference histogram.While these approximations work in L1 space, Andoni et al.<2> show how to embed EMD into well-behaved norm spaces of high dimensions.Applegate et al.<3> have shown a wavelet approximation for EMD on generalized manifolds."}, {"x": 70, "text": "Saliency-assisted Navigation of Very Large Landscape Images"}, {"x": 71, "text": "We are seeing a significant growth in the interest and relevance of very large images.One of the reasons behind this trend is the development of systems that can automatically capture and stitch photographs to create images of unprecedented detail ranging from a few gigapixels <21, 90, 179> to even a few terapixels <46>.Recent advances in consumer- grade robotic image acquisition from companies such as Gigapan have further energized social network communities that are interested in building, sharing, and collectively ex- ploring such large images.Some relevant work on processing of very large images in- cludes a streaming multigrid solver for gigapixel scale out-of-core gradient-domain image processing by Kazhdan and Hoppe <79>.More recently, Summa et al.<150> present pro- gressive processing of high-resolution images with interactive previews.Kopf et al.<90> discuss how to naturally display the stitched image by cylindrical projections.Luan et al.<102> adaptively annotate these very large images by text and audio according to the viewing position and scale.While these are very interesting first steps in computational processing and display of very large images, this chapter addresses a different challenge for such large images  their effective visual navigation."}, {"x": 72, "text": "Consider a gigapixel image shown in Figure 3.1 .The successive zooms give an indication of the level of detail in such images.When viewing such images, users typ- ically pan at the coarse level and occasionally zoom in to see the fine details.Panning at the finest level of detail is too tedious and panning at the coarsest level of detail does not have enough information for the user to know where to zoom in.Just to convey the magnitude of the problem, let us consider some numbers.Imagine a user is visualizing a 4 Gigapixel image on a 2 Megapixel monitor.This would suggest that every monitor pixel is representing 2000 image pixels and the observable image on the monitor is a mere 0.05% of the total dataset.Further, if it takes a user just a couple of seconds to scan the monitor, it will take more than an hour to scan through the entire image."}, {"x": 76, "text": "1.Visual Scalability: The visual scalability challenge arises from the inability of the human visual system to take in all the details that are present in a very large image.This arises from a fundamental limitation of the retina as well as the display hardware which have not kept pace with our ability to acquire ever larger images.Figure 3.2 shows the growth in resolution of the mainstream consumer-grade LCD displays against camera sensors in recent years.The display resolutions correspond to the highest-resolution mon- itors sold by a mainstream vendor (such as Dell and Apple) and the camera-sensor sizes correspond to the highest-resolution entry-level SLR cameras manufactured by Canon, Nikon, or Sony.It is easy to see how the resolution growth of these off-the-shelf cameras has clearly outpaced the resolution of the display monitors."}, {"x": 77, "text": "2.Information Scalability: The challenge here is to design effective computational 20 algorithms to identify nuggets of useful visual information that hide in large-scale im- ages.In very large images, most of the image data is innocuous and unimportant and even considering it wastes precious time and resources.Often relatively small regions in such very large images are accorded a very high information value by human observers.Identification of such informative regions in very large images that largely match human expectations is an ambitious challenge."}, {"x": 78, "text": "3.Data Scalability: The sheer data size of these images poses a computational chal- lenge.Processing such large images along with their auxiliary data structures often necessitate out-of-core methods as well as designing of algorithms that are cache- and memory-efficient.Even routine image-processing operations for very large images re- quire a careful mapping to the many-core and multi-core processor architectures for any reasonable performance."}, {"x": 80, "text": "1.We extend classical computational image saliency to very large images.Users of- ten navigate across three or more orders of magnitude scale differences  from the overview to the finest-scale views while viewing a very large image.Classical algo- rithms for multi-scale image saliency break down at handling such a large span of visual scales.We discuss the issues involved and present a solution in Section 3.2."}, {"x": 88, "text": "Visual Scalability: Traditional algorithms for multi-scale image saliency work well for small images up to a few megapixels but do not scale up well to gigapixels and beyond.To address this we augment the traditional multi-scale image saliency approach with a sliding window over scales to effectively work with very large images.Our approach only requires Gaussian convolutions on images.It is highly parallelizable and scales linearly with the size of the image.The sliding-window saliency map phase of our approach discovers thousands of locally salient regions from billions of pixels."}, {"x": 89, "text": "Information Scalability: Typical landscape images comprise of a large number of nat- ural elements such as clouds, rocks, grass, and trees.In this chapter we assume that such repeating scene elements are not of interest to the viewers.We characterize all image regions using automatic color-structure descriptors.We then argue that the most interest- ing regions are the ones that are the most different from their k nearest neighbors (k-NN) in such color-structure feature space.We have empirically observed that this definition works well for landscape images.Other descriptors may be found to be more suitable for other datasets.We use a spatial index to accelerate the k-nearest-neighbor queries.This indexing and querying process grows as O(nlogn), where n is the number of salient re- gions identified by the sliding-window saliency step.For gigapixel images n is typically of the order of a few tens of thousands.We refer to this step as anomaly detection."}, {"x": 90, "text": "Interactive Visual Exploration: We have developed an interactive visualization envi- ronment to assist in exploration of very large images.We facilitate users to be aware of details that are a fraction of the screen pixel by ensuring that the overlays for such regions are large enough to be visible at every scale.The users can then explore and inspect all such regions interactively.We also have an automatic mode of the system in which the users are led through a smooth camera fly-through over all the informative regions in the image in order of their uniqueness as determined by the Visual and Information Scalabil- ity stages of the algorithm.If a user comes across a region of the image that the system claims is important, but the user finds to be unimportant, the user can identify all similar regions (using a slider) and discard them interactively.The spatial index structure built to address the Information Scalability stage of the algorithm allows this operation to occur within a few milliseconds."}, {"x": 91, "text": "Data Scalability: The size of the very large images together with their auxiliary data- structures imposes a significant computational and storage burden.We have used a num- ber of approaches to ameliorate this problem including out-of-core computation, efficient storage of salient regions, and building the a clipmap-based image viewer."}, {"x": 94, "text": "3.2.1 Traditional Image Saliency"}, {"x": 95, "text": "A saliency map shows which part of an image is likely to attract the most atten- tion of the low-level human visual system.Itti et al.<60> have proposed a computational model of visual saliency by using multiscale image processing.Multiscale image process- ing techniques analyze an image at different scales to simulate the retinal receptive fields.Their image saliency model aggregates the results from three features of an image  in- tensity, color opponencies, and orientation.We have found that the use of the orientation features decreases the quality of our results as it ends up enhancing naturally occurring structures with strong edges such as cracks in rocks or trees, that end up becoming too salient.In this chapter we only consider the intensity and the two color-opponency at- tributes for computing image saliency.The intensity (FI ) is the average of primary colors, red, green, and blue.The color opponency attribute contains two sub channels, Red- Green(FR) and Blue-Yellow(FB).The details on computation of these attributes can be found in <60>."}, {"x": 97, "text": "Then, we convolve the feature images Fi with Gaussian kernels, G, at different scales j. We find contrasting regions by computing the difference of Gaussians (DoG) images at each scale, Gi,j.We compute the DoG images at scales <,4>,<,8>.The DoG op- eration mimics the contrast detecting receptive fields of retinal ganglion cells.Figure 3.5 shows the DoG operation extracts contrasting cars from the background.N is a normal- ization function that promotes the peak salient regions <59>.The saliency map, S, is an aggregation of the normalized DoG images.We use  = 2.0 in our experiments."}, {"x": 99, "text": "To see the difficulties introduced by the traditional saliency method, consider the saliency map for the parking lot image in Figure 3.4 computed by Ittis et al.<60> method.If we aggregate the saliency at all the levels of detail, we obtain the salient region in Figure 3.6(a).We observe that mostly the center of the parking lot has been included, while most of the surrounding cars have been excluded.It is interesting to note that if we analyze the saliency maps at each scale we find that cars are salient at fine scales ,2,4 and the parking lot is salient at scales 16,32,64.This can be seen in Figures 3.6(b)(d).Therefore even though the saliency maps at individual scales were able to correctly identify the constituent salient elements, the overall aggregation ended up suppressing a number of them.The reason behind this is that if the salient regions at two different scales overlap, this overlap tends to disproportionately promote the overall salience of that region.Such events are infrequent or otherwise are not of great concern when the image sizes are relatively small.However, this no longer holds true in very large images.As shown in Figure 3.4, an observer would recognize the parking lot and the cars independently of each other at different scales.Therefore we believe that it is inappropriate to aggregate the saliency of the cars and the parking lot together since they are detected by DoG filters that are 16 scales of difference apart.The key observation here is that while simulating the multiscale capabilities of the human visual system, we have to be aware that our eyes have a finite resolution.Therefore we should limit the number of scales in multiscale image processing based on the limits of the human visual system."}, {"x": 101, "text": "This sliding window approach ensures overlapping regions from drastically different scales do not interfere with one another.We seek a scale difference  that truly reflects the human visual system.We use  = 4 j in this chapter.We next use arguments from the human visual system theory to suggest why this may be appropriate."}, {"x": 106, "text": "3.3.1 Image Region Descriptors"}, {"x": 109, "text": "To achieve rotational invariance, we use histograms of the color-space of the pixels belonging to the region of interest.We have tested a number of color spaces  RGB, HSV, CIELab and found that neither of them were very discriminative.We also experimented with shape and orientation descriptors and found that they were excessively discrimi- native.This search led us towards a descriptor that would represent both color as well as statistical structural information of an image region and would have a discriminating ability that would lie between the two extremes (color-based and edge-based descriptors)."}, {"x": 110, "text": "The MPEG-7 color-structure image descriptor represents both color and structural information.The MPEG-7 is an ISO standard for describing multimedia content data and facilitates information retrieval.It consists of generic descriptors that cover many basic visual features, such as color, texture, and shape.The MPEG-7 color-structure descriptor embeds color structure information into the descriptor by counting color frequencies in a moving window of 8  8 pixels.Color values are represented in the double-coned HMMD color space, which is quantized non-uniformly into 64 bins.The range of histogram is normalized to 0  255.The resulting descriptor is a 64-dimensional vector.We follow the recommendation of MPEG-7 standard and compare them using the Euclidean L2 norm distance.p and q are the descriptors of two image patches and D(p,q) is the distance in between the descriptors.We compute the MPEG-7 color-structure descriptor for each image patch using the software provided by the BilVideo-7 <5> video indexing and retrieval system."}, {"x": 112, "text": "We compute the uniqueness of each region by considering its k-nearest-neighbors P is a set of image patch descriptors.The uniqueness of image patch p, U(p), is its average distance to its k-nearest neighbors, q1 ...qk.Repetitive regions with many close neighbors have a low average distance.Regions such as humans, signs, or vehicles should be distinct from the other regions and have a high average distance.We identify the unique regions of interest by their high average distances.We select the top 3% of salient regions as the regions of interest in our experiments."}, {"x": 113, "text": "Approximate nearest-neighbor data structures accelerate the k-nearest-neighbor search <138>.The biggest overhead in the k-nearest-neighbors anomaly detection is the need to retrieve k-nearest-neighbors for each region.Linear search of the k-nearest-neighbor queries is computationally expensive.Research in computational geometry provides many spatial data structures to facilitate this nearest neighbor querying.The approximated nearest- neighbors index significantly accelerates this search process.The sum of distances to the top k-approximated nearest-neighbors provides a reliable uniqueness estimate of each re- gion.Our implementation uses a randomized KD-Tree index in the flann library <111> through the OpenCV library.tection phase.This process reduces the 18 thousand salient regions to just about 500 anomalous regions."}, {"x": 117, "text": "Automatic exploration guides the user to discover the unique regions of the image.User interaction refines the computed detections."}, {"x": 129, "text": "3.5.1 Out-of-core GPU Saliency Computation"}, {"x": 130, "text": "We use GPUs to accelerate image saliency computation.The required operations for Difference of Gaussians (DoG): image filtering, addition, subtraction, and resizing are highly parallelizable and suitable for GPU implementation."}, {"x": 131, "text": "We compute a Gaussian pyramid to approximate the Gaussian blurred images at different scales.We repeatedly downsize the image by a scale of two and convolve it with a fixed Gaussian kernel of scale .We store the x scale Gaussian image at level log2(x) of the pyramid.The DoG images can be computed by simply finding the differ- ence of Gaussians images between two levels.The non-linear normalization function N iteratively applies the DoG operation <59> to promote the peak regions.We compute each of these normalized maps once and use them to compose sliding-window saliency maps ."}, {"x": 132, "text": "A significant problem in processing very large images (which currently are a few gigapixels) is that the entire image will not fit in the GPU or main memory.To address this, we divide each image into small tiles (256  256).We load the image tiles into the GPU independently for addition, subtraction, and resizing operations."}, {"x": 133, "text": "Gaussian filtering requires information on image boundaries.Filtering each tile without overlap results in loss of information at the tile boundaries.To address this we load these tiles into the GPU with overlaps for filtering.For every sub-image that is to be filtered we load two extra rows of tiles (top and bottom) and two extra columns of tiles (left and right) that surround the sub-image.We fill the GPU memory with the largest possible sub-image (with additional surrounding overlapping tiles) to ensure effi- cient processing and minimize re-filtering of overlapping tiles.Depending on the loading order, either one row or one column will be used for filtering the next consecutive set of tiles.The ability to independently filter these tiles allows parallelization."}, {"x": 134, "text": "In our implementation, we use the NVIDIA performance primitives for GPU Gaus- sian filtering, resizing, addition, and subtraction."}, {"x": 137, "text": "To address this, we first threshold the sliding-window saliency maps and locate con- tinuous regions, also sometimes referred to as blobs.The open-source library cvblob provides blob detection in our implementation.We carry out local Principal Component Analysis (PCA) to fit ellipses to these regions.This allows us to reduce the storage of each region from hundreds of pixels to a few parameters (center, orientation, and principal axes intercepts of each ellipse).The threshold of our experiments is 0.25."}, {"x": 139, "text": "Very large images presented in this chapter do not fit in the GPU or main memory for display.Each gigapixel in RGB format takes three gigabytes of memory in an uncom- pressed format for rendering.Images with even a few gigapixels exceed the GPU or main memory of a workstation.We have implemented an out-of-core tiled-image viewer.Our viewer fetches only what can be seen at an appropriate scale from the disk.This is similar in spirit to the concept of a clipmap <157>.To carry this out we build a mipmap pyramid of the image.We divide the images on each level into tiles of 256  256.We load the re- quired image tiles according to the viewing parameters.We pre-fetch two extra rows and columns of image tiles surrounding the viewing region to provide smooth panning.Load- ing images from the immediately nearby scales prepares for the zooming operation.We store these images in a texture array.This array is independent of the display arrangement of the textures.We map each texture to an array location by a hash function.The loaded texture can be reused on different views without any memory movement.The memory usage of the viewer is independent of the size of the image.It is related to the size of the viewing window on the screen only.Our viewer needs 350 megabytes for viewing a five gigapixel image with a few hundred overlay regions."}, {"x": 141, "text": "We evaluate our approach on four multi-gigapixel images.We report the regions identified by our system and compare them against web community tags.We also report timings of our experiments.We perform our experiments on the Linux platform with one Intel E5420 CPU, 4GB RAM, and one NVIDIA GeForce GTX 295 GPU (895MB)."}, {"x": 143, "text": "Digital image stitching and consumer grade robotics have made panoramic photog- raphy very popular.Compact digital cameras can stitch multiple consecutive pictures into a panorama.Robotic devices such as the Gigapan EPIC can take hundreds of pictures automatically for image stitching.These products allow consumers to create images of several gigapixels.Community panorama websites such as Gigapan and HDView have gained much popularity on the Internet.Users around the world upload their panoramic pictures to these websites.The web community of panoramic photography enthusiasts then explore, tag, and comment on interesting regions in these images.We downloaded four gigapixel images from the Gigapan website as shown in Figure 3.11, 3.12, and dis- cussed below."}, {"x": 144, "text": "Grimsel Pass : The Grimsel Pass is a high mountain pass in Switzerland.It connects the valley of Rhone River in the canton of Valais and the Haslital in the canton of Bern.The picture shows an overview of the mountain area, the lake, and the road network.There are distinctive areas with building constructions, hotels, and numerous cars on the road."}, {"x": 145, "text": "Royal Gorge Bridge : The Royal Gorge Bridge is the highest suspension bridge in the world.This tourist attraction is located in a theme park near Canon City, Colorado, shown in the top right of the picture.The Royal Gorge Route Railroad is a heritage railroad offering scenic and historical train-rides, shown at the bottom left of the picture.The picture shows the valley of Arkansas River with the Royal Gorge Bridge and a small town on the right."}, {"x": 146, "text": "Cacti : This picture shows a cactus field in Arizona.A few hikers are hidden among thousands of cacti."}, {"x": 147, "text": "Main Mt.Whitney Trail : This is a trail in the Sequoia National Park, California.This image of mountains and lakes includes many hikers.They all took the challenge to hike the highest peak (14,497) in the lower 48 states."}, {"x": 150, "text": "In the Grimsel Pass picture (Figure 3.11(a)), the system detects buildings in thumb- nails 1 and 8.Thumbnail 2 shows a blue Swiss Tardis.Cars, coaches, and road signs are found in thumbnails 3, 4, and 5.Thumbnail 6 shows a glacier in the mountain.Thumbnail 7 gives a view of the parking lot example in Section 3.2."}, {"x": 151, "text": "In the lower left of the Royal Gorge Bridge picture (Figure 3.11(b)), the system finds a train and a river rafting boat along the Arkansas river in thumbnails 1 and 2.We see two cable cars in thumbnails 3 and 4; the one in 3 has just departed the station whereas the one in 4 is much closer to the camera.Thumbnails 5 and 6 show a caravan and a restaurant sign around the town.Thumbnail 7 shows tourists and flags."}, {"x": 152, "text": "We found a few hikers among the cacti in Figure 3.12(a).Thumbnail 1 shows the back of a hiker; the system has identified him by his jeans.Thumbnail 2 shows a double image of two hikers, who probably moved and were captured at two instances.The hiker in thumbnail 3 was using a camera.We find a man sitting in thumbnail 4.Two other hikers are detected in thumbnail 5."}, {"x": 153, "text": "Although Mt.Whitney (Figure 3.12(b)) is a popular hiking spot, we detect more than the hikers.Thumbnail 1 and 4 show a bridge and the Alpine lake.We found 4 hikers in thumbnails 2 and 5.A hiking backpack is shown in thumbnail 3.We are able to detect 12 out of 13 hikers in this picture.detection, and user-guided interactive refinement."}, {"x": 156, "text": "Chapter 4 Hierarchical Exploration of Volumes using Multilevel Segmentation of the Intensity-Gradient Histograms"}, {"x": 160, "text": "Completeness Challenge: Exhaustive data exploration is a tedious and time-intensive exercise and yet is important to ensure that we do not overlook any important features in the data.We need mechanisms that facilitate a complete data exploration.In this chapter we show how to construct a exploration hierarchy to accomplish this goal using a top-down subdivision strategy to cover the entire feature space of a volume dataset."}, {"x": 162, "text": "In practice, users manually search for regions of interest by inspecting different areas of a feature space.Popular exploration subspaces for such a feature space include 1D density and 2D intensity-gradient.Histograms are often used to aid this search and have been implemented in several popular visualization packages, such as, Voreen <108>, VisIt <19>, and ImageVis3D <35>.For example, ImageVis3D provides a trapezoidal tool for this exploration task in Figure 4.1.We mimic this user search process by applying image segmentation to divide the histogram into intuitive regions at multiple scales.We show how to effectively discover regions of interest by traversing a hierarchy."}, {"x": 164, "text": "We present a visual-data-driven approach to volume data exploration.Users explore a hierarchy to search for regions of interest from coarse to fine."}, {"x": 165, "text": "We address the information challenge by extracting informative regions using im- age segmentation on reduced statistics.We mimic user explorations by visually segmenting the 2D histograms.We show these automatic 2D histogram segments well-approximate meaningful 3D volume segments.These segments fit the shape of the histogram and cover the entire domain.We discuss this segmentation approach in Section 4.2."}, {"x": 168, "text": "We address the semantic challenge by providing intuitive interactions to explore segments at different scales.Users can effectively identify regions of interest by traversing the hierarchy of segments.This interaction is detailed in Section 4.3.3."}, {"x": 170, "text": "We show a visual comparison of the Tooth dataset in Figure 4.1.The correspond- ing segments and histograms in the intensity-gradient domain are shown beneath the rendered image.Figure 4.1(a) shows a user-specified visualization in ImageVis3D.In Figure 4.1(b), spatial transfer function <131> connects voxels and histogram pixels in a bottom-up fashion and oversegments the histogram into many regions.Our top-down segmentation is progressive and only divides the histogram into a manageable number of segments."}, {"x": 171, "text": "Region-growing techniques with parametric shapes show limited coverage.Fig- ure 4.1(b) shows the Gaussian mixture transfer function <166, 167>.Automatic fitting produces the left visualization and requires manual resize, translate, rotate, and split op- erations on the transfer-function ellipses to produce the visualization on the right.Our visual segmentation approach produces a small number of freeform segments, that tightly fit the histogram and guarantee a complete coverage.We recursively apply the segmenta- tion to also cover the scale space."}, {"x": 174, "text": "The multilevel segmentation hierarchy completely covers the dataset at all scales."}, {"x": 177, "text": "We segment the intensity-gradient histogram of a volumetric dataset into a hier- archy of regions.We have observed that these regions express meaningful features and boundaries in the 3D volumes.The resulting hierarchy guides users to interactively ex- plore the dataset.Figure 4.2 shows an overview of our approach."}, {"x": 178, "text": "Information Challenge: We address the information challenge by segmenting intensity- gradient 2D histograms of a volumetric dataset into potential regions of interest.The histogram is the most commonly used tool to help in transfer function design.Kniss et al.<87> have shown that 2D segments in the intensity-gradient domain correspond to meaningful 3D regions in the dataset.Users recognize these shapes and patterns from the histograms image and explore the corresponding 3D regions.We mimic this user behavior by employing the normalized-cut image segmentation to extract such potential regions of interest from a 2D intensity-gradient histogram."}, {"x": 179, "text": "Completeness Challenge: The normalized-cut segments collectively span the entire intensity-gradient histogram.In order to also cover the scale space, we recursively apply normalized-cut algorithm to obtain segments of different sizes.These segments at differ- ent scales form a multilevel hierarchy from coarse-to-fine levels of detail.We have found this to be highly usable for interactive exploration."}, {"x": 180, "text": "Semantic Challenge: To address the semantic challenge, we provide interactive explo- ration with the multilevel segmentation hierarchy.Users traverse through the hierarchy to sift for meaningful features.They can cull away the irrelevant segments and subdivide the relevant segments to explore the details.We evaluate the entropies and information gain in this hierarchy to aid the exploration.These information theoretic measures guide the users in deciding where to explore.The exploration results in a visualization with features at different scales and sizes."}, {"x": 181, "text": "4.2 Volume Segmentation by Normalized Cut on 2D Histograms"}, {"x": 182, "text": "We aim to mimic how users would visually process a intensity-gradient histogram.Given a 3D intensity field, we compute its derivative, the gradient, to form a 2D intensity- gradient histogram.Users locate shapes and patterns from this 2D histogram to decide how to explore the 3D volume.As shown in Figure 4.1(a), users use widgets of different shapes to highlight the intensity-gradient histogram and visualize the regions of interest.We aid this tedious process by using image-segmentation algorithms to cut along the shape of this histogram.Previous work <87, 105, 131, 167> has shown that the continuity in the intensity-gradient domain reasonably approximates the spatial continuity in the dataset.We refer our readers to Kniss et al.s <87> work, for specific examples of how intensity-gradient histogram shapes map to corresponding volume regions in datasets."}, {"x": 184, "text": "We segment the intensity-gradient histogram using a normalized-cut approach to mimic a semantically meaningful segmentation of the volume dataset.We construct a 2D histogram from the volume dataset.We compress the dynamic range of the frequencies by taking the log, such that the statistics can be represented by a grayscale image.We trade the 3D spatial connectivity information for a compact abstraction in the form of a 2D histogram.The size of the histogram representation is independent of the size of the volume; it is only dependent on the bin sizes and precision, which can be controlled during the histogram construction.The normalized-cut segmentation procedure divides a 2D histogram into multiple segments.These non-parametric segments fit the histogram tightly as they completely cover the histograms intensity-gradient domain.In our exper- iments, we construct a 256  256 histogram from the dataset and store the histogram as a grayscale image.We compute the normalized cut using Cour et al.<25>s software."}, {"x": 185, "text": "4.3 Hierarchical Exploration"}, {"x": 188, "text": "4.3.1 Multilevel Segmentation Hierarchy"}, {"x": 189, "text": "To eliminate the need for a predetermined k, we recursively apply normalized cuts to segment the histogram and build a binary hierarchy.This hierarchy guides users to explore the histogram segments from coarse to fine details.Users interactively subdivide and explore selective regions of interest.For example, the users may interactively subdivide the tooth while keeping the box intact.This segmentation hierarchy covers the entire intensity-gradient domain at all different scales to ensure an exhaustive exploration."}, {"x": 194, "text": "We compute the entropy at each segment and evaluate the information gain at each subdivision of the segmentation hierarchy.Our goal is to guide users to explore segments that are more informative.To assist user exploration, we characterize the segments and the subdivision with two different information theoretic measures: (a) Entropy, and (b) Information Gain."}, {"x": 195, "text": "Segment Entropy: We use entropy to characterize the complexity of a segment.We extract sub-volumes, V , from the dataset according to the segments (the nodes in the hierarchy).We compute the entropy in the sub-volumes, H(V), as follows: where vi is a voxel in V, p(vi) is the probability of vi.This classic Shannon en- tropy measures how many bits are required to encode V .A high number of bits required represents a higher complexity."}, {"x": 196, "text": "In Figure 4.6(a), we color the segments of the Tooth dataset according to their entropy.It shows that the tooth contains a higher entropy than the empty space and tooth-holding material.However, when we further subdivide the tooth in Figure 4.6(b) the entropies of different components start converging and it becomes less clear which segment should be further explored.To address this we evaluate the information gain."}, {"x": 198, "text": "4.3.3 Interactive Exploration"}, {"x": 200, "text": "We present the dataset in a bi- segment configuration to start the exploration.Similar to other related work, we overlay the segments on the intensity-gradient histogram for the users to relate to the volume regions.By default, we color the segments using a randomly-generated color map.Clicking on any segment subdivides it into two components.Users can visualize the entropy or information gain using a color- coded visualization with an appropriate key press.Users may also choose to change the colors and opacities of each segment.These interactions allow a user to inspect and focus on regions of interest.We also provide shortcuts to clear the opacity of any segment to allow the user to easily cull away any segment.we decided to cull-away those segments and their subtrees are not further explored."}, {"x": 204, "text": "Implementation and Experimental Setup: We compute a six-level normalized-cut hi- erarchy for each histogram by using Cour et al.s <25> normalized cut software in Matlab.We only store the finest level of the segmentation and access the rest according to a binary- tree order.We visualize the segments as freeform components on a 2D intensity-gradient transfer function.We implement our application with Qt and the NVIDIA CUDA SDK volume rendering example.The preprocessing in Matlab takes about 15 seconds per his- togram.This preprocessing can be avoided completely if we can perform normalized cut with an accelerated eigensolver at exploration time as discussed in Section 4.5.We per- formed all experiments on a Linux workstation with a Intel Xeon 5140 and a NVIDIA GeForce 260GTX GPU."}, {"x": 209, "text": "Chapter 5 Personalizing the Brain Atlas through Gene Expression Correlates 5.1 Introduction"}, {"x": 211, "text": "Analysis of gene expression patterns in a three-dimensional context has revealed interesting results about the roles of specific genes in development and disease.Most studies to date have analyzed the expression of single genes within specific organs (such as heart, brain, or entire embryos) across stages of development or disease states.The spatial localization of individual genes can be determined through fluorescent in situ hy- bridization (FISH), followed by confocal microscopy, optical transmission tomography, or by imaging serial sections of (frozen or paraffin-embedded) tissue.A global view of gene expression across multiple genes can be obtained through microarray analysis of dissected tissue, either by selecting specific tissue types or through voxelization.In the latter approach, sections of immobilized tissue are segmented into spatially registered cubes (voxels) which are then subjected to microarray analyses.Voxelization is particu- larly appealing since the segmentation process is not biased by prior knowledge about the tissue being analyzed, making it possible to use the gene expression data to uncover novel morphological features."}, {"x": 212, "text": "Neurological disorders, such as autism, epilepsy, and schizophrenia are widely believed to have a basis in specific genes.Neurologists assess the presence or absence of candidate gene expressions in different brain regions to gain insights into these dis- eases <151>.While the relationship of the diseases and candidate gene expression profiles are not always well understood, it is important to facilitate this spatial-genomics explo- ration process through visual tools."}, {"x": 214, "text": "Allen Mouse Brain Dataset The Allen Mouse Brain Atlas <96> provides a set spa- tial gene expression profiles in adult and developing mouse brains.Many gene com- parison and visualization tools <152> have been published by the Allen brain institute for facilitating the use of this wealth of spatial genomic data.In addition to the gene expression profiles, it also provides an annotated reference atlas.In this chapter, we use a subset of the Allen Developing Mouse Brain dataset from the 2013 SciVis con- test (http://sciviscontest.ieeevis.org/).Our dataset contains 1600 gene expression profiles of developing mouse brains at stage 5 (E18.5)."}, {"x": 219, "text": "In this chapter, we extract the gene activity boundaries of a given 3D brain structure from a set of volumetric gene expression profiles.This data-driven procedure consists of three main steps:"}, {"x": 223, "text": "5.3 Selecting Relevant Gene Expression Profiles"}, {"x": 224, "text": "In order to discover high-quality and meaningful boundaries from the gene expres- sion profiles, we need to first limit the process to a handful of the most relevant genes that are highly expressed in the target region of interest.Given a target brain structure, we first use the volumetric anatomic mouse brain atlas <96> to construct a reference binary volume mask, m. Voxels inside the target structure are labeled by ones and voxels outside the structure are labeled by zeroes.For example, Figure 5.2 shows a visualization of the rostral midbrain tectum (MTt) structure in the middle of a mouse brain."}, {"x": 228, "text": "5.4 Extracting the Segmentation Surface from Gene Expression Profiles"}, {"x": 231, "text": "5.4.1 Coherent Normal Vector Field"}, {"x": 232, "text": "We use a voting approach to identify coherent normal directions from the highly expressed genes.Note that it is insufficient to identify high gradient regions of each gene expression profile and then aggregate them, because the gradients may have different orientations and represent different surfaces.Normal vectors or tensors have been used to vote in robust curvature computation <155, 119> and surface reconstruction <154>."}, {"x": 235, "text": "5.4.2 Extracting the Bounding Surface of the Gene Expressions"}, {"x": 237, "text": "5.5 Personalizing the Reference Structure to the Gene Expression Bound- ary Surface"}, {"x": 238, "text": "We personalize the reference structure with the gene expression boundary surface by deforming the reference structure to match the latter.Given a binary reference structure volume mask m, we first extract an iso-surface at iso-value 0.5 to represent the reference structure."}, {"x": 239, "text": "For each vertex on the reference surface, we find the corresponding closest point on the gene expression surface.Many distance field computation algorithms with spatial data structures <6> and GPU computing <30, 146, 147> can perform an accelerated proximity search for this.Figure 5.6(a) shows a visualization of the distance distribution between the reference surface and the gene expression boundary surface."}, {"x": 242, "text": "In this section, we present the results of our approach.For each example brain structure, we show the reference structure, the relevant gene expression profiles, the gene expression surface and the surface of our personalized reference structure.We overlay the wireframes of the reference structures to show the deformation.We first show exam- ples with reference structures that are similar to the gene expression surfaces, and then discuss cases in which the gene expression surfaces deviate from the reference brain atlas structures."}, {"x": 244, "text": "We have implemented our approach on the Linux platform with Python.The nor- mal voting and gradient computation have been implemented with NumPy.Iso-surface extraction and distances from surfaces are computated using VTK.We have run our ex- periments on a workstation with an Intel Xeon 2.33 GHz CPU and an NVIDIA GeForce GTX 295 GPU.The computation time for retrieving correlated genes, extracting the gene expression surface, and personalizing the reference structure is less than two seconds."}, {"x": 245, "text": "5.6.2 Structures whose Gene Expression Surfaces largely agree with the Atlas"}, {"x": 246, "text": "Central Subpallium The subpallium is the major basal subdivision of the embryonic telencephalon; it is related to the control of motor, cognitive and emotional responses.Figure 5.7(a) shows this structure.Figures 5.7 (b-e) show the relevant highly expressed genes.Figure 5.7 (e) shows the gene expression surface and Figure 5.7 (f) shows the personalized surface of the reference structure.In this example, the expressions of the three genes, Foxp1, Pde10a, and Drd2, span different parts of the targeted structure."}, {"x": 247, "text": "Alar plate of Prosomere 2 The Alar plate of Prosomere 2 is a neural structure in the developing mouse forebrain.The prosomere is a part of the thalamus, which is respon- sible for sensory perception and regulation of motor functions.Figure 5.8(a) shows this structure.Figures 5.8 (b-e) show the relevant highly expressed genes.Figure 5.8 (e) shows the gene expression surface and Figure 5.8 (f) shows the personalized surface of the reference structure.The expression of gene Prox1 is highly localized.Genes Ntng1 and Gbx2 show more tube like expression patterns."}, {"x": 248, "text": "Rostral Secondary Prosencephalon This mouse forebrain development region con- tains the preoptic area and the rostral hypothalamus, which controls much of a mouses basic behavior, including feeding.Figure 5.9(a) shows this structure.Figures 5.9 (b-e) show the relevant highly expressed genes.Figure 5.9 (e) shows the gene expression sur- face and Figure 5.9 (f) shows the personalized surface of the reference structure.The personalization deforms the reference surface unevenly according to expressions of the three genes."}, {"x": 249, "text": "5.6.3 Structures with Small Gene Expression Regions"}, {"x": 251, "text": "5.6.4 High Gene Expressions in Multiple Structures"}, {"x": 256, "text": "Fast Trajectory Clustering using the Kernel Distance 6.1 Introduction"}, {"x": 257, "text": "The study of time-varying geospatial patterns is important for many disciplines.The study of such patterns can greatly enhance our understanding of evolving spatial interactions and relationships amongst moving entities at varying scales of space and time.The advances and availability of tracking devices, such as RFID tags, GPS signals, as well as tracking from aerial and satellite imagery has led to an explosive growth of location-tagged data of people <175>, animals <169>, vehicles <127, 175>, and weather data <114>.For example, climate scientists study historical hurricane patterns to help predict future hurricane tracks.The study of animal movements reveal their migratory behavior and can help in protecting endangered species from poaching.Understanding vehicular traffic patterns can lead to more informed urban planning.While we are now able to track the movements of billions of entities every second, the sheer size of this data has far surpassed our ability to meaningfully analyze it.It is crucial for us to develop highly efficient algorithms if we are to make sense out of this enormous and growing body of geospatial trajectory data.In this chapter we present a novel approach to compare and cluster these geospatial trajectories."}, {"x": 259, "text": "The fundamental challenge in trajectory clustering is to efficiently compute the dis- tance between two trajectories.This traditionally has been a quadratic operation in the number of points of the two trajectories as we have to compute the distances between all pairs of points between the two trajectories.For example, the computation of the Fre chet distance, which measures the minimum distance between the points in two trajectories, requires an O(n2) solution for polygonal curves <1> and discrete points <29>."}, {"x": 270, "text": "In this section, we define kernel distance and describe a well-known procedure to approximate it efficiently.In the context of this chapter, a kernel is symmetric similarity measure K : Rd  Rd  R+ between pairs of points in Rd .Nearby points have a larger similarity value than points further away.One popular kernel is the Gaussian kernel, K(p,q)  epq2/2.Given two point sets P and Q with n and m points, respectively, we define the similarity function (P,Q) and compute the kernel distance Dk(P,Q) as follows: ping offers a number of advantages.The linearity of dot products allows us to represent nonlinear shapes, such as trajectories, as a single feature vector, (P) = pP (p), and the kernel distance Dk (P, Q) = (P)  (Q) H (the Euclidean distance).In essence, the embedding linearizes the metric by mapping the input (nonlinear) space into a vector space.Therefore, kernel methods have been widely used in the machine learning litera- ture to recognize non-linear structures in data."}, {"x": 271, "text": "The feature map, described above, is not readily usable for computational purposes since the feature space H is usually infinite dimensional.However, it is often possi- ble to construct a -dimensional feature map that approximates the kernel sufficiently well.Rahimi and Recht <130> address this problem for shift-invariant kernels (where K(p,q) = k(pq)).Their randomized Fourier feature map is based on Bochners theo- rem which states that for properly scaled shift-invariant kernel, its Fourier transform g() is a proper probability distribution.If (p) = ejT p, Rahimi and Recht <130> showed that (p)(q) is an unbiased estimator of k(pq) when  is drawn from g.In par- ticular,"}, {"x": 272, "text": "In this chapter, we use the Gaussian kernel in all our computations.Since it is a shift-invariant kernel, we can use the randomized Fourier feature approach to perform the embedding.For this kernel, we sample the  vector from a normal distribution."}, {"x": 273, "text": "6.3.1 Clustering Trajectories with the Kernel Distance"}, {"x": 274, "text": "We can cluster trajectories with the kernel distance by clustering their feature vec- tors with existing Euclidean clustering algorithms.(P,Q) can be computed efficiently by a dot product of the approximated feature vectors of   (P) and   (Q), where   (P) =  p  P   ( p ) ,"}, {"x": 275, "text": "In light of the above identity, it is not difficult to see that the Euclidean distance of feature vectors,   (P) and   (Q), yields the kernel distance between the two trajec- tories <75>.We can perform kernel-distance-based clustering of trajectories by using a wealth of Euclidean clustering algorithms.Furthermore, these feature vectors only have to be computed once for many repeated distance calculations.This is extremely efficient for clustering applications."}, {"x": 276, "text": "We model the continuity of the trajectories by adding the velocity to the trajectory points.We compute the discrete differences of points (dx,dy) in a trajectory and represent each point by a 4D vector (x,y,dx,dy), where x,y represent the point location, and dx,dy represent the velocity.Note that the dimensionality of embedding, , or the running time of the kernel distance approximation does not depend on the dimension of the trajectory points.The extra attributes do not incur any overhead after the kernel transform operation."}, {"x": 277, "text": "6.3.2 Evaluating the Approximate Kernel Distance"}, {"x": 281, "text": "6.4 Clustering Feature Vectors with k-means"}, {"x": 283, "text": "We use the midpoint displacement algorithm from fractal generation <109> to create trajectories of different shapes.For each trajectory, we rotate and translate it to create clusters of minor variations.These varying trajectories form clusters for our experiments.Figure 6.3(a) shows an example of these trajectories."}, {"x": 284, "text": "We project these trajectories onto a set of random basis as described in Section 6.3.In Figure 6.3(b), we visualize the distribution of the high-dimensional feature points by projecting them onto the first two principal components from the principal component analysis (PCA)."}, {"x": 288, "text": "6.5 Shape and Spatial Clustering of Trajectories"}, {"x": 290, "text": "T is a set containing N trajectories P1,...,PN.s and l are the desired numbers of shape and spatial clusters.C is a set of cluster labels for each trajectory.VS and VL are the shape and spatial feature vectors for clustering.For notational ease, we assume there are n points in each trajectory."}, {"x": 293, "text": "We update the feature vectors and clusters as discussed in Procedure 3.P = <P1PN> is the newly arrived set of trajectory points at timestep t. Vt1 and Ct1 are the sets of feature vectors and cluster labels from the previous timestep t  1.We compute a feature vector,   (Pt ), for trajectory P at time t by computing a weighted sum of the feature vector of the new points,   (P), and the feature vector of the trajectory at t  1,   (Pt1).We assign the weights, wt and wt1, in proportion to the number of points represented by   (P) and   (Pt1).If there is any new trajectory, we assign it to its closest cluster.We seed the k-means clustering procedure with cluster assignments of the previous timestep to accelerate convergence."}, {"x": 295, "text": "We have validated our approach by using two very large datasets (1) air-traffic over the continental United States, and (2) vehicular traffic in an urban environment.Our application datasets of air-traffic (2M points) and taxis (11M points) are significantly larger than the data used in the previous work (100K points <98>) on trajectory clustering."}, {"x": 296, "text": "Experimental Platform We have performed all our experiments on a PC with an Intel Xeon 5140 2.5 GHz processor and 4 GB of memory.Our software was implemented on the Linux platform with Python and the Numpy numerical package for computing the kernel transform and the Pycluster <27> package for performing k-means clustering."}, {"x": 297, "text": "Figure 6.6: San Francisco Taxi: (a) shows all of the 464 K taxi trajectories.(b) to (f) show the top clusters produced by our algorithm.(b) shows traffic in Northeastern San Francisco with connections to Oakland and Berkeley.(c) shows the traffic that passes the 101 highway with a cluster at San Mateo.The line pattern in (c) is due to faulty GPS data, however it does not affect our results, this shows our approach is reasonably robust to noise.(d) shows the traffic in downtown and Southern San Francisco.(e) shows a popular loop that connects the downtown to the San Francisco Airport.(f) shows the traffic in Western San Francisco.We adjust the transparency of the trajectories to visualize their relative densities in each figure, since (a) is dominated by clusters (b) and (d), some detailed patterns in the small cluster (c) may not be visible in (a)."}, {"x": 298, "text": "6.7.1 US Air Traffic Dataset"}, {"x": 299, "text": "The GE FlightQuest <41> dataset consists of a whole day of airplane flight trajec- tories over the United States airspace.There are a total of 24,843 flight tracks with well over two million GPS points.Clustering air traffic data helps us to understand the airspace usage and see patterns among flight routes.This is important for air traffic planners and authorities to improve the flight schedules, plan new routes, develop plans for avoiding congestion, and to keep air transportation flowing efficiently."}, {"x": 300, "text": "We use our shape and spatial clustering approach to cluster the flight trajectories 93 with s = 5 and l = 7.We first cluster the flight trajectories into different orientations then cluster them according to their locations.Figure 6.5(a) shows all 24K flight trajecto- ries.Figures 6.5(b)-(f) show the five shape clusters.The colors show the spatial clusters of the flights.As can be clearly seen, four of the five shape clusters separate North to South flight trajectories (Figure 6.5(b)), East to West flights (Figure 6.5(c)), Northeast to Southwest flights (Figure 6.5(d)), and Southeast to Northwest flights (Figure 6.5(e)).Figure 6.5(f) interestingly groups short flights in star-shaped clusters from popular hub airports, including Seattle and San Francisco in the West, Denver in the North, Dallas, Atlanta, and Miami in the South, and a host of airports from Washington, DC to Boston in the East."}, {"x": 301, "text": "6.7.2 San Francisco Taxi Dataset"}, {"x": 302, "text": "This dataset consists of a few weeks of taxi trajectories in San Francisco.There are a total of 464,000 trajectories and 11 million GPS locations.These taxi trajectories represent taxi routes while under hire by a passenger.Understanding traffic patterns is important for urban planning and road maintenance.Since the taxis can move freely in an urban environment, their trajectories are very different from the planned straight flight paths and the smoothly-curved hurricane tracks.The high variations amongst trajectories makes this a very challenging dataset.The taxi data is provided by cabspotting.org and has been collected by EPFL for studying mobile wireless networks <127>.It is avail- able from the CRAWDAD <91> data archive."}, {"x": 303, "text": "We cluster this taxi dataset by using our incremental clustering approach with the kernel distance.We use the k-means algorithm to directly cluster the feature vectors of the taxi trajectories into five clusters.Figure 6.6(a) shows all 424K taxi trajectories.Figure 6.6(b) shows a cluster of Northeast San Francisco with connections to Oakland and Berkeley.Figure 6.6 (c) shows the 101 highway and a cluster at San Mateo.Figure 6.6(d) shows a cluster of traffic at Central and South San Francisco.Figure 6.6(e) shows a"}, {"x": 304, "text": "Figure 6.7: Clustering of synthetic trajectories with community detection: (a) shows the trajectories.(b) shows the PCA plot of the trajectories.(c) shows the matrix of approx- imate kernel distance between the trajectories.(d) shows k-means cannot discover the correct clustering.(e) shows the multilevel community detection discovers the correct clustering.popular loop that connects the San Francisco downtown to the San Francisco Airport.Figure 6.6(f) shows a cluster in West San Francisco.This example shows our approach can meaningfully separate the city and suburban traffic of different shapes."}, {"x": 305, "text": "We compute the clustering of taxi trajectories by using the incremental update strat- egy.For each increment we loaded 4 million new points and constructed trajectories for clustering.We use the cluster assignments before the increment to seed the clustering process.Our performance is summarized in Section 6.10."}, {"x": 306, "text": "6.8 Clustering Feature Vectors with Community Detection"}, {"x": 310, "text": "We compute a k-nearest-neighbors graph of the high-dimensional feature points to approximate the data geometry.The edge weights between the vertices representing trajectories P and Q are modeled by the kernel e  (P),  (Q)."}, {"x": 312, "text": "6.9 Results with Community Detection"}, {"x": 313, "text": "We detect different groups of Atlantic Ocean hurricane trajectories by combining approximate kernel distance and multilevel community detection.We use an updated Atlantic Hurricane dataset which consists of more data than the previous study <95>.Note that this dataset consists of more overlapping curves from different clusters than the air traffic and taxi datasets."}, {"x": 314, "text": "6.9.1 Atlantic Hurricane Dataset"}, {"x": 315, "text": "This dataset consists of the tracks of the Atlantic Ocean hurricanes.There are a total of 1476 trajectories with 42, 203 points.Clustering hurricane trajectories is important for studying hurricane formation and for predicting the path of new hurricanes.This dataset is provided by the NOAA National Hurricane Center <114>."}, {"x": 317, "text": "The multilevel community detection algorithm automatically detects five clusters from the hurricane trajectories.Figure 6.8(a) shows all the 1476 hurricane tracks.Fig- ures 6.8(b)-(f) show the five automatically detected communities.Figure 6.8(b) shows hurricanes flowing from South to North and without much curvature.Figure 6.8 (c) and (d) show hurricanes that weaken after landfall in the North East of the US.Figure 6.8 (c) shows hurricanes that flow from the South Atlantic Ocean and Figure 6.8 (d) shows hurricanes that flow from the Mexican Gulf.Figure 6.8 (e) shows the strong C shape hurricanes that flow from the South Atlantic Ocean, hit the US North East, then exit back to the Atlantic Ocean.Figure 6.8 (f) shows southern hurricanes that weaken immedi- ately after the landfall.These results show that our approach can separate trajectories into intuitive and meaningful clusters."}, {"x": 320, "text": "We compare the performance and resulting clusters of our kernel distance clustering approach against the popular TRACLUS software provided by Lee et al.<95>.We used the provided programs to estimate the optimal parameters for TRACLUS clustering and performed experiments on the Hurricane dataset and the US Air Traffic dataset.We report"}, {"x": 322, "text": "6.10.2 Performance of Incrementally Clustering Taxi Trajectories"}, {"x": 328, "text": "In this dissertation, we have shown data-driven methods for visualizing large scientific datasets.Our work has spanned the increase in dimensionality across 2D, 3D, and multi-dimensions for different applications.We have shown how to identify and vi- sualize salient regions from very large 2D landscape images.By visually segmenting the intensity-gradient histograms, we extract meaningful structures from 3D volumetric datasets.When we visualize thousands of spatially-mapped 3D gene expression profiles, we first identify the coherently expressed genes within different brain structures.Then, we extract expression surfaces for visualizing the coherent gene expressions.We show how to combine the approximate kernel distance framework with clustering and commu- nity detection algorithms to identify common patterns among the time-varying geospatial trajectories.We believe these are the first steps towards extracting visual knowledge from huge scientific datasets with many spatial and temporal dimensions."}, {"x": 332, "text": "High-dimensional Brain Images In addition to extracting and visualizing gene expres- sion boundaries for a single structure at a single time point, we are interested in developing visualizations for tracking the structures physical and genetic changes in the development process.We started our pipeline with a specific brain structure; it would be interesting to construct a completely data-driven atlas by learning patterns from thousands of gene expression profiles.Another direction would be to analyze and visualize genetic infor- mation with images of different modalities, such as, MR, fMR, and EEG scan.With the development of exciting brain imaging and mapping technologies, we are interested in developing analytic and visualization tools to help improve our understanding of the most complex organ in our bodies."}, {"x": 333, "text": "Time-varying Geospatial Trajectories We are interested in developing kernel-distance- based techniques for data mining applications.We chose popular Gaussian kernel with the Euclidean distance as an example, but many other positive definite kernels can also be applied within this kernel distance framework.One possibility is to extend the Gaus- sian kernel with Generalized Radial Basis functions by using another distance function (like 2 distance).This is known to have better discriminating power in certain problem domains.We are currently working on achieving efficient feature maps for these kernels.It will be interesting to explore this space for mining rich data types such as time-series data and networks."}, {"x": 336, "text": "In addition to the work described in this dissertation <54, 55, 56, 57>, we have also contributed to other related areas during the course of this research.In the area of computational biology visualization, we have applied computational saliency to extract important timesteps from molecular simulations <82, 123>.We have summarized time- varying molecular dynamics simulations <121> with a data-driven 2D layout.We have also characterized stem cells by using their shape morphology and classified them by using support vector machines for bio-imaging applications <77>.In the area of computer graphics, we have developed a time-varying 3D social photography system <122> using smartphones.We have used the graphics-specific functions on a GPU to accelerate the generation of Poisson disk distributions <58>."}], "chapters": [{"text": "Abstract", "sentence_id": "s_0", "sentence_rank": "0", "paragraph_id": "p_0", "paragraph_rank": 0}, {"text": "Chapter 1 Introduction", "sentence_id": "s_10", "sentence_rank": "10", "paragraph_id": "p_4", "paragraph_rank": 4}, {"text": "1.1 The Big Data Challenge", "sentence_id": "s_29", "sentence_rank": "29", "paragraph_id": "p_8", "paragraph_rank": 8}, {"text": "1.2 Saliency-Assisted Navigation of Very Large Landscape Images", "sentence_id": "s_56", "sentence_rank": "56", "paragraph_id": "p_15", "paragraph_rank": 15}, {"text": "1.3 Hierarchical Exploration of Volumes using Multilevel Segmentation of the Intensity-Gradient Histograms", "sentence_id": "s_70", "sentence_rank": "70", "paragraph_id": "p_19", "paragraph_rank": 19}, {"text": "1.4 Personalizing the Brain Atlas through Gene Expression Correlates", "sentence_id": "s_77", "sentence_rank": "77", "paragraph_id": "p_21", "paragraph_rank": 21}, {"text": "1.5 Fast Trajectory Clustering using the Kernel Distance", "sentence_id": "s_89", "sentence_rank": "89", "paragraph_id": "p_24", "paragraph_rank": 24}, {"text": "1.6 Contributions", "sentence_id": "s_97", "sentence_rank": "97", "paragraph_id": "p_26", "paragraph_rank": 26}, {"text": "Chapter 2 Related Work", "sentence_id": "s_122", "sentence_rank": "122", "paragraph_id": "p_32", "paragraph_rank": 32}, {"text": "2.1 Overcoming Display Limitations", "sentence_id": "s_125", "sentence_rank": "125", "paragraph_id": "p_34", "paragraph_rank": 34}, {"text": "2.2 Scene Analysis and Image Saliency", "sentence_id": "s_137", "sentence_rank": "137", "paragraph_id": "p_36", "paragraph_rank": 36}, {"text": "2.3 Visual Data Analysis", "sentence_id": "s_166", "sentence_rank": "166", "paragraph_id": "p_42", "paragraph_rank": 42}, {"text": "2.4 Transfer Function Design", "sentence_id": "s_186", "sentence_rank": "186", "paragraph_id": "p_46", "paragraph_rank": 46}, {"text": "2.5 Visual Data Segmentation", "sentence_id": "s_219", "sentence_rank": "219", "paragraph_id": "p_50", "paragraph_rank": 50}, {"text": "2.5.1 Atlas-based Segmentation of Brain Images", "sentence_id": "s_271", "sentence_rank": "271", "paragraph_id": "p_55", "paragraph_rank": 55}, {"text": "2.5.2 Extracting 3D Surfaces from Scalar Fields", "sentence_id": "s_283", "sentence_rank": "283", "paragraph_id": "p_57", "paragraph_rank": 57}, {"text": "2.6 Clustering Moving Objects", "sentence_id": "s_293", "sentence_rank": "293", "paragraph_id": "p_59", "paragraph_rank": 59}, {"text": "2.7 Approximating Complex Distances", "sentence_id": "s_327", "sentence_rank": "327", "paragraph_id": "p_65", "paragraph_rank": 65}, {"text": "Chapter 3", "sentence_id": "s_348", "sentence_rank": "348", "paragraph_id": "p_69", "paragraph_rank": 69}, {"text": "Challenges", "sentence_id": "s_374", "sentence_rank": "374", "paragraph_id": "p_74", "paragraph_rank": 74}, {"text": "3.1 Overview", "sentence_id": "s_413", "sentence_rank": "413", "paragraph_id": "p_85", "paragraph_rank": 85}, {"text": "3.2 Sliding-Window Saliency", "sentence_id": "s_444", "sentence_rank": "444", "paragraph_id": "p_92", "paragraph_rank": 92}, {"text": "3.2.1 Traditional Image Saliency", "sentence_id": "s_449", "sentence_rank": "449", "paragraph_id": "p_94", "paragraph_rank": 94}, {"text": "3.2.2 Sliding Window Aggregation", "sentence_id": "s_468", "sentence_rank": "468", "paragraph_id": "p_98", "paragraph_rank": 98}, {"text": "3.3 Information Discovery", "sentence_id": "s_500", "sentence_rank": "500", "paragraph_id": "p_103", "paragraph_rank": 103}, {"text": "3.3.1 Image Region Descriptors", "sentence_id": "s_513", "sentence_rank": "513", "paragraph_id": "p_106", "paragraph_rank": 106}, {"text": "3.3.2 k-Nearest-Neighbors Anomaly Detection", "sentence_id": "s_532", "sentence_rank": "532", "paragraph_id": "p_111", "paragraph_rank": 111}, {"text": "3.4 Interactive Visualization", "sentence_id": "s_548", "sentence_rank": "548", "paragraph_id": "p_114", "paragraph_rank": 114}, {"text": "3.4.1 Visualizing the Detected Regions", "sentence_id": "s_555", "sentence_rank": "555", "paragraph_id": "p_118", "paragraph_rank": 118}, {"text": "3.4.2 Automatic Exploration", "sentence_id": "s_565", "sentence_rank": "565", "paragraph_id": "p_121", "paragraph_rank": 121}, {"text": "3.4.3 Interactive Refinement", "sentence_id": "s_572", "sentence_rank": "572", "paragraph_id": "p_123", "paragraph_rank": 123}, {"text": "3.5 Data Scalability", "sentence_id": "s_594", "sentence_rank": "594", "paragraph_id": "p_127", "paragraph_rank": 127}, {"text": "3.5.1 Out-of-core GPU Saliency Computation", "sentence_id": "s_597", "sentence_rank": "597", "paragraph_id": "p_129", "paragraph_rank": 129}, {"text": "3.5.2 Salient Regions Storage", "sentence_id": "s_617", "sentence_rank": "617", "paragraph_id": "p_135", "paragraph_rank": 135}, {"text": "3.5.3 Tiled Image Viewer", "sentence_id": "s_627", "sentence_rank": "627", "paragraph_id": "p_138", "paragraph_rank": 138}, {"text": "3.6 Results", "sentence_id": "s_646", "sentence_rank": "646", "paragraph_id": "p_140", "paragraph_rank": 140}, {"text": "3.6.1 Datasets", "sentence_id": "s_651", "sentence_rank": "651", "paragraph_id": "p_142", "paragraph_rank": 142}, {"text": "3.6.2 Evaluation", "sentence_id": "s_674", "sentence_rank": "674", "paragraph_id": "p_148", "paragraph_rank": 148}, {"text": "Chapter 4 Hierarchical Exploration of Volumes using Multilevel Segmentation of the Intensity-Gradient Histograms", "sentence_id": "s_711", "sentence_rank": "711", "paragraph_id": "p_156", "paragraph_rank": 156}, {"text": "4.1 Overview", "sentence_id": "s_770", "sentence_rank": "770", "paragraph_id": "p_176", "paragraph_rank": 176}, {"text": "4.2 Volume Segmentation by Normalized Cut on 2D Histograms", "sentence_id": "s_791", "sentence_rank": "791", "paragraph_id": "p_181", "paragraph_rank": 181}, {"text": "4.3 Hierarchical Exploration", "sentence_id": "s_820", "sentence_rank": "820", "paragraph_id": "p_185", "paragraph_rank": 185}, {"text": "4.3.1 Multilevel Segmentation Hierarchy", "sentence_id": "s_828", "sentence_rank": "828", "paragraph_id": "p_188", "paragraph_rank": 188}, {"text": "4.3.2 Information Content", "sentence_id": "s_844", "sentence_rank": "844", "paragraph_id": "p_192", "paragraph_rank": 192}, {"text": "4.3.3 Interactive Exploration", "sentence_id": "s_874", "sentence_rank": "874", "paragraph_id": "p_198", "paragraph_rank": 198}, {"text": "4.4 Results", "sentence_id": "s_905", "sentence_rank": "905", "paragraph_id": "p_202", "paragraph_rank": 202}, {"text": "4.5 Conclusions and Future Work", "sentence_id": "s_925", "sentence_rank": "925", "paragraph_id": "p_207", "paragraph_rank": 207}, {"text": "Chapter 5 Personalizing the Brain Atlas through Gene Expression Correlates 5.1 Introduction", "sentence_id": "s_936", "sentence_rank": "936", "paragraph_id": "p_209", "paragraph_rank": 209}, {"text": "5.2 Overview", "sentence_id": "s_963", "sentence_rank": "963", "paragraph_id": "p_218", "paragraph_rank": 218}, {"text": "5.3 Selecting Relevant Gene Expression Profiles", "sentence_id": "s_972", "sentence_rank": "972", "paragraph_id": "p_223", "paragraph_rank": 223}, {"text": "5.4 Extracting the Segmentation Surface from Gene Expression Profiles", "sentence_id": "s_985", "sentence_rank": "985", "paragraph_id": "p_228", "paragraph_rank": 228}, {"text": "5.4.1 Coherent Normal Vector Field", "sentence_id": "s_992", "sentence_rank": "992", "paragraph_id": "p_231", "paragraph_rank": 231}, {"text": "5.4.2 Extracting the Bounding Surface of the Gene Expressions", "sentence_id": "s_1003", "sentence_rank": "1003", "paragraph_id": "p_235", "paragraph_rank": 235}, {"text": "5.5 Personalizing the Reference Structure to the Gene Expression Bound- ary Surface", "sentence_id": "s_1007", "sentence_rank": "1007", "paragraph_id": "p_237", "paragraph_rank": 237}, {"text": "5.6 Results", "sentence_id": "s_1015", "sentence_rank": "1015", "paragraph_id": "p_241", "paragraph_rank": 241}, {"text": "5.6.1 Experimental Setup", "sentence_id": "s_1020", "sentence_rank": "1020", "paragraph_id": "p_243", "paragraph_rank": 243}, {"text": "5.6.2 Structures whose Gene Expression Surfaces largely agree with the Atlas", "sentence_id": "s_1026", "sentence_rank": "1026", "paragraph_id": "p_245", "paragraph_rank": 245}, {"text": "5.6.3 Structures with Small Gene Expression Regions", "sentence_id": "s_1044", "sentence_rank": "1044", "paragraph_id": "p_249", "paragraph_rank": 249}, {"text": "5.6.4 High Gene Expressions in Multiple Structures", "sentence_id": "s_1047", "sentence_rank": "1047", "paragraph_id": "p_251", "paragraph_rank": 251}, {"text": "5.7 Conclusions and Discussions", "sentence_id": "s_1052", "sentence_rank": "1052", "paragraph_id": "p_253", "paragraph_rank": 253}, {"text": "Chapter 6", "sentence_id": "s_1060", "sentence_rank": "1060", "paragraph_id": "p_255", "paragraph_rank": 255}, {"text": "6.1.1 Challenges", "sentence_id": "s_1071", "sentence_rank": "1071", "paragraph_id": "p_258", "paragraph_rank": 258}, {"text": "6.1.2 Contributions", "sentence_id": "s_1078", "sentence_rank": "1078", "paragraph_id": "p_261", "paragraph_rank": 261}, {"text": "6.2 Overview", "sentence_id": "s_1096", "sentence_rank": "1096", "paragraph_id": "p_266", "paragraph_rank": 266}, {"text": "6.3 Approximate Kernel Distance", "sentence_id": "s_1114", "sentence_rank": "1114", "paragraph_id": "p_269", "paragraph_rank": 269}, {"text": "6.3.1 Clustering Trajectories with the Kernel Distance", "sentence_id": "s_1132", "sentence_rank": "1132", "paragraph_id": "p_273", "paragraph_rank": 273}, {"text": "6.3.2 Evaluating the Approximate Kernel Distance", "sentence_id": "s_1143", "sentence_rank": "1143", "paragraph_id": "p_277", "paragraph_rank": 277}, {"text": "6.4 Clustering Feature Vectors with k-means", "sentence_id": "s_1154", "sentence_rank": "1154", "paragraph_id": "p_281", "paragraph_rank": 281}, {"text": "6.5 Shape and Spatial Clustering of Trajectories", "sentence_id": "s_1172", "sentence_rank": "1172", "paragraph_id": "p_288", "paragraph_rank": 288}, {"text": "6.6 Incremental and Stream Processing", "sentence_id": "s_1181", "sentence_rank": "1181", "paragraph_id": "p_291", "paragraph_rank": 291}, {"text": "6.7 Results with k-means Clustering", "sentence_id": "s_1192", "sentence_rank": "1192", "paragraph_id": "p_294", "paragraph_rank": 294}, {"text": "6.7.1 US Air Traffic Dataset", "sentence_id": "s_1206", "sentence_rank": "1206", "paragraph_id": "p_298", "paragraph_rank": 298}, {"text": "6.7.2 San Francisco Taxi Dataset", "sentence_id": "s_1218", "sentence_rank": "1218", "paragraph_id": "p_301", "paragraph_rank": 301}, {"text": "6.8 Clustering Feature Vectors with Community Detection", "sentence_id": "s_1246", "sentence_rank": "1246", "paragraph_id": "p_306", "paragraph_rank": 306}, {"text": "6.9 Results with Community Detection", "sentence_id": "s_1267", "sentence_rank": "1267", "paragraph_id": "p_312", "paragraph_rank": 312}, {"text": "6.9.1 Atlantic Hurricane Dataset", "sentence_id": "s_1271", "sentence_rank": "1271", "paragraph_id": "p_314", "paragraph_rank": 314}, {"text": "6.10 Comparison and Performance", "sentence_id": "s_1287", "sentence_rank": "1287", "paragraph_id": "p_318", "paragraph_rank": 318}, {"text": "6.10.1 Comparison with TRACLUS", "sentence_id": "s_1288", "sentence_rank": "1288", "paragraph_id": "p_319", "paragraph_rank": 319}, {"text": "6.10.2 Performance of Incrementally Clustering Taxi Trajectories", "sentence_id": "s_1299", "sentence_rank": "1299", "paragraph_id": "p_322", "paragraph_rank": 322}, {"text": "6.11 Conclusions and Discussions", "sentence_id": "s_1302", "sentence_rank": "1302", "paragraph_id": "p_324", "paragraph_rank": 324}, {"text": "Chapter 7 Conclusions and Future Work", "sentence_id": "s_1313", "sentence_rank": "1313", "paragraph_id": "p_327", "paragraph_rank": 327}, {"text": "7.1 Future work", "sentence_id": "s_1322", "sentence_rank": "1322", "paragraph_id": "p_329", "paragraph_rank": 329}, {"text": "7.2 Additional Contributions", "sentence_id": "s_1353", "sentence_rank": "1353", "paragraph_id": "p_335", "paragraph_rank": 335}], "scenes": [["3D_computer_graphics", "2D_computer_graphics"], ["3D_computer_graphics", "2D_computer_graphics"], ["Machine_learning"], ["3D_computer_graphics", "2D_computer_graphics"], ["Big_data"], ["The_Cancer_Genome_Atlas", "Allen_Brain_Atlas", "Sloan_Digital_Sky_Survey", "Karl_G._Jansky_Very_Large_Array", "Large_Synoptic_Survey_Telescope", "Internet", "Large_Hadron_Collider", "Moore's_law", "Genome_project"], ["Semantics", "Data_visualization"], ["3D_computer_graphics", "2D_computer_graphics"], ["Navigation"], ["Internet"], ["Hierarchy", "Image_segmentation"], ["2D_computer_graphics"], ["Brain_atlas", "Gene_expression"], ["Image_segmentation"], ["3D_computer_graphics"], ["Trajectory", "Cluster_analysis"], ["San_Francisco"], ["Data_mining", "3D_computer_graphics"], ["Graphics_processing_unit", "3D_computer_graphics", "2D_computer_graphics", "Scalability"], ["Data_visualization", "User_(computing)"], ["3D_computer_graphics"], ["Viola"], ["Transfer_function"], ["Massachusetts", "Zhou_dynasty"], ["Mixture_model", "Cartesian_coordinate_system", "User_(computing)"], ["User_(computing)"], ["3D_computer_graphics", "Cartesian_coordinate_system"], ["3D_computer_graphics", "Massachusetts", "Cartesian_coordinate_system"], ["Cartesian_coordinate_system", "Weir", "Image_segmentation", "Massachusetts"], ["Graphics_processing_unit", "Cartesian_coordinate_system"], ["Human_brain", "Image_segmentation"], ["3D_computer_graphics", "Brain_atlas"], ["Scalar_(physics)", "Stereoscopy"], ["Tang_dynasty"], ["Cluster_analysis"], ["Tang_dynasty"], ["Global_Positioning_System", "Zhou_dynasty"], ["Complex_number"], ["Puroresu"], ["Earth_mover's_distance", "Earth", "Hungarian_algorithm", "Lp_space", "Taxicab_geometry"], ["Navigation"], ["Gigapan"], ["Gigapixel_image", "Pixel"], ["Canon_Inc.", "Liquid-crystal_display", "Dell", "Scalability", "Nikon", "Single-lens_reflex_camera", "Sony", "Apple_Inc."], ["High_School_Musical:_El_Desaf\u00edo", "Scalability"], ["Scalability"], ["Classical_music", "User_(computing)"], ["Folk_music", "Gaussian_function", "Scalability"], ["Scalability"], ["Scalability"], ["Scalability"], ["Folk_music"], ["Blue", "Yellow", "France", "Facebook", "Color_blindness", "Multiscale_modeling"], ["Difference_of_Gaussians", "Gaussian_function"], ["Difference_of_Gaussians"], ["Visual_system"], ["Region"], ["HSL_and_HSV", "RGB_color_model", "Lab_color_space"], ["Euclidean_space", "MPEG-7", "International_Organization_for_Standardization"], ["Region", "Uttar_Pradesh"], ["OpenCV", "Linear_search", "K-d_tree"], ["Human\u2013computer_interaction"], ["Graphics_processing_unit"], ["Graphics_processing_unit", "Difference_of_Gaussians"], ["Difference_of_Gaussians", "Normal_distribution", "Gaussian_function"], ["Graphics_processing_unit"], ["Graphics_processing_unit"], ["Graphics_processing_unit", "Nvidia"], ["Principal_component_analysis"], ["Graphics_processing_unit", "RGB_color_model"], ["Intel", "GeForce_200_series", "Graphics_processing_unit", "GeForce", "Linux", "Central_processing_unit", "Random-access_memory"], ["Point-and-shoot_camera", "Unincorporated_area", "User_(computing)", "Gigapan", "Grimsel_Pass", "Internet"], ["Royal_Gorge_Bridge", "Oberhasli", "Canton_of_Bern", "Rh\u00f4ne", "Grimsel_Pass", "Switzerland", "Valais"], ["Arkansas_River", "Royal_Gorge_Bridge", "Cactus", "Ca\u00f1on_City,_Colorado", "Royal_Gorge_Route_Railroad"], ["Arizona"], ["Sequoia_National_Park"], ["Switzerland", "Car", "Thumbnail", "Grimsel_Pass"], ["Arkansas_River", "Royal_Gorge_Bridge", "Thumbnail"], ["Thumbnail"], ["Thumbnail"], ["Hierarchy", "Image_segmentation"], ["Semantics"], ["ImageVis3D", "Voreen", "2D_computer_graphics", "VisIt", "Histogram"], ["User_(computing)"], ["3D_computer_graphics", "2D_computer_graphics"], ["User_(computing)"], ["ImageVis3D"], ["Normal_distribution"], ["User_(computing)"], ["3D_computer_graphics"], ["3D_computer_graphics", "2D_computer_graphics", "User_(computing)"], ["Semantics"], ["User_(computing)"], ["2D_computer_graphics", "Normalization_(statistics)", "Image_segmentation", "Histogram"], ["3D_computer_graphics", "2D_computer_graphics", "User_(computing)"], ["3D_computer_graphics", "2D_computer_graphics"], ["Hierarchy"], ["Image_segmentation"], ["User_(computing)"], ["Kullback\u2013Leibler_divergence", "Entropy_(information_theory)"], ["Claude_Shannon", "Entropy_(information_theory)", "Victoria_and_Albert_Museum"], ["Kullback\u2013Leibler_divergence"], ["Interactivity"], ["User_(computing)"], ["2D_computer_graphics", "MATLAB", "Graphics_processing_unit", "Xeon", "Experiment", "CUDA", "GeForce", "Linux", "Software_development_kit", "Qt_(software)"], ["Brain_atlas", "Gene_expression"], ["Neurology", "Fluorescence_in_situ_hybridization"], ["Neurology"], ["Human_brain", "Mouse", "Allen_Brain_Atlas"], ["3D_computer_graphics"], ["Out-of-order_execution", "Gene_expression"], ["Voxel"], ["Gene_expression", "Surface"], ["Coherent_(operating_system)", "Normal_(geometry)"], ["Normal_(geometry)"], ["Gene", "Surface"], ["Gene_expression"], ["Foreach_loop"], ["General-purpose_computing_on_graphics_processing_units"], ["Foreach_loop"], ["Python_(programming_language)", "GeForce_200_series", "VTK", "Hertz", "Graphics_processing_unit", "Xeon", "GeForce", "Linux", "Central_processing_unit", "NumPy"], ["Gene_expression"], ["Alar_plate", "FOXP1", "PDE10A"], ["Alar_plate", "GBX2", "Anatomical_terms_of_location", "PROX1", "NTNG1"], ["High_school", "Forebrain"], ["Gene_expression"], ["Gene"], ["Distance", "Linux_kernel", "Computer_cluster"], ["Radio-frequency_identification", "GPS_signals"], ["Big_O_notation"], ["Gaussian_function", "Euclidean_distance", "PP_(complexity)", "K\u00b7p_perturbation_theory"], ["Fourier_transform", "K\u00b7p_perturbation_theory"], ["Gaussian_function", "Fourier_transform"], ["Cluster_analysis"], ["Euclidean_space"], ["Euclidean_space", "Euclidean_distance"], ["Spacetime"], ["Evaluation"], ["Computer_cluster"], ["Foreach_loop"], ["Principal_component_analysis"], ["Supreme_Headquarters_Allied_Powers_Europe", "Computer_cluster"], ["Village"], ["Piper_PT-1"], ["Contiguous_United_States"], ["Python_(programming_language)", "Xeon", "Hertz", "Personal_computer", "Computing_platform", "Linux", "United_Kingdom", "NumPy"], ["Taxicab", "San_Francisco", "San_Francisco_International_Airport", "Southern_United_States", "Oakland,_California", "Western_United_States", "San_Mateo_County,_California", "Global_Positioning_System", "University_of_California", "Northeastern_United_States"], ["United_States", "Air_traffic_control"], ["Germany", "United_States", "Global_Positioning_System"], ["Southwestern_United_States", "San_Francisco", "Miami", "North_Dallas", "West_Coast_of_the_United_States", "Denver,_Indiana", "Southern_United_States", "East_Coast_of_the_United_States", "Washington,_D.C.", "Boston", "Pacific_Northwest", "Atlanta", "Seattle", "North_America", "Northeastern_United_States"], ["Taxicab", "San_Francisco"], ["Global_Positioning_System", "San_Francisco"], ["South_San_Francisco,_California", "San_Francisco", "Oakland,_California", "San_Mateo_County,_California", "Central_United_States", "University_of_California", "Northeastern_United_States"], ["Computer_cluster", "West_Coast_of_the_United_States", "San_Francisco_International_Airport", "San_Francisco", "Principal_component_analysis"], ["Foreach_loop"], ["Computer_cluster", "Unincorporated_area"], ["Extended_play"], ["Unincorporated_area"], ["Atlantic_Ocean", "Atlantic_hurricane"], ["Atlantic_hurricane"], ["Atlantic_Ocean", "National_Hurricane_Center"], ["East_Coast_of_the_United_States", "Atlantic_Ocean", "Gulf_of_Mexico", "North_America", "Southern_United_States"], ["Tropical_cyclone", "Air_traffic_control"], ["Cluster_analysis"], ["3D_computer_graphics"], ["Brain", "Electroencephalography"], ["Radial_basis_function", "Carl_Friedrich_Gauss", "Geospatial_analysis", "Euclidean_distance", "Gaussian_function"], ["Graphics_processing_unit", "3D_computer_graphics", "2D_computer_graphics", "Poisson_distribution"]], "characters": [{"name": "Blue", "offsets": [46114], "paragraph_occurrences": [95], "sentence_occurrences": [458], "affiliation": "light", "frequency": 1, "id": "Blue"}, {"name": "Interactivity", "offsets": [85415], "paragraph_occurrences": [198], "sentence_occurrences": [874], "affiliation": "light", "frequency": 1, "id": "Interactivity"}, {"name": "San Francisco", "offsets": [12843, 120396, 120554, 120879, 121007, 122530, 122690, 122777, 123753, 124359, 124449], "paragraph_occurrences": [25, 297, 297, 297, 297, 300, 301, 302, 303, 304, 304], "sentence_occurrences": [96, 1197, 1199, 1202, 1204, 1217, 1218, 1219, 1230, 1239, 1240], "affiliation": "light", "frequency": 11, "id": "San_Francisco"}, {"name": "Tang dynasty", "offsets": [29763, 31577], "paragraph_occurrences": [58, 63], "sentence_occurrences": [288, 318], "affiliation": "light", "frequency": 2, "id": "Tang_dynasty"}, {"name": "Taxi", "offsets": [120410, 122704], "paragraph_occurrences": [297, 301], "sentence_occurrences": [1197, 1218], "affiliation": "light", "frequency": 2, "id": "Taxicab"}, {"name": "GeForce 200 series", "offsets": [64513, 101902], "paragraph_occurrences": [141, 244], "sentence_occurrences": [650, 1024], "affiliation": "light", "frequency": 2, "id": "GeForce_200_series"}, {"name": "Big O notation", "offsets": [107425], "paragraph_occurrences": [259], "sentence_occurrences": [1074], "affiliation": "light", "frequency": 1, "id": "Big_O_notation"}, {"name": "Image segmentation", "offsets": [9094, 10165, 27364, 28431, 69176, 77190, 80912], "paragraph_occurrences": [19, 22, 53, 55, 156, 181, 188], "sentence_occurrences": [70, 78, 254, 271, 711, 791, 828], "affiliation": "light", "frequency": 7, "id": "Image_segmentation"}, {"name": "Principal component analysis", "offsets": [62564, 62594, 116716, 124085], "paragraph_occurrences": [137, 137, 284, 304], "sentence_occurrences": [624, 624, 1163, 1235], "affiliation": "light", "frequency": 4, "id": "Principal_component_analysis"}, {"name": "High School Musical: El Desafio", "offsets": [38084], "paragraph_occurrences": [77], "sentence_occurrences": [383], "affiliation": "light", "frequency": 1, "id": "High_School_Musical:_El_Desaf\u00edo"}, {"name": "Global Positioning System", "offsets": [31766, 120728, 121463, 122848], "paragraph_occurrences": [64, 297, 299, 302], "sentence_occurrences": [324, 1201, 1208, 1220], "affiliation": "light", "frequency": 4, "id": "Global_Positioning_System"}, {"name": "The Internet", "offsets": [4397, 9028, 64992], "paragraph_occurrences": [9, 18, 143], "sentence_occurrences": [30, 69, 656], "affiliation": "light", "frequency": 3, "id": "Internet"}, {"name": "National Hurricane Center", "offsets": [127677], "paragraph_occurrences": [315], "sentence_occurrences": [1275], "affiliation": "light", "frequency": 1, "id": "National_Hurricane_Center"}, {"name": "Pixel", "offsets": [35908], "paragraph_occurrences": [72], "sentence_occurrences": [366], "affiliation": "light", "frequency": 1, "id": "Pixel"}, {"name": "General-purpose computing on graphics processing units", "offsets": [100539], "paragraph_occurrences": [239], "sentence_occurrences": [1011], "affiliation": "light", "frequency": 1, "id": "General-purpose_computing_on_graphics_processing_units"}, {"name": "Arkansas River", "offsets": [66039, 67305], "paragraph_occurrences": [145, 151], "sentence_occurrences": [667, 686], "affiliation": "light", "frequency": 2, "id": "Arkansas_River"}, {"name": "PROX1", "offsets": [103142], "paragraph_occurrences": [247], "sentence_occurrences": [1037], "affiliation": "light", "frequency": 1, "id": "PROX1"}, {"name": "Atlantic Ocean", "offsets": [127021, 127434, 128652, 128426, 128585], "paragraph_occurrences": [313, 315, 317, 317, 317], "sentence_occurrences": [1268, 1272, 1284, 1283, 1284], "affiliation": "light", "frequency": 5, "id": "Atlantic_Ocean"}, {"name": "Graphics processing unit", "offsets": [14001, 14248, 28403, 59896, 60128, 60868, 60986, 61250, 61462, 61898, 62924, 63103, 64521, 59927, 89077, 101910, 136994], "paragraph_occurrences": [29, 29, 54, 129, 130, 132, 132, 133, 133, 134, 139, 139, 141, 130, 204, 244, 336], "sentence_occurrences": [105, 108, 270, 597, 599, 606, 608, 611, 613, 616, 628, 630, 650, 598, 913, 1024, 1359], "affiliation": "light", "frequency": 17, "id": "Graphics_processing_unit"}, {"name": "High school", "offsets": [103237], "paragraph_occurrences": [248], "sentence_occurrences": [1039], "affiliation": "light", "frequency": 1, "id": "High_school"}, {"name": "Weir", "offsets": [27934], "paragraph_occurrences": [53], "sentence_occurrences": [267], "affiliation": "light", "frequency": 1, "id": "Weir"}, {"name": "User", "offsets": [15010, 24228, 24954, 39310, 65001, 72341, 73473, 75102, 75940, 76751, 77429, 81160, 86217, 86334], "paragraph_occurrences": [30, 48, 49, 80, 143, 164, 168, 174, 178, 180, 182, 189, 200, 200], "sentence_occurrences": [112, 210, 217, 394, 656, 735, 749, 767, 778, 785, 793, 830, 883, 884], "affiliation": "light", "frequency": 14, "id": "User_(computing)"}, {"name": "Computer cluster", "offsets": [105652, 115754, 117670, 123981, 124888], "paragraph_occurrences": [256, 281, 288, 304, 306], "sentence_occurrences": [1061, 1154, 1172, 1234, 1246], "affiliation": "light", "frequency": 5, "id": "Computer_cluster"}, {"name": "Facebook", "offsets": [46126], "paragraph_occurrences": [95], "sentence_occurrences": [458], "affiliation": "light", "frequency": 1, "id": "Facebook"}, {"name": "Large Hadron Collider", "offsets": [4443], "paragraph_occurrences": [9], "sentence_occurrences": [31], "affiliation": "light", "frequency": 1, "id": "Large_Hadron_Collider"}, {"name": "Apple Inc.", "offsets": [37788], "paragraph_occurrences": [76], "sentence_occurrences": [380], "affiliation": "light", "frequency": 1, "id": "Apple_Inc."}, {"name": "Semantics", "offsets": [6807, 71023, 76616], "paragraph_occurrences": [13, 160, 179], "sentence_occurrences": [51, 724, 784], "affiliation": "light", "frequency": 3, "id": "Semantics"}, {"name": "CUDA", "offsets": [88706], "paragraph_occurrences": [204], "sentence_occurrences": [910], "affiliation": "light", "frequency": 1, "id": "CUDA"}, {"name": "Gulf of Mexico", "offsets": [128502], "paragraph_occurrences": [317], "sentence_occurrences": [1283], "affiliation": "light", "frequency": 1, "id": "Gulf_of_Mexico"}, {"name": "Oberhasli", "offsets": [65454], "paragraph_occurrences": [144], "sentence_occurrences": [661], "affiliation": "light", "frequency": 1, "id": "Oberhasli"}, {"name": "South San Francisco", "offsets": [123928], "paragraph_occurrences": [303], "sentence_occurrences": [1232], "affiliation": "light", "frequency": 1, "id": "South_San_Francisco,_California"}, {"name": "Atlanta", "offsets": [122586], "paragraph_occurrences": [300], "sentence_occurrences": [1217], "affiliation": "light", "frequency": 1, "id": "Atlanta"}, {"name": "Automobile", "offsets": [66998], "paragraph_occurrences": [150], "sentence_occurrences": [682], "affiliation": "light", "frequency": 1, "id": "Car"}, {"name": "Region", "offsets": [51855, 54458], "paragraph_occurrences": [106, 112], "sentence_occurrences": [513, 535], "affiliation": "light", "frequency": 2, "id": "Region"}, {"name": "United States", "offsets": [121250, 121371], "paragraph_occurrences": [298, 299], "sentence_occurrences": [1206, 1207], "affiliation": "light", "frequency": 2, "id": "United_States"}, {"name": "Fluorescence in situ hybridization", "offsets": [92376], "paragraph_occurrences": [211], "sentence_occurrences": [942], "affiliation": "light", "frequency": 1, "id": "Fluorescence_in_situ_hybridization"}, {"name": "San Mateo County", "offsets": [120677, 123862], "paragraph_occurrences": [297, 303], "sentence_occurrences": [1200, 1231], "affiliation": "light", "frequency": 2, "id": "San_Mateo_County,_California"}, {"name": "Visual system", "offsets": [49661], "paragraph_occurrences": [101], "sentence_occurrences": [493], "affiliation": "light", "frequency": 1, "id": "Visual_system"}, {"name": "Prosencephalon", "offsets": [103247], "paragraph_occurrences": [248], "sentence_occurrences": [1039], "affiliation": "light", "frequency": 1, "id": "Forebrain"}, {"name": "Euclidean space", "offsets": [53838, 113350, 113790], "paragraph_occurrences": [110, 274, 275], "sentence_occurrences": [529, 1133, 1136], "affiliation": "light", "frequency": 3, "id": "Euclidean_space"}, {"name": "United Kingdom", "offsets": [120176], "paragraph_occurrences": [296], "sentence_occurrences": [1195], "affiliation": "light", "frequency": 1, "id": "United_Kingdom"}, {"name": "Qt", "offsets": [88695], "paragraph_occurrences": [204], "sentence_occurrences": [910], "affiliation": "light", "frequency": 1, "id": "Qt_(software)"}, {"name": "2D computer graphics", "offsets": [727, 2342, 3483, 7247, 9388, 13906, 14123, 71764, 72595, 72633, 75657, 75844, 76181, 77224, 77396, 77472, 79298, 79560, 79819, 88621, 136657], "paragraph_occurrences": [2, 5, 7, 14, 20, 29, 29, 162, 165, 165, 178, 178, 178, 181, 182, 182, 184, 184, 184, 204, 336], "sentence_occurrences": [6, 14, 24, 54, 72, 105, 107, 729, 738, 739, 775, 778, 780, 791, 793, 794, 811, 813, 815, 909, 1356], "affiliation": "light", "frequency": 21, "id": "2D_computer_graphics"}, {"name": "Unincorporated area", "offsets": [64902, 124920, 126972], "paragraph_occurrences": [143, 306, 312], "sentence_occurrences": [655, 1246, 1267], "affiliation": "light", "frequency": 3, "id": "Unincorporated_area"}, {"name": "Human brain", "offsets": [28447, 94193, 94647], "paragraph_occurrences": [55, 214, 214], "sentence_occurrences": [271, 953, 956], "affiliation": "light", "frequency": 3, "id": "Human_brain"}, {"name": "Yellow", "offsets": [46119], "paragraph_occurrences": [95], "sentence_occurrences": [458], "affiliation": "light", "frequency": 1, "id": "Yellow"}, {"name": "Data mining", "offsets": [13098], "paragraph_occurrences": [28], "sentence_occurrences": [99], "affiliation": "light", "frequency": 1, "id": "Data_mining"}, {"name": "Gigapan", "offsets": [34489, 64755, 64938, 65244], "paragraph_occurrences": [71, 143, 143, 143], "sentence_occurrences": [352, 654, 656, 659], "affiliation": "light", "frequency": 4, "id": "Gigapan"}, {"name": "Experimentalist", "offsets": [88312], "paragraph_occurrences": [204], "sentence_occurrences": [907], "affiliation": "light", "frequency": 1, "id": "Experiment"}, {"name": "Machine learning", "offsets": [2723], "paragraph_occurrences": [6], "sentence_occurrences": [16], "affiliation": "light", "frequency": 1, "id": "Machine_learning"}, {"name": "Stereoscopy", "offsets": [29309], "paragraph_occurrences": [57], "sentence_occurrences": [283], "affiliation": "light", "frequency": 1, "id": "Stereoscopy"}, {"name": "Mouse", "offsets": [94187, 94641], "paragraph_occurrences": [214, 214], "sentence_occurrences": [953, 956], "affiliation": "light", "frequency": 2, "id": "Mouse"}, {"name": "Atlantic tropical cyclone", "offsets": [127153, 127365], "paragraph_occurrences": [313, 314], "sentence_occurrences": [1269, 1271], "affiliation": "light", "frequency": 2, "id": "Atlantic_hurricane"}, {"name": "FOXP1", "offsets": [102594], "paragraph_occurrences": [246], "sentence_occurrences": [1031], "affiliation": "light", "frequency": 1, "id": "FOXP1"}, {"name": "Voreen", "offsets": [71909], "paragraph_occurrences": [162], "sentence_occurrences": [730], "affiliation": "light", "frequency": 1, "id": "Voreen"}, {"name": "Data visualization", "offsets": [6828, 14764], "paragraph_occurrences": [13, 30], "sentence_occurrences": [51, 111], "affiliation": "light", "frequency": 2, "id": "Data_visualization"}, {"name": "Oakland", "offsets": [120588, 123787], "paragraph_occurrences": [297, 303], "sentence_occurrences": [1199, 1230], "affiliation": "light", "frequency": 2, "id": "Oakland,_California"}, {"name": "France", "offsets": [46106], "paragraph_occurrences": [95], "sentence_occurrences": [458], "affiliation": "light", "frequency": 1, "id": "France"}, {"name": "Big data", "offsets": [4231], "paragraph_occurrences": [8], "sentence_occurrences": [29], "affiliation": "light", "frequency": 1, "id": "Big_data"}, {"name": "Very Large Array", "offsets": [4806, 4833], "paragraph_occurrences": [9, 9], "sentence_occurrences": [33, 33], "affiliation": "light", "frequency": 2, "id": "Karl_G._Jansky_Very_Large_Array"}, {"name": "Surface", "offsets": [97728, 99691], "paragraph_occurrences": [228, 235], "sentence_occurrences": [985, 1003], "affiliation": "light", "frequency": 2, "id": "Surface"}, {"name": "Canton of Valais", "offsets": [65429], "paragraph_occurrences": [144], "sentence_occurrences": [661], "affiliation": "light", "frequency": 1, "id": "Valais"}, {"name": "Thumbnail", "offsets": [66960, 67064, 67108, 67552, 67645, 67727, 68049], "paragraph_occurrences": [150, 150, 150, 151, 152, 152, 153], "sentence_occurrences": [681, 683, 684, 688, 690, 691, 697], "affiliation": "light", "frequency": 7, "id": "Thumbnail"}, {"name": "Contiguous United States", "offsets": [119799], "paragraph_occurrences": [295], "sentence_occurrences": [1193], "affiliation": "light", "frequency": 1, "id": "Contiguous_United_States"}, {"name": "East Coast of the United States", "offsets": [122271, 122679, 128360, 128624], "paragraph_occurrences": [300, 300, 317, 317], "sentence_occurrences": [1216, 1217, 1282, 1284], "affiliation": "light", "frequency": 4, "id": "East_Coast_of_the_United_States"}, {"name": "Southwestern United States", "offsets": [122322], "paragraph_occurrences": [300], "sentence_occurrences": [1216], "affiliation": "light", "frequency": 1, "id": "Southwestern_United_States"}, {"name": "Arizona", "offsets": [66157], "paragraph_occurrences": [146], "sentence_occurrences": [668], "affiliation": "light", "frequency": 1, "id": "Arizona"}, {"name": "Euclidean distance", "offsets": [112010, 113586, 135181], "paragraph_occurrences": [270, 275, 333], "sentence_occurrences": [1120, 1135, 1344], "affiliation": "light", "frequency": 3, "id": "Euclidean_distance"}, {"name": "Victoria and Albert Museum", "offsets": [83952], "paragraph_occurrences": [195], "sentence_occurrences": [860], "affiliation": "light", "frequency": 1, "id": "Victoria_and_Albert_Museum"}, {"name": "Kullback\u2013Leibler divergence", "offsets": [83564, 84436], "paragraph_occurrences": [194, 196], "sentence_occurrences": [856, 865], "affiliation": "light", "frequency": 2, "id": "Kullback\u2013Leibler_divergence"}, {"name": "PP", "offsets": [111950], "paragraph_occurrences": [270], "sentence_occurrences": [1120], "affiliation": "light", "frequency": 1, "id": "PP_(complexity)"}, {"name": "Large Synoptic Survey Telescope", "offsets": [4678], "paragraph_occurrences": [9], "sentence_occurrences": [32], "affiliation": "light", "frequency": 1, "id": "Large_Synoptic_Survey_Telescope"}, {"name": "Massachusetts", "offsets": [23610, 25910, 26077, 27207], "paragraph_occurrences": [47, 52, 52, 53], "sentence_occurrences": [202, 230, 233, 252], "affiliation": "light", "frequency": 4, "id": "Massachusetts"}, {"name": "Village", "offsets": [118210], "paragraph_occurrences": [290], "sentence_occurrences": [1179], "affiliation": "light", "frequency": 1, "id": "Village"}, {"name": "Sony Broadcast & Professional Research Laboratories", "offsets": [37917], "paragraph_occurrences": [76], "sentence_occurrences": [380], "affiliation": "light", "frequency": 1, "id": "Sony"}, {"name": "Software development kit", "offsets": [88718], "paragraph_occurrences": [204], "sentence_occurrences": [910], "affiliation": "light", "frequency": 1, "id": "Software_development_kit"}, {"name": "North America", "offsets": [122219, 128248, 128354, 128618], "paragraph_occurrences": [300, 317, 317, 317], "sentence_occurrences": [1216, 1281, 1282, 1284], "affiliation": "light", "frequency": 4, "id": "North_America"}, {"name": "Python", "offsets": [101640, 120245], "paragraph_occurrences": [244, 296], "sentence_occurrences": [1021, 1196], "affiliation": "light", "frequency": 2, "id": "Python_(programming_language)"}, {"name": "Hungarian algorithm", "offsets": [33463], "paragraph_occurrences": [68], "sentence_occurrences": [340], "affiliation": "light", "frequency": 1, "id": "Hungarian_algorithm"}, {"name": "Foreach loop", "offsets": [100346, 101076, 116245, 124661], "paragraph_occurrences": [238, 242, 283, 305], "sentence_occurrences": [1009, 1016, 1158, 1242], "affiliation": "light", "frequency": 4, "id": "Foreach_loop"}, {"name": "Single-lens reflex camera", "offsets": [37872], "paragraph_occurrences": [76], "sentence_occurrences": [380], "affiliation": "light", "frequency": 1, "id": "Single-lens_reflex_camera"}, {"name": "Air traffic control", "offsets": [121253, 129223], "paragraph_occurrences": [298, 320], "sentence_occurrences": [1206, 1291], "affiliation": "light", "frequency": 2, "id": "Air_traffic_control"}, {"name": "Radial basis function", "offsets": [135382], "paragraph_occurrences": [333], "sentence_occurrences": [1345], "affiliation": "light", "frequency": 1, "id": "Radial_basis_function"}, {"name": "Spacetime", "offsets": [114175], "paragraph_occurrences": [276], "sentence_occurrences": [1140], "affiliation": "light", "frequency": 1, "id": "Spacetime"}, {"name": "University of California", "offsets": [120600, 123799], "paragraph_occurrences": [297, 303], "sentence_occurrences": [1199, 1230], "affiliation": "light", "frequency": 2, "id": "University_of_California"}, {"name": "NTNG1", "offsets": [103174], "paragraph_occurrences": [247], "sentence_occurrences": [1038], "affiliation": "light", "frequency": 1, "id": "NTNG1"}, {"name": "Carl Friedrich Gauss", "offsets": [135347], "paragraph_occurrences": [333], "sentence_occurrences": [1345], "affiliation": "light", "frequency": 1, "id": "Carl_Friedrich_Gauss"}, {"name": "Difference of Gaussians", "offsets": [46426, 46451, 46498, 46533, 46643, 46836, 48323, 60001, 60026, 60418, 60583], "paragraph_occurrences": [97, 97, 97, 97, 97, 97, 99, 130, 130, 131, 131], "sentence_occurrences": [461, 461, 462, 463, 464, 466, 480, 599, 599, 603, 604], "affiliation": "light", "frequency": 11, "id": "Difference_of_Gaussians"}, {"name": "Tropical cyclone", "offsets": [129194], "paragraph_occurrences": [320], "sentence_occurrences": [1291], "affiliation": "light", "frequency": 1, "id": "Tropical_cyclone"}, {"name": "Cluster analysis", "offsets": [11423, 30054, 113197, 129798], "paragraph_occurrences": [24, 59, 273, 322], "sentence_occurrences": [89, 293, 1132, 1299], "affiliation": "light", "frequency": 4, "id": "Cluster_analysis"}, {"name": "Electroencephalography", "offsets": [134786], "paragraph_occurrences": [332], "sentence_occurrences": [1341], "affiliation": "light", "frequency": 1, "id": "Electroencephalography"}, {"name": "Hierarchy", "offsets": [9041, 69123, 80161], "paragraph_occurrences": [19, 156, 185], "sentence_occurrences": [70, 711, 820], "affiliation": "light", "frequency": 3, "id": "Hierarchy"}, {"name": "NumPy", "offsets": [101719, 120260], "paragraph_occurrences": [244, 296], "sentence_occurrences": [1022, 1196], "affiliation": "light", "frequency": 2, "id": "NumPy"}, {"name": "Western United States", "offsets": [120999], "paragraph_occurrences": [297], "sentence_occurrences": [1204], "affiliation": "light", "frequency": 1, "id": "Western_United_States"}, {"name": "Computing platform", "offsets": [120073], "paragraph_occurrences": [296], "sentence_occurrences": [1195], "affiliation": "light", "frequency": 1, "id": "Computing_platform"}, {"name": "Washington, D.C.", "offsets": [122647], "paragraph_occurrences": [300], "sentence_occurrences": [1217], "affiliation": "light", "frequency": 1, "id": "Washington,_D.C."}, {"name": "Central United States", "offsets": [123916], "paragraph_occurrences": [303], "sentence_occurrences": [1232], "affiliation": "light", "frequency": 1, "id": "Central_United_States"}, {"name": "Piper PT-1", "offsets": [119379, 119485], "paragraph_occurrences": [293, 293], "sentence_occurrences": [1188, 1189], "affiliation": "light", "frequency": 2, "id": "Piper_PT-1"}, {"name": "Out-of-order execution", "offsets": [96300], "paragraph_occurrences": [223], "sentence_occurrences": [972], "affiliation": "light", "frequency": 1, "id": "Out-of-order_execution"}, {"name": "Gaussian function", "offsets": [42154, 46337, 60320, 111600, 112971, 135156], "paragraph_occurrences": [88, 97, 131, 270, 272, 333], "sentence_occurrences": [423, 461, 601, 1118, 1129, 1344], "affiliation": "light", "frequency": 6, "id": "Gaussian_function"}, {"name": "Double-sided RAM", "offsets": [64485], "paragraph_occurrences": [141], "sentence_occurrences": [650], "affiliation": "light", "frequency": 1, "id": "Random-access_memory"}, {"name": "Complex number", "offsets": [32041], "paragraph_occurrences": [65], "sentence_occurrences": [327], "affiliation": "light", "frequency": 1, "id": "Complex_number"}, {"name": "Earth mover's distance", "offsets": [33194, 33216, 33221, 33574, 33686, 33874, 33986], "paragraph_occurrences": [68, 68, 68, 68, 68, 68, 68], "sentence_occurrences": [338, 338, 338, 342, 343, 345, 347], "affiliation": "light", "frequency": 7, "id": "Earth_mover's_distance"}, {"name": "k-d tree", "offsets": [55397], "paragraph_occurrences": [113], "sentence_occurrences": [545], "affiliation": "light", "frequency": 1, "id": "K-d_tree"}, {"name": "Hertz", "offsets": [101872, 120156], "paragraph_occurrences": [244, 296], "sentence_occurrences": [1024, 1195], "affiliation": "light", "frequency": 2, "id": "Hertz"}, {"name": "OpenCV", "offsets": [55450], "paragraph_occurrences": [113], "sentence_occurrences": [545], "affiliation": "light", "frequency": 1, "id": "OpenCV"}, {"name": "Coherent", "offsets": [98344], "paragraph_occurrences": [231], "sentence_occurrences": [992], "affiliation": "light", "frequency": 1, "id": "Coherent_(operating_system)"}, {"name": "Brain atlas", "offsets": [10008, 28534, 91372], "paragraph_occurrences": [21, 56, 209], "sentence_occurrences": [77, 272, 936], "affiliation": "light", "frequency": 3, "id": "Brain_atlas"}, {"name": "Ca\u00f1on City", "offsets": [65809], "paragraph_occurrences": [145], "sentence_occurrences": [665], "affiliation": "light", "frequency": 1, "id": "Ca\u00f1on_City,_Colorado"}, {"name": "Mixture model", "offsets": [24572], "paragraph_occurrences": [48], "sentence_occurrences": [214], "affiliation": "light", "frequency": 1, "id": "Mixture_model"}, {"name": "Histogram", "offsets": [71786, 77227], "paragraph_occurrences": [162, 181], "sentence_occurrences": [729, 791], "affiliation": "light", "frequency": 2, "id": "Histogram"}, {"name": "Evaluation", "offsets": [114521], "paragraph_occurrences": [277], "sentence_occurrences": [1143], "affiliation": "light", "frequency": 1, "id": "Evaluation"}, {"name": "k\u00b7p perturbation theory", "offsets": [111617, 112604], "paragraph_occurrences": [270, 271], "sentence_occurrences": [1118, 1125], "affiliation": "light", "frequency": 2, "id": "K\u00b7p_perturbation_theory"}, {"name": "Cartesian coordinate system", "offsets": [24061, 24148, 24281, 25078, 25318, 25868, 27165, 28237], "paragraph_occurrences": [48, 48, 48, 51, 51, 52, 53, 54], "sentence_occurrences": [208, 210, 211, 220, 223, 229, 251, 270], "affiliation": "light", "frequency": 8, "id": "Cartesian_coordinate_system"}, {"name": "GBX2", "offsets": [103184], "paragraph_occurrences": [247], "sentence_occurrences": [1038], "affiliation": "light", "frequency": 1, "id": "GBX2"}, {"name": "Geospatial analysis", "offsets": [135020], "paragraph_occurrences": [333], "sentence_occurrences": [1343], "affiliation": "light", "frequency": 1, "id": "Geospatial_analysis"}, {"name": "Taxicab geometry", "offsets": [33613], "paragraph_occurrences": [68], "sentence_occurrences": [342], "affiliation": "light", "frequency": 1, "id": "Taxicab_geometry"}, {"name": "Uttar Pradesh", "offsets": [54318], "paragraph_occurrences": [112], "sentence_occurrences": [534], "affiliation": "light", "frequency": 1, "id": "Uttar_Pradesh"}, {"name": "Liquid-crystal display", "offsets": [37618], "paragraph_occurrences": [76], "sentence_occurrences": [379], "affiliation": "light", "frequency": 1, "id": "Liquid-crystal_display"}, {"name": "RGB color model", "offsets": [52641, 62973], "paragraph_occurrences": [109, 139], "sentence_occurrences": [519, 629], "affiliation": "light", "frequency": 2, "id": "RGB_color_model"}, {"name": "Nikon Corporation", "offsets": [37907], "paragraph_occurrences": [76], "sentence_occurrences": [380], "affiliation": "light", "frequency": 1, "id": "Nikon"}, {"name": "EP", "offsets": [126664], "paragraph_occurrences": [310], "sentence_occurrences": [1263], "affiliation": "light", "frequency": 1, "id": "Extended_play"}, {"name": "St. Anne School", "offsets": [122518], "paragraph_occurrences": [300], "sentence_occurrences": [1217], "affiliation": "light", "frequency": 1, "id": "Seattle"}, {"name": "MATLAB", "offsets": [88455, 88768], "paragraph_occurrences": [204, 204], "sentence_occurrences": [907, 911], "affiliation": "light", "frequency": 2, "id": "MATLAB"}, {"name": "PDE10A", "offsets": [102601], "paragraph_occurrences": [246], "sentence_occurrences": [1031], "affiliation": "light", "frequency": 1, "id": "PDE10A"}, {"name": "North Dallas", "offsets": [122571], "paragraph_occurrences": [300], "sentence_occurrences": [1217], "affiliation": "light", "frequency": 1, "id": "North_Dallas"}, {"name": "MPEG-7", "offsets": [53090, 53183, 53398, 53795, 53983], "paragraph_occurrences": [110, 110, 110, 110, 110], "sentence_occurrences": [522, 523, 525, 529, 531], "affiliation": "light", "frequency": 5, "id": "MPEG-7"}, {"name": "Linux kernel", "offsets": [105673], "paragraph_occurrences": [256], "sentence_occurrences": [1061], "affiliation": "light", "frequency": 1, "id": "Linux_kernel"}, {"name": "HSL and HSV", "offsets": [52646], "paragraph_occurrences": [109], "sentence_occurrences": [519], "affiliation": "light", "frequency": 1, "id": "HSL_and_HSV"}, {"name": "The Cancer Genome Atlas", "offsets": [5372], "paragraph_occurrences": [9], "sentence_occurrences": [37], "affiliation": "light", "frequency": 1, "id": "The_Cancer_Genome_Atlas"}, {"name": "Intel", "offsets": [64464], "paragraph_occurrences": [141], "sentence_occurrences": [650], "affiliation": "light", "frequency": 1, "id": "Intel"}, {"name": "Scalar", "offsets": [29326], "paragraph_occurrences": [57], "sentence_occurrences": [283], "affiliation": "light", "frequency": 1, "id": "Scalar_(physics)"}, {"name": "VTK", "offsets": [101797], "paragraph_occurrences": [244], "sentence_occurrences": [1023], "affiliation": "light", "frequency": 1, "id": "VTK"}, {"name": "Rh\u00f4ne", "offsets": [65410], "paragraph_occurrences": [144], "sentence_occurrences": [661], "affiliation": "light", "frequency": 1, "id": "Rh\u00f4ne"}, {"name": "GeForce", "offsets": [64498, 89055, 101887], "paragraph_occurrences": [141, 204, 244], "sentence_occurrences": [650, 913, 1024], "affiliation": "light", "frequency": 3, "id": "GeForce"}, {"name": "Nvidia", "offsets": [61864], "paragraph_occurrences": [134], "sentence_occurrences": [616], "affiliation": "light", "frequency": 1, "id": "Nvidia"}, {"name": "Switzerland", "offsets": [65372, 66985], "paragraph_occurrences": [144, 150], "sentence_occurrences": [660, 682], "affiliation": "light", "frequency": 2, "id": "Switzerland"}, {"name": "Gene", "offsets": [99706, 103983], "paragraph_occurrences": [235, 251], "sentence_occurrences": [1003, 1047], "affiliation": "light", "frequency": 2, "id": "Gene"}, {"name": "Navigation", "offsets": [7437, 34042], "paragraph_occurrences": [15, 70], "sentence_occurrences": [56, 349], "affiliation": "light", "frequency": 2, "id": "Navigation"}, {"name": "Normalization", "offsets": [77206], "paragraph_occurrences": [181], "sentence_occurrences": [791], "affiliation": "light", "frequency": 1, "id": "Normalization_(statistics)"}, {"name": "Voxel", "offsets": [96671], "paragraph_occurrences": [224], "sentence_occurrences": [974], "affiliation": "light", "frequency": 1, "id": "Voxel"}, {"name": "Royal Gorge Bridge", "offsets": [65663, 65688, 66063, 67200], "paragraph_occurrences": [144, 145, 145, 151], "sentence_occurrences": [663, 664, 667, 686], "affiliation": "light", "frequency": 4, "id": "Royal_Gorge_Bridge"}, {"name": "Point-and-shoot camera", "offsets": [64646], "paragraph_occurrences": [143], "sentence_occurrences": [652], "affiliation": "light", "frequency": 1, "id": "Point-and-shoot_camera"}, {"name": "Human\u2013computer interaction", "offsets": [56001], "paragraph_occurrences": [117], "sentence_occurrences": [553], "affiliation": "light", "frequency": 1, "id": "Human\u2013computer_interaction"}, {"name": "Personal computer", "offsets": [120125], "paragraph_occurrences": [296], "sentence_occurrences": [1195], "affiliation": "light", "frequency": 1, "id": "Personal_computer"}, {"name": "Gigapixel image", "offsets": [35885], "paragraph_occurrences": [72], "sentence_occurrences": [366], "affiliation": "light", "frequency": 1, "id": "Gigapixel_image"}, {"name": "Sloan Digital Sky Survey", "offsets": [4555], "paragraph_occurrences": [9], "sentence_occurrences": [32], "affiliation": "light", "frequency": 1, "id": "Sloan_Digital_Sky_Survey"}, {"name": "VisIt", "offsets": [71923], "paragraph_occurrences": [162], "sentence_occurrences": [730], "affiliation": "light", "frequency": 1, "id": "VisIt"}, {"name": "Classical music", "offsets": [39470], "paragraph_occurrences": [80], "sentence_occurrences": [395], "affiliation": "light", "frequency": 1, "id": "Classical_music"}, {"name": "Normal distribution", "offsets": [60160, 60196, 60367, 74227], "paragraph_occurrences": [131, 131, 131, 171], "sentence_occurrences": [600, 600, 602, 759], "affiliation": "light", "frequency": 4, "id": "Normal_distribution"}, {"name": "Neurology", "offsets": [93092, 93214], "paragraph_occurrences": [211, 212], "sentence_occurrences": [945, 946], "affiliation": "light", "frequency": 2, "id": "Neurology"}, {"name": "Anatomical terms of location", "offsets": [103229], "paragraph_occurrences": [247], "sentence_occurrences": [1038], "affiliation": "light", "frequency": 1, "id": "Anatomical_terms_of_location"}, {"name": "Boston", "offsets": [122665], "paragraph_occurrences": [300], "sentence_occurrences": [1217], "affiliation": "light", "frequency": 1, "id": "Boston"}, {"name": "Claude Shannon", "offsets": [83888], "paragraph_occurrences": [195], "sentence_occurrences": [860], "affiliation": "light", "frequency": 1, "id": "Claude_Shannon"}, {"name": "Lp space", "offsets": [33829], "paragraph_occurrences": [68], "sentence_occurrences": [344], "affiliation": "light", "frequency": 1, "id": "Lp_space"}, {"name": "Lab color space", "offsets": [52651], "paragraph_occurrences": [109], "sentence_occurrences": [519], "affiliation": "light", "frequency": 1, "id": "Lab_color_space"}, {"name": "GPS signals", "offsets": [106031], "paragraph_occurrences": [257], "sentence_occurrences": [1064], "affiliation": "light", "frequency": 1, "id": "GPS_signals"}, {"name": "Gene expression", "offsets": [10028, 91392, 96276, 97741, 100038, 102098, 103780], "paragraph_occurrences": [21, 209, 223, 228, 237, 245, 249], "sentence_occurrences": [77, 936, 972, 985, 1007, 1026, 1044], "affiliation": "light", "frequency": 7, "id": "Gene_expression"}, {"name": "Canon Inc.", "offsets": [37900], "paragraph_occurrences": [76], "sentence_occurrences": [380], "affiliation": "light", "frequency": 1, "id": "Canon_Inc."}, {"name": "Trajectory", "offsets": [11412], "paragraph_occurrences": [24], "sentence_occurrences": [89], "affiliation": "light", "frequency": 1, "id": "Trajectory"}, {"name": "Puroresu", "offsets": [32750], "paragraph_occurrences": [67], "sentence_occurrences": [333], "affiliation": "light", "frequency": 1, "id": "Puroresu"}, {"name": "Southern United States", "offsets": [120870, 122228, 122612, 122361, 128239], "paragraph_occurrences": [297, 300, 300, 300, 317], "sentence_occurrences": [1202, 1216, 1217, 1216, 1281], "affiliation": "light", "frequency": 5, "id": "Southern_United_States"}, {"name": "Alar plate", "offsets": [102666, 102696], "paragraph_occurrences": [246, 247], "sentence_occurrences": [1031, 1032], "affiliation": "light", "frequency": 2, "id": "Alar_plate"}, {"name": "Grimsel Pass", "offsets": [65313, 65332, 66868], "paragraph_occurrences": [143, 144, 150], "sentence_occurrences": [659, 660, 681], "affiliation": "light", "frequency": 3, "id": "Grimsel_Pass"}, {"name": "Viola", "offsets": [21632], "paragraph_occurrences": [44], "sentence_occurrences": [175], "affiliation": "light", "frequency": 1, "id": "Viola"}, {"name": "Moore's law", "offsets": [5170], "paragraph_occurrences": [9], "sentence_occurrences": [36], "affiliation": "light", "frequency": 1, "id": "Moore's_law"}, {"name": "Sequoia National Park", "offsets": [66261], "paragraph_occurrences": [147], "sentence_occurrences": [671], "affiliation": "light", "frequency": 1, "id": "Sequoia_National_Park"}, {"name": "Poisson distribution", "offsets": [137030], "paragraph_occurrences": [336], "sentence_occurrences": [1359], "affiliation": "light", "frequency": 1, "id": "Poisson_distribution"}, {"name": "3D computer graphics", "offsets": [748, 2353, 3662, 7263, 10837, 13411, 14107, 20903, 25092, 26271, 26460, 26629, 29212, 72683, 75431, 75914, 76038, 77325, 77514, 79481, 95786, 131512, 131758, 131829, 136891], "paragraph_occurrences": [2, 5, 7, 14, 23, 28, 29, 43, 51, 52, 52, 52, 56, 165, 177, 178, 178, 182, 182, 184, 219, 328, 328, 328, 336], "sentence_occurrences": [6, 14, 25, 54, 84, 101, 106, 169, 220, 235, 238, 242, 282, 739, 772, 778, 779, 793, 794, 813, 964, 1315, 1317, 1318, 1358], "affiliation": "light", "frequency": 25, "id": "3D_computer_graphics"}, {"name": "Dell", "offsets": [37779], "paragraph_occurrences": [76], "sentence_occurrences": [380], "affiliation": "light", "frequency": 1, "id": "Dell"}, {"name": "Scalability", "offsets": [13791, 37218, 38071, 38624, 41804, 42398, 44270, 44367], "paragraph_occurrences": [29, 76, 77, 78, 88, 89, 90, 91], "sentence_occurrences": [104, 377, 383, 388, 421, 426, 441, 442], "affiliation": "light", "frequency": 8, "id": "Scalability"}, {"name": "Miami", "offsets": [122599], "paragraph_occurrences": [300], "sentence_occurrences": [1217], "affiliation": "light", "frequency": 1, "id": "Miami"}, {"name": "Germany", "offsets": [121276], "paragraph_occurrences": [299], "sentence_occurrences": [1207], "affiliation": "light", "frequency": 1, "id": "Germany"}, {"name": "Transfer function", "offsets": [22637], "paragraph_occurrences": [46], "sentence_occurrences": [186], "affiliation": "light", "frequency": 1, "id": "Transfer_function"}, {"name": "Zhou dynasty", "offsets": [23221, 31954], "paragraph_occurrences": [47, 64], "sentence_occurrences": [194, 326], "affiliation": "light", "frequency": 2, "id": "Zhou_dynasty"}, {"name": "Multiscale modeling", "offsets": [45364], "paragraph_occurrences": [95], "sentence_occurrences": [452], "affiliation": "light", "frequency": 1, "id": "Multiscale_modeling"}, {"name": "Genome project", "offsets": [5259], "paragraph_occurrences": [9], "sentence_occurrences": [37], "affiliation": "light", "frequency": 1, "id": "Genome_project"}, {"name": "Distance", "offsets": [105680], "paragraph_occurrences": [256], "sentence_occurrences": [1061], "affiliation": "light", "frequency": 1, "id": "Distance"}, {"name": "Entropy", "offsets": [83547, 83589], "paragraph_occurrences": [194, 195], "sentence_occurrences": [856, 857], "affiliation": "light", "frequency": 2, "id": "Entropy_(information_theory)"}, {"name": "Denver", "offsets": [122557], "paragraph_occurrences": [300], "sentence_occurrences": [1217], "affiliation": "light", "frequency": 1, "id": "Denver,_Indiana"}, {"name": "West Coast of the United States", "offsets": [122279, 122551, 124444], "paragraph_occurrences": [300, 300, 304], "sentence_occurrences": [1216, 1217, 1240], "affiliation": "light", "frequency": 3, "id": "West_Coast_of_the_United_States"}, {"name": "Canton of Bern", "offsets": [65470], "paragraph_occurrences": [144], "sentence_occurrences": [661], "affiliation": "light", "frequency": 1, "id": "Canton_of_Bern"}, {"name": "Fourier transform", "offsets": [112637, 113075, 112754], "paragraph_occurrences": [271, 272, 271], "sentence_occurrences": [1126, 1130, 1126], "affiliation": "light", "frequency": 3, "id": "Fourier_transform"}, {"name": "Royal Gorge Route Railroad", "offsets": [65873], "paragraph_occurrences": [145], "sentence_occurrences": [666], "affiliation": "light", "frequency": 1, "id": "Royal_Gorge_Route_Railroad"}, {"name": "Xeon", "offsets": [89033, 101856, 120136], "paragraph_occurrences": [204, 244, 296], "sentence_occurrences": [913, 1024, 1195], "affiliation": "light", "frequency": 3, "id": "Xeon"}, {"name": "Color blindness", "offsets": [46095], "paragraph_occurrences": [95], "sentence_occurrences": [458], "affiliation": "light", "frequency": 1, "id": "Color_blindness"}, {"name": "International Organization for Standardization", "offsets": [53196], "paragraph_occurrences": [110], "sentence_occurrences": [523], "affiliation": "light", "frequency": 1, "id": "International_Organization_for_Standardization"}, {"name": "Pacific Northwest", "offsets": [122374], "paragraph_occurrences": [300], "sentence_occurrences": [1216], "affiliation": "light", "frequency": 1, "id": "Pacific_Northwest"}, {"name": "Central processing unit", "offsets": [64476, 101876], "paragraph_occurrences": [141, 244], "sentence_occurrences": [650, 1024], "affiliation": "light", "frequency": 2, "id": "Central_processing_unit"}, {"name": "Normal", "offsets": [98353, 98675], "paragraph_occurrences": [231, 232], "sentence_occurrences": [992, 994], "affiliation": "light", "frequency": 2, "id": "Normal_(geometry)"}, {"name": "Northeast United States", "offsets": [120541, 122309, 123743], "paragraph_occurrences": [297, 300, 303], "sentence_occurrences": [1199, 1216, 1230], "affiliation": "light", "frequency": 3, "id": "Northeastern_United_States"}, {"name": "Radio Frequency Identification", "offsets": [106020], "paragraph_occurrences": [257], "sentence_occurrences": [1064], "affiliation": "light", "frequency": 1, "id": "Radio-frequency_identification"}, {"name": "ImageVis3D", "offsets": [71939, 71968, 73851], "paragraph_occurrences": [162, 162, 170], "sentence_occurrences": [730, 731, 755], "affiliation": "light", "frequency": 3, "id": "ImageVis3D"}, {"name": "San Francisco International Airport", "offsets": [120952, 124389], "paragraph_occurrences": [297, 304], "sentence_occurrences": [1203, 1239], "affiliation": "light", "frequency": 2, "id": "San_Francisco_International_Airport"}, {"name": "Folk music", "offsets": [41817, 45107], "paragraph_occurrences": [88, 94], "sentence_occurrences": [421, 449], "affiliation": "light", "frequency": 2, "id": "Folk_music"}, {"name": "Brain", "offsets": [134202], "paragraph_occurrences": [332], "sentence_occurrences": [1339], "affiliation": "light", "frequency": 1, "id": "Brain"}, {"name": "Linear search", "offsets": [54955], "paragraph_occurrences": [113], "sentence_occurrences": [540], "affiliation": "light", "frequency": 1, "id": "Linear_search"}, {"name": "GNU/Linux", "offsets": [64440, 89008, 101620, 120225], "paragraph_occurrences": [141, 204, 244, 296], "sentence_occurrences": [650, 913, 1021, 1196], "affiliation": "light", "frequency": 4, "id": "Linux"}, {"name": "Earth", "offsets": [33367], "paragraph_occurrences": [68], "sentence_occurrences": [340], "affiliation": "light", "frequency": 1, "id": "Earth"}, {"name": "Supreme Headquarters Allied Powers Europe", "offsets": [117652], "paragraph_occurrences": [288], "sentence_occurrences": [1172], "affiliation": "light", "frequency": 1, "id": "Supreme_Headquarters_Allied_Powers_Europe"}, {"name": "Cactus", "offsets": [66112], "paragraph_occurrences": [145], "sentence_occurrences": [667], "affiliation": "light", "frequency": 1, "id": "Cactus"}, {"name": "Allen Brain Atlas", "offsets": [5494, 94211], "paragraph_occurrences": [9, 214], "sentence_occurrences": [39, 953], "affiliation": "light", "frequency": 2, "id": "Allen_Brain_Atlas"}], "all_paragraphs": [{"paragraph_info": {"end": 8, "start": 0, "text": "Abstract", "rank": 0, "paragraph_comparative_number": 1, "entities": [], "id": "p_0"}, "sentences": [{"end": 8, "text": "Abstract", "rank": 0, "start": 0, "IsComparative": "1", "id": "st_0"}]}, {"paragraph_info": {"end": 635, "start": 8, "text": "Technological advances have enabled us to acquire extremely large datasets but it remains a challenge to store, process, and extract information from them.This disserta- tion builds upon recent advances in machine learning, visualization, and user interactions to facilitate exploration of large-scale scientific datasets.First, we use data-driven ap- proaches to computationally identify regions of interest in the datasets.Second, we use visual presentation for effective user comprehension.Third, we provide interactions for human users to integrate domain knowledge and semantic information into this explo- ration process.", "rank": 1, "paragraph_comparative_number": 2, "entities": [], "id": "p_1"}, "sentences": [{"end": 163, "text": "Technological advances have enabled us to acquire extremely large datasets but it remains a challenge to store, process, and extract information from them.", "rank": 1, "start": 8, "IsComparative": "1", "id": "st_1"}, {"end": 330, "text": "This disserta- tion builds upon recent advances in machine learning, visualization, and user interactions to facilitate exploration of large-scale scientific datasets.", "rank": 2, "start": 163, "IsComparative": "1", "id": "st_2"}, {"end": 433, "text": "First, we use data-driven ap- proaches to computationally identify regions of interest in the datasets.", "rank": 3, "start": 330, "IsComparative": "0", "id": "st_3"}, {"end": 501, "text": "Second, we use visual presentation for effective user comprehension.", "rank": 4, "start": 433, "IsComparative": "0", "id": "st_4"}, {"end": 635, "text": "Third, we provide interactions for human users to integrate domain knowledge and semantic information into this explo- ration process.", "rank": 5, "start": 501, "IsComparative": "0", "id": "st_5"}]}, {"paragraph_info": {"end": 1522, "start": 635, "text": "Our research shows how to extract, visualize, and explore informative regions on very large 2D landscape images, 3D volumetric datasets, high-dimensional volumetric mouse brain datasets with thousands of spatially-mapped gene expression profiles, and geospatial trajectories that evolve over time.The contribution of this dissertation include: (1) We introduce a sliding-window saliency model that discovers regions of user interest in very large images; (2) We develop visual segmentation of intensity-gradient histograms to identify meaningful components from volumetric datasets; (3) We extract boundary surfaces from a wealth of volumetric gene expression mouse brain profiles to personalize the reference brain atlas; (4) We show how to efficiently cluster geospatial trajectories by mapping each sequence of locations to a high-dimensional point with the kernel distance framework.", "rank": 2, "paragraph_comparative_number": 2, "entities": [], "id": "p_2"}, "sentences": [{"end": 932, "text": "Our research shows how to extract, visualize, and explore informative regions on very large 2D landscape images, 3D volumetric datasets, high-dimensional volumetric mouse brain datasets with thousands of spatially-mapped gene expression profiles, and geospatial trajectories that evolve over time.", "rank": 6, "start": 635, "IsComparative": "1", "id": "st_6"}, {"end": 1522, "text": "The contribution of this dissertation include: (1) We introduce a sliding-window saliency model that discovers regions of user interest in very large images; (2) We develop visual segmentation of intensity-gradient histograms to identify meaningful components from volumetric datasets; (3) We extract boundary surfaces from a wealth of volumetric gene expression mouse brain profiles to personalize the reference brain atlas; (4) We show how to efficiently cluster geospatial trajectories by mapping each sequence of locations to a high-dimensional point with the kernel distance framework.", "rank": 7, "start": 932, "IsComparative": "1", "id": "st_7"}]}, {"paragraph_info": {"end": 1812, "start": 1522, "text": "We aim to discover patterns, relationships, and anomalies that would lead to new scientific, engineering, and medical advances.This work represents one of the first steps toward better visual understanding of large-scale scientific data by combining machine learning and human intelligence.", "rank": 3, "paragraph_comparative_number": 0, "entities": [], "id": "p_3"}, "sentences": [{"end": 1649, "text": "We aim to discover patterns, relationships, and anomalies that would lead to new scientific, engineering, and medical advances.", "rank": 8, "start": 1522, "IsComparative": "0", "id": "st_8"}, {"end": 1812, "text": "This work represents one of the first steps toward better visual understanding of large-scale scientific data by combining machine learning and human intelligence.", "rank": 9, "start": 1649, "IsComparative": "0", "id": "st_9"}]}, {"paragraph_info": {"end": 1834, "start": 1812, "text": "Chapter 1 Introduction", "rank": 4, "paragraph_comparative_number": 0, "entities": [], "id": "p_4"}, "sentences": [{"end": 1834, "text": "Chapter 1 Introduction", "rank": 10, "start": 1812, "IsComparative": "0", "id": "st_10"}]}, {"paragraph_info": {"end": 2551, "start": 1834, "text": "Big data challenges our capacity to turn data into knowledge for advancing science, engineering, and medicine.This dissertation aims to show that the exploration process of big data can be assisted by integrating machine learning with visualization.We specifically show how users can efficiently identify the regions of interest in datasets by coupling visualization and knowledge discovery.In this dissertation, we analyze and visualize scientific datasets of increasing dimensions, such as spatially large 2D images, 3D volumetric medical and climate datasets, high-dimensional volumetric brain datasets with thousands of spatially-mapped gene expression profiles, and geospatial trajectories that evolve over time.", "rank": 5, "paragraph_comparative_number": 2, "entities": [], "id": "p_5"}, "sentences": [{"end": 1944, "text": "Big data challenges our capacity to turn data into knowledge for advancing science, engineering, and medicine.", "rank": 11, "start": 1834, "IsComparative": "1", "id": "st_11"}, {"end": 2083, "text": "This dissertation aims to show that the exploration process of big data can be assisted by integrating machine learning with visualization.", "rank": 12, "start": 1944, "IsComparative": "0", "id": "st_12"}, {"end": 2225, "text": "We specifically show how users can efficiently identify the regions of interest in datasets by coupling visualization and knowledge discovery.", "rank": 13, "start": 2083, "IsComparative": "0", "id": "st_13"}, {"end": 2551, "text": "In this dissertation, we analyze and visualize scientific datasets of increasing dimensions, such as spatially large 2D images, 3D volumetric medical and climate datasets, high-dimensional volumetric brain datasets with thousands of spatially-mapped gene expression profiles, and geospatial trajectories that evolve over time.", "rank": 14, "start": 2225, "IsComparative": "1", "id": "st_14"}]}, {"paragraph_info": {"end": 3304, "start": 2551, "text": "The advances in computing and acquisition allow us to acquire, process, and store massive amounts of raw data.However, our ability to comprehend the data remains unchanged.Machine learning and visualization can offer help in understanding large datasets in two ways.First, machine learning discovers information from raw data by recognizing patterns, anomalies, and relationships.This artificial intelligence approach reduces the vast amount of data to more manageable knowledge and information.Sec- ond, visualization presents the raw data in a visual form for effective user comprehension.Visual representation enhances user cognition and reasoning on the abstract data.User interactions facilitate feedback between machine learning and visualization.", "rank": 6, "paragraph_comparative_number": 4, "entities": [], "id": "p_6"}, "sentences": [{"end": 2661, "text": "The advances in computing and acquisition allow us to acquire, process, and store massive amounts of raw data.", "rank": 15, "start": 2551, "IsComparative": "0", "id": "st_15"}, {"end": 2723, "text": "However, our ability to comprehend the data remains unchanged.", "rank": 16, "start": 2661, "IsComparative": "1", "id": "st_16"}, {"end": 2817, "text": "Machine learning and visualization can offer help in understanding large datasets in two ways.", "rank": 17, "start": 2723, "IsComparative": "1", "id": "st_17"}, {"end": 2931, "text": "First, machine learning discovers information from raw data by recognizing patterns, anomalies, and relationships.", "rank": 18, "start": 2817, "IsComparative": "0", "id": "st_18"}, {"end": 3046, "text": "This artificial intelligence approach reduces the vast amount of data to more manageable knowledge and information.", "rank": 19, "start": 2931, "IsComparative": "1", "id": "st_19"}, {"end": 3142, "text": "Sec- ond, visualization presents the raw data in a visual form for effective user comprehension.", "rank": 20, "start": 3046, "IsComparative": "0", "id": "st_20"}, {"end": 3223, "text": "Visual representation enhances user cognition and reasoning on the abstract data.", "rank": 21, "start": 3142, "IsComparative": "1", "id": "st_21"}, {"end": 3304, "text": "User interactions facilitate feedback between machine learning and visualization.", "rank": 22, "start": 3223, "IsComparative": "0", "id": "st_22"}]}, {"paragraph_info": {"end": 4223, "start": 3304, "text": "This dissertation shows how machine learning can assist in visual exploration of two, three and multi-dimensional scientific datasets, along with temporal evolution.On very large 2D multi-gigapixel landscape images, we show that our approach of progres- sive elicitation of salient regions is fast and allows rapid identification of regions of inter- est.On 3D volumetric datasets, our approach mimics user exploration behavior by analyzing the intensity-gradient histogram with the normalized-cut multilevel segmentation technique.The resulting segments lead users to discover volumetric regions of interests.We extract gene expression surfaces of different anatomical brain structures from thou- sands of spatially-mapped gene expression profiles of mouse brains.We also show how to efficiently cluster and detect communities in time-varying geospatial trajectories by using the approximate kernel distance framework.", "rank": 7, "paragraph_comparative_number": 2, "entities": [], "id": "p_7"}, "sentences": [{"end": 3469, "text": "This dissertation shows how machine learning can assist in visual exploration of two, three and multi-dimensional scientific datasets, along with temporal evolution.", "rank": 23, "start": 3304, "IsComparative": "0", "id": "st_23"}, {"end": 3659, "text": "On very large 2D multi-gigapixel landscape images, we show that our approach of progres- sive elicitation of salient regions is fast and allows rapid identification of regions of inter- est.", "rank": 24, "start": 3469, "IsComparative": "1", "id": "st_24"}, {"end": 3836, "text": "On 3D volumetric datasets, our approach mimics user exploration behavior by analyzing the intensity-gradient histogram with the normalized-cut multilevel segmentation technique.", "rank": 25, "start": 3659, "IsComparative": "1", "id": "st_25"}, {"end": 3914, "text": "The resulting segments lead users to discover volumetric regions of interests.", "rank": 26, "start": 3836, "IsComparative": "0", "id": "st_26"}, {"end": 4069, "text": "We extract gene expression surfaces of different anatomical brain structures from thou- sands of spatially-mapped gene expression profiles of mouse brains.", "rank": 27, "start": 3914, "IsComparative": "0", "id": "st_27"}, {"end": 4223, "text": "We also show how to efficiently cluster and detect communities in time-varying geospatial trajectories by using the approximate kernel distance framework.", "rank": 28, "start": 4069, "IsComparative": "0", "id": "st_28"}]}, {"paragraph_info": {"end": 4249, "start": 4223, "text": "1.1 The Big Data Challenge", "rank": 8, "paragraph_comparative_number": 0, "entities": [], "id": "p_8"}, "sentences": [{"end": 4249, "text": "1.1 The Big Data Challenge", "rank": 29, "start": 4223, "IsComparative": "0", "id": "st_29"}]}, {"paragraph_info": {"end": 5642, "start": 4249, "text": "Big data has its origins in scientific disciplines, such as astronomy, to medical dis- cplines, such as genomics, to consumer applications, such as Internet transactions and social networks.The Large Hadron Collider (LHC) generates 15 petabytes of high en- ergy particle experiments data annually <17>.The Sloan Digital Sky Survey (SDSS)<153> has gathered 140 terabytes of optical astronomy images since 2000, its successor, the Large Synoptic Survey Telescope (LSST) <61>, is designed to capture 30 terabytes every night with its 3200 megapixel camera.The Expanded Very Large Array (EVLA) <125> radio telescopes are producing 1.2 terabytes of data everyday.Computational methods have played an instrumental role in genomics research.The cost of genomic sequencing has been rapid falling from $100,000, at the completion of the first human genome in 2001, to a few thousand dollars <106> now.This trend is outgrowing the Moores law and it implies the data can outgrow our computing power in this area.The 1000 Genome Project <148> hosts 130 terabytes of genomics data to provide us a better view on human genetic variation.The Cancer Genome Atlas <107> sequences genomes of tumors and normal pair tissues at a rate of 20 terabytes per month.The Allen Brain Atlas <74> pro- vides a 600 terabytes data archive of how thousands of genes are expressed in different parts of mouse and human brains.", "rank": 9, "paragraph_comparative_number": 7, "entities": [], "id": "p_9"}, "sentences": [{"end": 4439, "text": "Big data has its origins in scientific disciplines, such as astronomy, to medical dis- cplines, such as genomics, to consumer applications, such as Internet transactions and social networks.", "rank": 30, "start": 4249, "IsComparative": "1", "id": "st_30"}, {"end": 4551, "text": "The Large Hadron Collider (LHC) generates 15 petabytes of high en- ergy particle experiments data annually <17>.", "rank": 31, "start": 4439, "IsComparative": "1", "id": "st_31"}, {"end": 4802, "text": "The Sloan Digital Sky Survey (SDSS)<153> has gathered 140 terabytes of optical astronomy images since 2000, its successor, the Large Synoptic Survey Telescope (LSST) <61>, is designed to capture 30 terabytes every night with its 3200 megapixel camera.", "rank": 32, "start": 4551, "IsComparative": "1", "id": "st_32"}, {"end": 4907, "text": "The Expanded Very Large Array (EVLA) <125> radio telescopes are producing 1.2 terabytes of data everyday.", "rank": 33, "start": 4802, "IsComparative": "0", "id": "st_33"}, {"end": 4983, "text": "Computational methods have played an instrumental role in genomics research.", "rank": 34, "start": 4907, "IsComparative": "0", "id": "st_34"}, {"end": 5141, "text": "The cost of genomic sequencing has been rapid falling from $100,000, at the completion of the first human genome in 2001, to a few thousand dollars <106> now.", "rank": 35, "start": 4983, "IsComparative": "1", "id": "st_35"}, {"end": 5250, "text": "This trend is outgrowing the Moores law and it implies the data can outgrow our computing power in this area.", "rank": 36, "start": 5141, "IsComparative": "1", "id": "st_36"}, {"end": 5372, "text": "The 1000 Genome Project <148> hosts 130 terabytes of genomics data to provide us a better view on human genetic variation.", "rank": 37, "start": 5250, "IsComparative": "1", "id": "st_37"}, {"end": 5490, "text": "The Cancer Genome Atlas <107> sequences genomes of tumors and normal pair tissues at a rate of 20 terabytes per month.", "rank": 38, "start": 5372, "IsComparative": "1", "id": "st_38"}, {"end": 5642, "text": "The Allen Brain Atlas <74> pro- vides a 600 terabytes data archive of how thousands of genes are expressed in different parts of mouse and human brains.", "rank": 39, "start": 5490, "IsComparative": "0", "id": "st_39"}]}, {"paragraph_info": {"end": 6171, "start": 5642, "text": "It is imperative for us to understand these massive datasets for enabling the next- generation of scientific discoveries.We need new technologies to analyze, visualize, and extract useful information from these extremely large datasets.The size of these big datasets challenges the human cognitive capacity, computational capacity, and the visu- alization capacity.We seek tools for discovering patterns or structures in data and locate regions of interest for visualization.We outline three challenges in big data visualization:", "rank": 10, "paragraph_comparative_number": 3, "entities": [], "id": "p_10"}, "sentences": [{"end": 5763, "text": "It is imperative for us to understand these massive datasets for enabling the next- generation of scientific discoveries.", "rank": 40, "start": 5642, "IsComparative": "1", "id": "st_40"}, {"end": 5878, "text": "We need new technologies to analyze, visualize, and extract useful information from these extremely large datasets.", "rank": 41, "start": 5763, "IsComparative": "1", "id": "st_41"}, {"end": 6007, "text": "The size of these big datasets challenges the human cognitive capacity, computational capacity, and the visu- alization capacity.", "rank": 42, "start": 5878, "IsComparative": "0", "id": "st_42"}, {"end": 6117, "text": "We seek tools for discovering patterns or structures in data and locate regions of interest for visualization.", "rank": 43, "start": 6007, "IsComparative": "0", "id": "st_43"}, {"end": 6171, "text": "We outline three challenges in big data visualization:", "rank": 44, "start": 6117, "IsComparative": "1", "id": "st_44"}]}, {"paragraph_info": {"end": 6504, "start": 6171, "text": "Visual Challenge: The visual challenge arises from the inability of the human visual system to take in all the details that are presented in very large datasets.There are limits on computing both spatial resolution and dimensionality.These arise from a fundamental resolution limitation of the retina as well as the display hardware.", "rank": 11, "paragraph_comparative_number": 1, "entities": [], "id": "p_11"}, "sentences": [{"end": 6332, "text": "Visual Challenge: The visual challenge arises from the inability of the human visual system to take in all the details that are presented in very large datasets.", "rank": 45, "start": 6171, "IsComparative": "1", "id": "st_45"}, {"end": 6405, "text": "There are limits on computing both spatial resolution and dimensionality.", "rank": 46, "start": 6332, "IsComparative": "0", "id": "st_46"}, {"end": 6504, "text": "These arise from a fundamental resolution limitation of the retina as well as the display hardware.", "rank": 47, "start": 6405, "IsComparative": "0", "id": "st_47"}]}, {"paragraph_info": {"end": 6791, "start": 6504, "text": "Data Challenge: Processing large amounts of raw data for visualization presents a com- putational challenge.The increase in dimensionality further exacerbates the problem.We have to address this challenge by better data analysis and the use of parallel computational hardware <117, 118>.", "rank": 12, "paragraph_comparative_number": 1, "entities": [], "id": "p_12"}, "sentences": [{"end": 6612, "text": "Data Challenge: Processing large amounts of raw data for visualization presents a com- putational challenge.", "rank": 48, "start": 6504, "IsComparative": "0", "id": "st_48"}, {"end": 6675, "text": "The increase in dimensionality further exacerbates the problem.", "rank": 49, "start": 6612, "IsComparative": "0", "id": "st_49"}, {"end": 6791, "text": "We have to address this challenge by better data analysis and the use of parallel computational hardware <117, 118>.", "rank": 50, "start": 6675, "IsComparative": "1", "id": "st_50"}]}, {"paragraph_info": {"end": 7170, "start": 6791, "text": "Information and Semantics Challenge: Visualization of machine-analyzed data helps users understand the data faster.Identifying informative regions in datasets that match human expectations is an ambitious challenge.We iterate the analysis and visualization with user interactions, such that users can provide valuable semantic inputs to improve the information discovery process.", "rank": 13, "paragraph_comparative_number": 0, "entities": [], "id": "p_13"}, "sentences": [{"end": 6906, "text": "Information and Semantics Challenge: Visualization of machine-analyzed data helps users understand the data faster.", "rank": 51, "start": 6791, "IsComparative": "0", "id": "st_51"}, {"end": 7006, "text": "Identifying informative regions in datasets that match human expectations is an ambitious challenge.", "rank": 52, "start": 6906, "IsComparative": "0", "id": "st_52"}, {"end": 7170, "text": "We iterate the analysis and visualization with user interactions, such that users can provide valuable semantic inputs to improve the information discovery process.", "rank": 53, "start": 7006, "IsComparative": "0", "id": "st_53"}]}, {"paragraph_info": {"end": 7415, "start": 7170, "text": "In this dissertation, we address each of these challenges progressively from 2D im- ages and 3D volumes to datasets with thousands of dimensions and time-varying geospa- tial locations.The next sections outline the results and the contributions.", "rank": 14, "paragraph_comparative_number": 1, "entities": [], "id": "p_14"}, "sentences": [{"end": 7355, "text": "In this dissertation, we address each of these challenges progressively from 2D im- ages and 3D volumes to datasets with thousands of dimensions and time-varying geospa- tial locations.", "rank": 54, "start": 7170, "IsComparative": "1", "id": "st_54"}, {"end": 7415, "text": "The next sections outline the results and the contributions.", "rank": 55, "start": 7355, "IsComparative": "0", "id": "st_55"}]}, {"paragraph_info": {"end": 7478, "start": 7415, "text": "1.2 Saliency-Assisted Navigation of Very Large Landscape Images", "rank": 15, "paragraph_comparative_number": 1, "entities": [], "id": "p_15"}, "sentences": [{"end": 7478, "text": "1.2 Saliency-Assisted Navigation of Very Large Landscape Images", "rank": 56, "start": 7415, "IsComparative": "1", "id": "st_56"}]}, {"paragraph_info": {"end": 8064, "start": 7478, "text": "The field of visualization has addressed navigation of very large datasets, usually meshes and volumes.Significantly less attention has been devoted to the issues surround- ing navigation of very large images.In the last few years the explosive growth in the resolution of camera sensors and robotic image acquisition techniques has widened the gap between the display and image resolutions to three orders of magnitude or more.This work <56> presents the first steps towards navigation of very large images, particularly landscape images, from an interactive visualization perspective.", "rank": 16, "paragraph_comparative_number": 3, "entities": [], "id": "p_16"}, "sentences": [{"end": 7581, "text": "The field of visualization has addressed navigation of very large datasets, usually meshes and volumes.", "rank": 57, "start": 7478, "IsComparative": "0", "id": "st_57"}, {"end": 7687, "text": "Significantly less attention has been devoted to the issues surround- ing navigation of very large images.", "rank": 58, "start": 7581, "IsComparative": "1", "id": "st_58"}, {"end": 7906, "text": "In the last few years the explosive growth in the resolution of camera sensors and robotic image acquisition techniques has widened the gap between the display and image resolutions to three orders of magnitude or more.", "rank": 59, "start": 7687, "IsComparative": "1", "id": "st_59"}, {"end": 8064, "text": "This work <56> presents the first steps towards navigation of very large images, particularly landscape images, from an interactive visualization perspective.", "rank": 60, "start": 7906, "IsComparative": "1", "id": "st_60"}]}, {"paragraph_info": {"end": 8655, "start": 8064, "text": "The grand challenge in navigation of very large images is identifying regions of potential interest.We outline a three-step approach.In the first step we use multi-scale saliency to narrow down the potential areas of interest.In the second step we outline a method based on statistical signatures to further cull out regions of high conformity.In the final step we allow a user to interactively identify the exceptional regions of high interest that merit further attention.For example, in Figure 1.1, we identify regions of interest, such as landscape features, buildings, and human beings.", "rank": 17, "paragraph_comparative_number": 0, "entities": [], "id": "p_17"}, "sentences": [{"end": 8164, "text": "The grand challenge in navigation of very large images is identifying regions of potential interest.", "rank": 61, "start": 8064, "IsComparative": "0", "id": "st_61"}, {"end": 8197, "text": "We outline a three-step approach.", "rank": 62, "start": 8164, "IsComparative": "0", "id": "st_62"}, {"end": 8290, "text": "In the first step we use multi-scale saliency to narrow down the potential areas of interest.", "rank": 63, "start": 8197, "IsComparative": "0", "id": "st_63"}, {"end": 8408, "text": "In the second step we outline a method based on statistical signatures to further cull out regions of high conformity.", "rank": 64, "start": 8290, "IsComparative": "0", "id": "st_64"}, {"end": 8538, "text": "In the final step we allow a user to interactively identify the exceptional regions of high interest that merit further attention.", "rank": 65, "start": 8408, "IsComparative": "0", "id": "st_65"}, {"end": 8655, "text": "For example, in Figure 1.1, we identify regions of interest, such as landscape features, buildings, and human beings.", "rank": 66, "start": 8538, "IsComparative": "0", "id": "st_66"}]}, {"paragraph_info": {"end": 9037, "start": 8655, "text": "We show that our approach of progressive elicitation is fast and allows rapid iden- tification of regions of interest.Unlike previous work in this area, our approach is scal- able and computationally reasonable on very large images.We validate the results of our approach by comparing them to user-tagged regions of interest on several very large landscape images from the Internet.", "rank": 18, "paragraph_comparative_number": 3, "entities": [], "id": "p_18"}, "sentences": [{"end": 8773, "text": "We show that our approach of progressive elicitation is fast and allows rapid iden- tification of regions of interest.", "rank": 67, "start": 8655, "IsComparative": "1", "id": "st_67"}, {"end": 8887, "text": "Unlike previous work in this area, our approach is scal- able and computationally reasonable on very large images.", "rank": 68, "start": 8773, "IsComparative": "1", "id": "st_68"}, {"end": 9037, "text": "We validate the results of our approach by comparing them to user-tagged regions of interest on several very large landscape images from the Internet.", "rank": 69, "start": 8887, "IsComparative": "1", "id": "st_69"}]}, {"paragraph_info": {"end": 9143, "start": 9037, "text": "1.3 Hierarchical Exploration of Volumes using Multilevel Segmentation of the Intensity-Gradient Histograms", "rank": 19, "paragraph_comparative_number": 0, "entities": [], "id": "p_19"}, "sentences": [{"end": 9143, "text": "1.3 Hierarchical Exploration of Volumes using Multilevel Segmentation of the Intensity-Gradient Histograms", "rank": 70, "start": 9037, "IsComparative": "0", "id": "st_70"}]}, {"paragraph_info": {"end": 9986, "start": 9143, "text": "Visual exploration of volumetric datasets to discover the embedded features and spatial structures is a challenging and tedious task.We present a semi-automatic ap- proach to this problem that works by visually segmenting the intensity-gradient 2D his- togram of a volumetric dataset into an exploration hierarchy <57>.Our approach mimics user exploration behavior by analyzing the histogram with the normalized-cut multilevel segmentation technique.Unlike previous work in this area, our technique segments the histogram into a reasonable set of intuitive components that are mutually exclusive and collectively exhaustive.We use information-theoretic measures of the volumetric data segments to guide the exploration.This provides a data-driven coarse-to-fine hierarchy for a user to interactively navigate the volume in a meaningful manner.", "rank": 20, "paragraph_comparative_number": 4, "entities": [], "id": "p_20"}, "sentences": [{"end": 9276, "text": "Visual exploration of volumetric datasets to discover the embedded features and spatial structures is a challenging and tedious task.", "rank": 71, "start": 9143, "IsComparative": "1", "id": "st_71"}, {"end": 9462, "text": "We present a semi-automatic ap- proach to this problem that works by visually segmenting the intensity-gradient 2D his- togram of a volumetric dataset into an exploration hierarchy <57>.", "rank": 72, "start": 9276, "IsComparative": "0", "id": "st_72"}, {"end": 9593, "text": "Our approach mimics user exploration behavior by analyzing the histogram with the normalized-cut multilevel segmentation technique.", "rank": 73, "start": 9462, "IsComparative": "1", "id": "st_73"}, {"end": 9767, "text": "Unlike previous work in this area, our technique segments the histogram into a reasonable set of intuitive components that are mutually exclusive and collectively exhaustive.", "rank": 74, "start": 9593, "IsComparative": "1", "id": "st_74"}, {"end": 9862, "text": "We use information-theoretic measures of the volumetric data segments to guide the exploration.", "rank": 75, "start": 9767, "IsComparative": "1", "id": "st_75"}, {"end": 9986, "text": "This provides a data-driven coarse-to-fine hierarchy for a user to interactively navigate the volume in a meaningful manner.", "rank": 76, "start": 9862, "IsComparative": "0", "id": "st_76"}]}, {"paragraph_info": {"end": 10054, "start": 9986, "text": "1.4 Personalizing the Brain Atlas through Gene Expression Correlates", "rank": 21, "paragraph_comparative_number": 0, "entities": [], "id": "p_21"}, "sentences": [{"end": 10054, "text": "1.4 Personalizing the Brain Atlas through Gene Expression Correlates", "rank": 77, "start": 9986, "IsComparative": "0", "id": "st_77"}]}, {"paragraph_info": {"end": 10219, "start": 10054, "text": "We introduce a data-driven approach to personalize the brain atlas with multiple gene expression profiles <55>.Segmentation of brain volumes is a challenging problem", "rank": 22, "paragraph_comparative_number": 0, "entities": [], "id": "p_22"}, "sentences": [{"end": 10165, "text": "We introduce a data-driven approach to personalize the brain atlas with multiple gene expression profiles <55>.", "rank": 78, "start": 10054, "IsComparative": "0", "id": "st_78"}, {"end": 10219, "text": "Segmentation of brain volumes is a challenging problem", "rank": 79, "start": 10165, "IsComparative": "0", "id": "st_79"}]}, {"paragraph_info": {"end": 11403, "start": 10219, "text": "Learn an expression Personalize the reference surface Retrieve gene expression profiles surface from the genes with the gene expression surface that often requires fitting a reference atlas with boundaries of the brain structures to a brain volume.Figure 1.3 shows a data-driven approach for extracting these structural boundaries from a wealth of spatially-mapped gene expression scalar fields.We first re- trieve genes that are highly correlated with a brain structure of interest.Then, we apply tensor voting to identify a surface with coherent directions that spans the peaks of the gene expression gradients.This 3D surface represents the gene expression boundaries around the brain structure of interest.We visualize the difference between this genetic boundary and the reference atlas.We also compute a deformation that maps the reference atlas to the gene expression surface.This data-driven deformation allows us to personalize the reference brain atlas according to coherent structures in multiple volumetric gene expres- sion profiles.Our experimental results compare a variety of gene expression surfaces to the gene expression profiles and the reference brain structures.", "rank": 23, "paragraph_comparative_number": 4, "entities": [], "id": "p_23"}, "sentences": [{"end": 10467, "text": "Learn an expression Personalize the reference surface Retrieve gene expression profiles surface from the genes with the gene expression surface that often requires fitting a reference atlas with boundaries of the brain structures to a brain volume.", "rank": 80, "start": 10219, "IsComparative": "0", "id": "st_80"}, {"end": 10614, "text": "Figure 1.3 shows a data-driven approach for extracting these structural boundaries from a wealth of spatially-mapped gene expression scalar fields.", "rank": 81, "start": 10467, "IsComparative": "1", "id": "st_81"}, {"end": 10702, "text": "We first re- trieve genes that are highly correlated with a brain structure of interest.", "rank": 82, "start": 10614, "IsComparative": "1", "id": "st_82"}, {"end": 10832, "text": "Then, we apply tensor voting to identify a surface with coherent directions that spans the peaks of the gene expression gradients.", "rank": 83, "start": 10702, "IsComparative": "1", "id": "st_83"}, {"end": 10929, "text": "This 3D surface represents the gene expression boundaries around the brain structure of interest.", "rank": 84, "start": 10832, "IsComparative": "0", "id": "st_84"}, {"end": 11011, "text": "We visualize the difference between this genetic boundary and the reference atlas.", "rank": 85, "start": 10929, "IsComparative": "0", "id": "st_85"}, {"end": 11102, "text": "We also compute a deformation that maps the reference atlas to the gene expression surface.", "rank": 86, "start": 11011, "IsComparative": "0", "id": "st_86"}, {"end": 11265, "text": "This data-driven deformation allows us to personalize the reference brain atlas according to coherent structures in multiple volumetric gene expres- sion profiles.", "rank": 87, "start": 11102, "IsComparative": "0", "id": "st_87"}, {"end": 11403, "text": "Our experimental results compare a variety of gene expression surfaces to the gene expression profiles and the reference brain structures.", "rank": 88, "start": 11265, "IsComparative": "1", "id": "st_88"}]}, {"paragraph_info": {"end": 11459, "start": 11403, "text": "1.5 Fast Trajectory Clustering using the Kernel Distance", "rank": 24, "paragraph_comparative_number": 0, "entities": [], "id": "p_24"}, "sentences": [{"end": 11459, "text": "1.5 Fast Trajectory Clustering using the Kernel Distance", "rank": 89, "start": 11403, "IsComparative": "0", "id": "st_89"}]}, {"paragraph_info": {"end": 12875, "start": 11459, "text": "We present a novel approach for clustering geospatial trajectories by the approxi- mate kernel distance <54>.Computing a distance between two trajectories is a tradition- ally challenging problem, due to the quadratic distance computations between points in the two trajectories.The approximate kernel distance method projects point sets, curves, and surfaces to high-dimensional feature vectors for similarity comparison.In this work, we show how to map each trajectory to a high dimensional point with this framework in O(nlgn) for clustering applications.This is very attractive as it allows conventional point-based data mining algorithms to be applied to geospatial trajectories.We present (1) a new technique to cluster geospatial trajectories with an approximate kernel distance, (2) we show how to combine this approach with k-means clustering and operate in a streaming fashion which we can update the feature vectors dynamically as the new points arrive, (3) we also show how to combine the approximate kernel distance framework with community detection methods to automatically discover unevenly distributed clusters of various shapes, and (4) our performance studies show efficient scaling up of this method to process very large datasets with hundreds of thousands of trajectories and tens of mil- lions points within a few minutes.Figure 1.4 shows five clusters of 464K San Francisco taxi trajectories.", "rank": 25, "paragraph_comparative_number": 5, "entities": [], "id": "p_25"}, "sentences": [{"end": 11568, "text": "We present a novel approach for clustering geospatial trajectories by the approxi- mate kernel distance <54>.", "rank": 90, "start": 11459, "IsComparative": "1", "id": "st_90"}, {"end": 11738, "text": "Computing a distance between two trajectories is a tradition- ally challenging problem, due to the quadratic distance computations between points in the two trajectories.", "rank": 91, "start": 11568, "IsComparative": "1", "id": "st_91"}, {"end": 11881, "text": "The approximate kernel distance method projects point sets, curves, and surfaces to high-dimensional feature vectors for similarity comparison.", "rank": 92, "start": 11738, "IsComparative": "1", "id": "st_92"}, {"end": 12017, "text": "In this work, we show how to map each trajectory to a high dimensional point with this framework in O(nlgn) for clustering applications.", "rank": 93, "start": 11881, "IsComparative": "1", "id": "st_93"}, {"end": 12143, "text": "This is very attractive as it allows conventional point-based data mining algorithms to be applied to geospatial trajectories.", "rank": 94, "start": 12017, "IsComparative": "0", "id": "st_94"}, {"end": 12804, "text": "We present (1) a new technique to cluster geospatial trajectories with an approximate kernel distance, (2) we show how to combine this approach with k-means clustering and operate in a streaming fashion which we can update the feature vectors dynamically as the new points arrive, (3) we also show how to combine the approximate kernel distance framework with community detection methods to automatically discover unevenly distributed clusters of various shapes, and (4) our performance studies show efficient scaling up of this method to process very large datasets with hundreds of thousands of trajectories and tens of mil- lions points within a few minutes.", "rank": 95, "start": 12143, "IsComparative": "0", "id": "st_95"}, {"end": 12875, "text": "Figure 1.4 shows five clusters of 464K San Francisco taxi trajectories.", "rank": 96, "start": 12804, "IsComparative": "1", "id": "st_96"}]}, {"paragraph_info": {"end": 12892, "start": 12875, "text": "1.6 Contributions", "rank": 26, "paragraph_comparative_number": 0, "entities": [], "id": "p_26"}, "sentences": [{"end": 12892, "text": "1.6 Contributions", "rank": 97, "start": 12875, "IsComparative": "0", "id": "st_97"}]}, {"paragraph_info": {"end": 13091, "start": 12892, "text": "We outline the contributions of this dissertation for addressing the visual, data, and semantic challenges: visual knowledge discovery, data scalability, as well as, visualiza- tion and interactions.", "rank": 27, "paragraph_comparative_number": 1, "entities": [], "id": "p_27"}, "sentences": [{"end": 13091, "text": "We outline the contributions of this dissertation for addressing the visual, data, and semantic challenges: visual knowledge discovery, data scalability, as well as, visualiza- tion and interactions.", "rank": 98, "start": 12892, "IsComparative": "1", "id": "st_98"}]}, {"paragraph_info": {"end": 13786, "start": 13091, "text": "Visual Knowledge Discovery: We use visual approaches to identify regions of interest from visual datasets and provide guided explorations.We simulate the zooming process on very large images by using a sliding window to compute saliency and then visualize the details of a multi-gigapixel image on megapixel displays.On 3D volumetric datasets, we mimic user behaviors by visually segmenting the intensity-gradient histogram of vol- ume datasets.Our work on spatially-mapped gene expression profiles extracts expression surfaces from thousands of gene expression profiles.Clustering similar trajectories geo- metrically discovers visually similar patterns in time-varying geospatial trajectories.", "rank": 28, "paragraph_comparative_number": 3, "entities": [], "id": "p_28"}, "sentences": [{"end": 13229, "text": "Visual Knowledge Discovery: We use visual approaches to identify regions of interest from visual datasets and provide guided explorations.", "rank": 99, "start": 13091, "IsComparative": "1", "id": "st_99"}, {"end": 13408, "text": "We simulate the zooming process on very large images by using a sliding window to compute saliency and then visualize the details of a multi-gigapixel image on megapixel displays.", "rank": 100, "start": 13229, "IsComparative": "1", "id": "st_100"}, {"end": 13536, "text": "On 3D volumetric datasets, we mimic user behaviors by visually segmenting the intensity-gradient histogram of vol- ume datasets.", "rank": 101, "start": 13408, "IsComparative": "0", "id": "st_101"}, {"end": 13662, "text": "Our work on spatially-mapped gene expression profiles extracts expression surfaces from thousands of gene expression profiles.", "rank": 102, "start": 13536, "IsComparative": "1", "id": "st_102"}, {"end": 13786, "text": "Clustering similar trajectories geo- metrically discovers visually similar patterns in time-varying geospatial trajectories.", "rank": 103, "start": 13662, "IsComparative": "0", "id": "st_103"}]}, {"paragraph_info": {"end": 14748, "start": 13786, "text": "Data Scalability: We show our visual information discovery can be implemented in a scalable fashion.For spatially large 2D images, we implement sliding-window image saliency computation in an out-of-core fashion on GPUs.We observe that meaningful volumetric segments can be found in the intensity-gradient histogram of a 3D dataset.This 2D histogram is independent of the volume size, thus allowing us to process a large amount of data.We use parallelizable and GPU-friendly techniques, such as tensor voting and isosurface algorithms, to extract expression surfaces from spatially-mapped volumet- ric gene expression profiles.We enable efficient clustering of time-varying geospatial tra- jectories by mapping a sequence of points onto a high-dimensional point through random projections.This mapping allows us to apply some highly scalable point-based clustering and community detection algorithms to hundreds of thousands of trajectories within a few minutes.", "rank": 29, "paragraph_comparative_number": 2, "entities": [], "id": "p_29"}, "sentences": [{"end": 13886, "text": "Data Scalability: We show our visual information discovery can be implemented in a scalable fashion.", "rank": 104, "start": 13786, "IsComparative": "0", "id": "st_104"}, {"end": 14006, "text": "For spatially large 2D images, we implement sliding-window image saliency computation in an out-of-core fashion on GPUs.", "rank": 105, "start": 13886, "IsComparative": "1", "id": "st_105"}, {"end": 14118, "text": "We observe that meaningful volumetric segments can be found in the intensity-gradient histogram of a 3D dataset.", "rank": 106, "start": 14006, "IsComparative": "0", "id": "st_106"}, {"end": 14222, "text": "This 2D histogram is independent of the volume size, thus allowing us to process a large amount of data.", "rank": 107, "start": 14118, "IsComparative": "1", "id": "st_107"}, {"end": 14413, "text": "We use parallelizable and GPU-friendly techniques, such as tensor voting and isosurface algorithms, to extract expression surfaces from spatially-mapped volumet- ric gene expression profiles.", "rank": 108, "start": 14222, "IsComparative": "0", "id": "st_108"}, {"end": 14575, "text": "We enable efficient clustering of time-varying geospatial tra- jectories by mapping a sequence of points onto a high-dimensional point through random projections.", "rank": 109, "start": 14413, "IsComparative": "0", "id": "st_109"}, {"end": 14748, "text": "This mapping allows us to apply some highly scalable point-based clustering and community detection algorithms to hundreds of thousands of trajectories within a few minutes.", "rank": 110, "start": 14575, "IsComparative": "0", "id": "st_110"}]}, {"paragraph_info": {"end": 15331, "start": 14748, "text": "Interaction and Visualization: We provide efficient visualization and exploration mech- anisms for users to associate their knowledge with the data.We visualize small informa- tive regions on very large images and allow users to interactively refine the results.Users hierarchically explore machine segmented components in a volume dataset.We use a sur- face representation to visualize many coherently expressed genes within a user-specified anatomical brain structure.Clusters and communities of geospatial trajectories allow users to visually identify patterns and spot anomalies.", "rank": 30, "paragraph_comparative_number": 1, "entities": [], "id": "p_30"}, "sentences": [{"end": 14896, "text": "Interaction and Visualization: We provide efficient visualization and exploration mech- anisms for users to associate their knowledge with the data.", "rank": 111, "start": 14748, "IsComparative": "1", "id": "st_111"}, {"end": 15010, "text": "We visualize small informa- tive regions on very large images and allow users to interactively refine the results.", "rank": 112, "start": 14896, "IsComparative": "0", "id": "st_112"}, {"end": 15088, "text": "Users hierarchically explore machine segmented components in a volume dataset.", "rank": 113, "start": 15010, "IsComparative": "0", "id": "st_113"}, {"end": 15218, "text": "We use a sur- face representation to visualize many coherently expressed genes within a user-specified anatomical brain structure.", "rank": 114, "start": 15088, "IsComparative": "0", "id": "st_114"}, {"end": 15331, "text": "Clusters and communities of geospatial trajectories allow users to visually identify patterns and spot anomalies.", "rank": 115, "start": 15218, "IsComparative": "0", "id": "st_115"}]}, {"paragraph_info": {"end": 16061, "start": 15331, "text": "The remainder of this dissertation is organized as follows: In Chapter 2 we re- view related work on visual data analysis.In Chapter 3, we show how the computational saliency model can facilitate the navigation in very large landscape images.In Chapter 4, we describe how to explore volume datasets with a multilevel segmentation of intensity- gradient histogram.In Chapter 5, we show how to extract and visualize gene expression surfaces from volumetric brain images with thousands of spatially-mapped gene expres- sion profiles.In Chapter 6, we cluster time-varying geospatial trajectories with the ap- proximate kernel distance framework.Chapter 7 concludes this dissertation and discusses about the directions for future work.", "rank": 31, "paragraph_comparative_number": 2, "entities": [], "id": "p_31"}, "sentences": [{"end": 15453, "text": "The remainder of this dissertation is organized as follows: In Chapter 2 we re- view related work on visual data analysis.", "rank": 116, "start": 15331, "IsComparative": "0", "id": "st_116"}, {"end": 15573, "text": "In Chapter 3, we show how the computational saliency model can facilitate the navigation in very large landscape images.", "rank": 117, "start": 15453, "IsComparative": "1", "id": "st_117"}, {"end": 15694, "text": "In Chapter 4, we describe how to explore volume datasets with a multilevel segmentation of intensity- gradient histogram.", "rank": 118, "start": 15573, "IsComparative": "1", "id": "st_118"}, {"end": 15861, "text": "In Chapter 5, we show how to extract and visualize gene expression surfaces from volumetric brain images with thousands of spatially-mapped gene expres- sion profiles.", "rank": 119, "start": 15694, "IsComparative": "0", "id": "st_119"}, {"end": 15972, "text": "In Chapter 6, we cluster time-varying geospatial trajectories with the ap- proximate kernel distance framework.", "rank": 120, "start": 15861, "IsComparative": "0", "id": "st_120"}, {"end": 16061, "text": "Chapter 7 concludes this dissertation and discusses about the directions for future work.", "rank": 121, "start": 15972, "IsComparative": "0", "id": "st_121"}]}, {"paragraph_info": {"end": 16083, "start": 16061, "text": "Chapter 2 Related Work", "rank": 32, "paragraph_comparative_number": 0, "entities": [], "id": "p_32"}, "sentences": [{"end": 16083, "text": "Chapter 2 Related Work", "rank": 122, "start": 16061, "IsComparative": "0", "id": "st_122"}]}, {"paragraph_info": {"end": 16287, "start": 16083, "text": "In this chapter, we review the current tools on visual data analysis.We focus on the tools and analysis that are related to our results on large images, volumes, brain images, and geospatial trajectories.", "rank": 33, "paragraph_comparative_number": 1, "entities": [], "id": "p_33"}, "sentences": [{"end": 16152, "text": "In this chapter, we review the current tools on visual data analysis.", "rank": 123, "start": 16083, "IsComparative": "0", "id": "st_123"}, {"end": 16287, "text": "We focus on the tools and analysis that are related to our results on large images, volumes, brain images, and geospatial trajectories.", "rank": 124, "start": 16152, "IsComparative": "1", "id": "st_124"}]}, {"paragraph_info": {"end": 16321, "start": 16287, "text": "2.1 Overcoming Display Limitations", "rank": 34, "paragraph_comparative_number": 0, "entities": [], "id": "p_34"}, "sentences": [{"end": 16321, "text": "2.1 Overcoming Display Limitations", "rank": 125, "start": 16287, "IsComparative": "0", "id": "st_125"}]}, {"paragraph_info": {"end": 17821, "start": 16321, "text": "Over the years a number of techniques have evolved to address limitations of the display medium with respect to the visual data.If the input data has more bits of color information than those that can be displayed, we use tone mapping to approximate the appearance of high-dynamic range images <28>.This involves mapping the color space from a high-dimensional input to a low-dimensional output, while preserving most of the salient content.Similarly, video summarization techniques <26> typically involve extrac- tion of the salient key-frames with some context that results in warping of the temporal space.Recent research has also looked at how to carry out image warping so that images that are larger than the display can be adaptively resized to preserve their most salient con- tent <4, 133>.Most recently, Laffont et al.<92> present content-aware zooming on images up to 16 megapixels.While such image re-targeting techniques could be effective for im- ages that are an order of magnitude larger than the displays, they do not scale well to three orders of magnitude or more that we desire.In In Chapter 3 we present distortion-free navigation of very large images, assisted by identification of their most salient content, to allow viewing of very large images on displays of modest sizes.Unlike the previously discussed methods, visualization by navigation maintains the metric fidelity of the image.The pan and zoom interactions allow the users to follow the local image context naturally.", "rank": 35, "paragraph_comparative_number": 8, "entities": [], "id": "p_35"}, "sentences": [{"end": 16449, "text": "Over the years a number of techniques have evolved to address limitations of the display medium with respect to the visual data.", "rank": 126, "start": 16321, "IsComparative": "0", "id": "st_126"}, {"end": 16620, "text": "If the input data has more bits of color information than those that can be displayed, we use tone mapping to approximate the appearance of high-dynamic range images <28>.", "rank": 127, "start": 16449, "IsComparative": "1", "id": "st_127"}, {"end": 16762, "text": "This involves mapping the color space from a high-dimensional input to a low-dimensional output, while preserving most of the salient content.", "rank": 128, "start": 16620, "IsComparative": "1", "id": "st_128"}, {"end": 16930, "text": "Similarly, video summarization techniques <26> typically involve extrac- tion of the salient key-frames with some context that results in warping of the temporal space.", "rank": 129, "start": 16762, "IsComparative": "1", "id": "st_129"}, {"end": 17120, "text": "Recent research has also looked at how to carry out image warping so that images that are larger than the display can be adaptively resized to preserve their most salient con- tent <4, 133>.", "rank": 130, "start": 16930, "IsComparative": "1", "id": "st_130"}, {"end": 17149, "text": "Most recently, Laffont et al.", "rank": 131, "start": 17120, "IsComparative": "0", "id": "st_131"}, {"end": 17214, "text": "<92> present content-aware zooming on images up to 16 megapixels.", "rank": 132, "start": 17149, "IsComparative": "1", "id": "st_132"}, {"end": 17419, "text": "While such image re-targeting techniques could be effective for im- ages that are an order of magnitude larger than the displays, they do not scale well to three orders of magnitude or more that we desire.", "rank": 133, "start": 17214, "IsComparative": "1", "id": "st_133"}, {"end": 17619, "text": "In In Chapter 3 we present distortion-free navigation of very large images, assisted by identification of their most salient content, to allow viewing of very large images on displays of modest sizes.", "rank": 134, "start": 17419, "IsComparative": "0", "id": "st_134"}, {"end": 17731, "text": "Unlike the previously discussed methods, visualization by navigation maintains the metric fidelity of the image.", "rank": 135, "start": 17619, "IsComparative": "1", "id": "st_135"}, {"end": 17821, "text": "The pan and zoom interactions allow the users to follow the local image context naturally.", "rank": 136, "start": 17731, "IsComparative": "1", "id": "st_136"}]}, {"paragraph_info": {"end": 17858, "start": 17821, "text": "2.2 Scene Analysis and Image Saliency", "rank": 36, "paragraph_comparative_number": 0, "entities": [], "id": "p_36"}, "sentences": [{"end": 17858, "text": "2.2 Scene Analysis and Image Saliency", "rank": 137, "start": 17821, "IsComparative": "0", "id": "st_137"}]}, {"paragraph_info": {"end": 18255, "start": 17858, "text": "Image saliency has been used in modeling visual attention.Top-down and bottom- up models for building a saliency map have been introduced by Tsotsos et al.<159>, Itti et al.<60> and several others.Jacobs <62> discusses which viewpoint invariant properties are salient.Suh et al.<149> use image saliency to crop thumbnails from images.Oliva et al.<116> apply the top-down model to object detection.", "rank": 37, "paragraph_comparative_number": 3, "entities": [], "id": "p_37"}, "sentences": [{"end": 17916, "text": "Image saliency has been used in modeling visual attention.", "rank": 138, "start": 17858, "IsComparative": "0", "id": "st_138"}, {"end": 18013, "text": "Top-down and bottom- up models for building a saliency map have been introduced by Tsotsos et al.", "rank": 139, "start": 17916, "IsComparative": "0", "id": "st_139"}, {"end": 18031, "text": "<159>, Itti et al.", "rank": 140, "start": 18013, "IsComparative": "1", "id": "st_140"}, {"end": 18055, "text": "<60> and several others.", "rank": 141, "start": 18031, "IsComparative": "1", "id": "st_141"}, {"end": 18126, "text": "Jacobs <62> discusses which viewpoint invariant properties are salient.", "rank": 142, "start": 18055, "IsComparative": "0", "id": "st_142"}, {"end": 18136, "text": "Suh et al.", "rank": 143, "start": 18126, "IsComparative": "0", "id": "st_143"}, {"end": 18192, "text": "<149> use image saliency to crop thumbnails from images.", "rank": 144, "start": 18136, "IsComparative": "0", "id": "st_144"}, {"end": 18204, "text": "Oliva et al.", "rank": 145, "start": 18192, "IsComparative": "0", "id": "st_145"}, {"end": 18255, "text": "<116> apply the top-down model to object detection.", "rank": 146, "start": 18204, "IsComparative": "1", "id": "st_146"}]}, {"paragraph_info": {"end": 18709, "start": 18255, "text": "Recent approaches include work by Hou and Zhang <50> that computes image saliency by the difference of the images original and smoothed log-Fourier spectrum.Bruce et al.<13> learn a set of sparse code from example images to evaluate saliency of new images.Wang et al.<165> use random graph walk on image pixels to compute image saliency.Goferman et al.<43> consider visual organization and high level features such as human faces in saliency computation.", "rank": 38, "paragraph_comparative_number": 3, "entities": [], "id": "p_38"}, "sentences": [{"end": 18412, "text": "Recent approaches include work by Hou and Zhang <50> that computes image saliency by the difference of the images original and smoothed log-Fourier spectrum.", "rank": 147, "start": 18255, "IsComparative": "0", "id": "st_147"}, {"end": 18424, "text": "Bruce et al.", "rank": 148, "start": 18412, "IsComparative": "0", "id": "st_148"}, {"end": 18511, "text": "<13> learn a set of sparse code from example images to evaluate saliency of new images.", "rank": 149, "start": 18424, "IsComparative": "1", "id": "st_149"}, {"end": 18522, "text": "Wang et al.", "rank": 150, "start": 18511, "IsComparative": "0", "id": "st_150"}, {"end": 18592, "text": "<165> use random graph walk on image pixels to compute image saliency.", "rank": 151, "start": 18522, "IsComparative": "1", "id": "st_151"}, {"end": 18607, "text": "Goferman et al.", "rank": 152, "start": 18592, "IsComparative": "0", "id": "st_152"}, {"end": 18709, "text": "<43> consider visual organization and high level features such as human faces in saliency computation.", "rank": 153, "start": 18607, "IsComparative": "1", "id": "st_153"}]}, {"paragraph_info": {"end": 19312, "start": 18709, "text": "In spite of the impressive advances in the recognition of specific objects, such as buildings, cars, and humans, general scene understanding remains a hard problem <47>.State-of-the-art systems <20, 100, 136> train on web-scale databases of small images and then extract regions of interests for test scenes in a supervised manner.More recently, Kim and Torralba <80> use alternating optimization on sets of unlabeled images to extract one to three regions of interest per image.Our system needs a more general approach since we expect a variety of regions and objects of interest in a very large image.", "rank": 39, "paragraph_comparative_number": 3, "entities": [], "id": "p_39"}, "sentences": [{"end": 18878, "text": "In spite of the impressive advances in the recognition of specific objects, such as buildings, cars, and humans, general scene understanding remains a hard problem <47>.", "rank": 154, "start": 18709, "IsComparative": "1", "id": "st_154"}, {"end": 19040, "text": "State-of-the-art systems <20, 100, 136> train on web-scale databases of small images and then extract regions of interests for test scenes in a supervised manner.", "rank": 155, "start": 18878, "IsComparative": "0", "id": "st_155"}, {"end": 19188, "text": "More recently, Kim and Torralba <80> use alternating optimization on sets of unlabeled images to extract one to three regions of interest per image.", "rank": 156, "start": 19040, "IsComparative": "1", "id": "st_156"}, {"end": 19312, "text": "Our system needs a more general approach since we expect a variety of regions and objects of interest in a very large image.", "rank": 157, "start": 19188, "IsComparative": "1", "id": "st_157"}]}, {"paragraph_info": {"end": 20149, "start": 19312, "text": "Although there has been extensive previous work in identifying salient regions us- ing several methods, such techniques typically extract a very small number of regions from a relatively small image.For instance, Goferman et al.s <43> program requires 74 seconds to process a 250  142 image, and Bruce et al.s <13> program requires 30 minutes to process a 3000  1500 image.These timings are on a current state-of-the-art worksta- tion described in Section 3.6.Assuming their running time scales linearly and memory swapping does not become an issue, these approaches will take hundreds of hours to pro- cess gigapixel-sized images.The purpose of this is not to downplay the achievements of these approaches, which are actually quite impressive in what they are targeting, rather to highlight the difference in their approaches from ours.", "rank": 40, "paragraph_comparative_number": 2, "entities": [], "id": "p_40"}, "sentences": [{"end": 19511, "text": "Although there has been extensive previous work in identifying salient regions us- ing several methods, such techniques typically extract a very small number of regions from a relatively small image.", "rank": 158, "start": 19312, "IsComparative": "0", "id": "st_158"}, {"end": 19685, "text": "For instance, Goferman et al.s <43> program requires 74 seconds to process a 250  142 image, and Bruce et al.s <13> program requires 30 minutes to process a 3000  1500 image.", "rank": 159, "start": 19511, "IsComparative": "1", "id": "st_159"}, {"end": 19772, "text": "These timings are on a current state-of-the-art worksta- tion described in Section 3.6.", "rank": 160, "start": 19685, "IsComparative": "0", "id": "st_160"}, {"end": 19943, "text": "Assuming their running time scales linearly and memory swapping does not become an issue, these approaches will take hundreds of hours to pro- cess gigapixel-sized images.", "rank": 161, "start": 19772, "IsComparative": "1", "id": "st_161"}, {"end": 20149, "text": "The purpose of this is not to downplay the achievements of these approaches, which are actually quite impressive in what they are targeting, rather to highlight the difference in their approaches from ours.", "rank": 162, "start": 19943, "IsComparative": "0", "id": "st_162"}]}, {"paragraph_info": {"end": 20593, "start": 20149, "text": "We believe user interaction in the visualization process can greatly assist in rapid culling of false positives and can greatly enhance the overall computational efficiency of the resulting algorithms.Our approach adopts a three-step process of progressive culling of potential regions of interest.We believe this provides a better balance of accuracy and computational efficiency with a user in the middle than a purely computational approach.", "rank": 41, "paragraph_comparative_number": 2, "entities": [], "id": "p_41"}, "sentences": [{"end": 20350, "text": "We believe user interaction in the visualization process can greatly assist in rapid culling of false positives and can greatly enhance the overall computational efficiency of the resulting algorithms.", "rank": 163, "start": 20149, "IsComparative": "1", "id": "st_163"}, {"end": 20447, "text": "Our approach adopts a three-step process of progressive culling of potential regions of interest.", "rank": 164, "start": 20350, "IsComparative": "1", "id": "st_164"}, {"end": 20593, "text": "We believe this provides a better balance of accuracy and computational efficiency with a user in the middle than a purely computational approach.", "rank": 165, "start": 20447, "IsComparative": "0", "id": "st_165"}]}, {"paragraph_info": {"end": 20617, "start": 20593, "text": "2.3 Visual Data Analysis", "rank": 42, "paragraph_comparative_number": 0, "entities": [], "id": "p_42"}, "sentences": [{"end": 20617, "text": "2.3 Visual Data Analysis", "rank": 166, "start": 20593, "IsComparative": "0", "id": "st_166"}]}, {"paragraph_info": {"end": 21333, "start": 20617, "text": "There is a rich history of data analysis for visual summarization and identification of information-rich subspaces for effective visual presentation.We next present a few exam- ple of how salience is defined and used for visual datasets to enhance their depiction.No- table advances on 3D datasets include defining saliency for polygonal meshes <94>, com- paring it to human eye movements <85>, and illuminating meshes based on saliency <93>.Howlett et al.<51> use eye-tracking data to identify salient features on meshes and carry outuserstudiestovalidatetheirfindings.Kimetal.presentandvalidatesaliency-based enhancement operators to guide visual attention in volume visualization <83> and geomet- ric meshes <84>.", "rank": 43, "paragraph_comparative_number": 3, "entities": [], "id": "p_43"}, "sentences": [{"end": 20766, "text": "There is a rich history of data analysis for visual summarization and identification of information-rich subspaces for effective visual presentation.", "rank": 167, "start": 20617, "IsComparative": "0", "id": "st_167"}, {"end": 20881, "text": "We next present a few exam- ple of how salience is defined and used for visual datasets to enhance their depiction.", "rank": 168, "start": 20766, "IsComparative": "1", "id": "st_168"}, {"end": 21059, "text": "No- table advances on 3D datasets include defining saliency for polygonal meshes <94>, com- paring it to human eye movements <85>, and illuminating meshes based on saliency <93>.", "rank": 169, "start": 20881, "IsComparative": "1", "id": "st_169"}, {"end": 21073, "text": "Howlett et al.", "rank": 170, "start": 21059, "IsComparative": "0", "id": "st_170"}, {"end": 21195, "text": "<51> use eye-tracking data to identify salient features on meshes and carry outuserstudiestovalidatetheirfindings.Kimetal.", "rank": 171, "start": 21073, "IsComparative": "0", "id": "st_171"}, {"end": 21333, "text": "presentandvalidatesaliency-based enhancement operators to guide visual attention in volume visualization <83> and geomet- ric meshes <84>.", "rank": 172, "start": 21195, "IsComparative": "1", "id": "st_172"}]}, {"paragraph_info": {"end": 22501, "start": 21333, "text": "Machiraju et al.<104> present a system to detect contextually significant multiscale features in very large datasets directly in the wavelet domain and visualize them pro- gressively.Bordoloi and Shen <12> select informative views of volumetric data based on saliency defined using entropy measures.Viola et al.<163> determine the most ex- pressive view for a selected region of interest in a volume using mutual information.Bruckner and Mo ller <14> use isosurface similarity maps based on mutual information to automatically select the most salient isosurfaces.Saliency-based summarization of time-varying datasets has been carried out for videos <26> and molecular dynamics sim- ulations <123>.Wiebel et al.<168> identify salience with the vortices that originate from walls in three-dimensional time-dependent vector fields and track their evolution using generalized streak lines.More recently, Information contents of datasets have been ex- tensively used to compact representations and visualizations.Ja nicke <66, 65> and Chen <64> use evaluate information content to better visualize flows.Kim and JaJa <81> con- struct isosurfaces from entropy-based octrees.", "rank": 44, "paragraph_comparative_number": 5, "entities": [], "id": "p_44"}, "sentences": [{"end": 21349, "text": "Machiraju et al.", "rank": 173, "start": 21333, "IsComparative": "0", "id": "st_173"}, {"end": 21516, "text": "<104> present a system to detect contextually significant multiscale features in very large datasets directly in the wavelet domain and visualize them pro- gressively.", "rank": 174, "start": 21349, "IsComparative": "1", "id": "st_174"}, {"end": 21632, "text": "Bordoloi and Shen <12> select informative views of volumetric data based on saliency defined using entropy measures.", "rank": 175, "start": 21516, "IsComparative": "0", "id": "st_175"}, {"end": 21644, "text": "Viola et al.", "rank": 176, "start": 21632, "IsComparative": "0", "id": "st_176"}, {"end": 21758, "text": "<163> determine the most ex- pressive view for a selected region of interest in a volume using mutual information.", "rank": 177, "start": 21644, "IsComparative": "0", "id": "st_177"}, {"end": 21896, "text": "Bruckner and Mo ller <14> use isosurface similarity maps based on mutual information to automatically select the most salient isosurfaces.", "rank": 178, "start": 21758, "IsComparative": "0", "id": "st_178"}, {"end": 22030, "text": "Saliency-based summarization of time-varying datasets has been carried out for videos <26> and molecular dynamics sim- ulations <123>.", "rank": 179, "start": 21896, "IsComparative": "1", "id": "st_179"}, {"end": 22043, "text": "Wiebel et al.", "rank": 180, "start": 22030, "IsComparative": "0", "id": "st_180"}, {"end": 22218, "text": "<168> identify salience with the vortices that originate from walls in three-dimensional time-dependent vector fields and track their evolution using generalized streak lines.", "rank": 181, "start": 22043, "IsComparative": "1", "id": "st_181"}, {"end": 22341, "text": "More recently, Information contents of datasets have been ex- tensively used to compact representations and visualizations.", "rank": 182, "start": 22218, "IsComparative": "0", "id": "st_182"}, {"end": 22432, "text": "Ja nicke <66, 65> and Chen <64> use evaluate information content to better visualize flows.", "rank": 183, "start": 22341, "IsComparative": "1", "id": "st_183"}, {"end": 22501, "text": "Kim and JaJa <81> con- struct isosurfaces from entropy-based octrees.", "rank": 184, "start": 22432, "IsComparative": "1", "id": "st_184"}]}, {"paragraph_info": {"end": 22633, "start": 22501, "text": "Unlike much of the previous work on volumetric or time-varying data, the focus of our work is on visualization of very large images.", "rank": 45, "paragraph_comparative_number": 1, "entities": [], "id": "p_45"}, "sentences": [{"end": 22633, "text": "Unlike much of the previous work on volumetric or time-varying data, the focus of our work is on visualization of very large images.", "rank": 185, "start": 22501, "IsComparative": "1", "id": "st_185"}]}, {"paragraph_info": {"end": 22661, "start": 22633, "text": "2.4 Transfer Function Design", "rank": 46, "paragraph_comparative_number": 0, "entities": [], "id": "p_46"}, "sentences": [{"end": 22661, "text": "2.4 Transfer Function Design", "rank": 186, "start": 22633, "IsComparative": "0", "id": "st_186"}]}, {"paragraph_info": {"end": 23780, "start": 22661, "text": "Transfer functions directly influence the visualization by assigning optical proper- ties such as color and opacity to voxels.Previous work has devoted a lot of effort on transfer function generation.Pfister et al.<126> present a survey of different approaches to transfer function design.Traditionally, a transfer function maps voxels to colors and opacity according to a 1D function of the scalar values.Subsequent work has consid- ered multiple attributes and has involved the design of transfer functions using multiple dimensions.Fujishiro et al.<38> and Zhou et al.<177> analyze the topology of the scalar field to generate transfer functions.Tzeng et al.<160> paint on the volume data to design high-dimensional transfer functions.Sereda et al.<141> compute LH histograms to detect material boundaries and transfer functions.Salama et al.<137> include abstract semantic attributes to assist in domain-specific visualization design.Correa and Ma <23, 24> have recently incorporate size and visibility into transfer functions.Ruiz et al.<135> generate automatic transfer functions based on information divergences.", "rank": 47, "paragraph_comparative_number": 9, "entities": [], "id": "p_47"}, "sentences": [{"end": 22787, "text": "Transfer functions directly influence the visualization by assigning optical proper- ties such as color and opacity to voxels.", "rank": 187, "start": 22661, "IsComparative": "1", "id": "st_187"}, {"end": 22861, "text": "Previous work has devoted a lot of effort on transfer function generation.", "rank": 188, "start": 22787, "IsComparative": "0", "id": "st_188"}, {"end": 22875, "text": "Pfister et al.", "rank": 189, "start": 22861, "IsComparative": "0", "id": "st_189"}, {"end": 22950, "text": "<126> present a survey of different approaches to transfer function design.", "rank": 190, "start": 22875, "IsComparative": "1", "id": "st_190"}, {"end": 23067, "text": "Traditionally, a transfer function maps voxels to colors and opacity according to a 1D function of the scalar values.", "rank": 191, "start": 22950, "IsComparative": "1", "id": "st_191"}, {"end": 23196, "text": "Subsequent work has consid- ered multiple attributes and has involved the design of transfer functions using multiple dimensions.", "rank": 192, "start": 23067, "IsComparative": "1", "id": "st_192"}, {"end": 23212, "text": "Fujishiro et al.", "rank": 193, "start": 23196, "IsComparative": "0", "id": "st_193"}, {"end": 23232, "text": "<38> and Zhou et al.", "rank": 194, "start": 23212, "IsComparative": "1", "id": "st_194"}, {"end": 23310, "text": "<177> analyze the topology of the scalar field to generate transfer functions.", "rank": 195, "start": 23232, "IsComparative": "1", "id": "st_195"}, {"end": 23322, "text": "Tzeng et al.", "rank": 196, "start": 23310, "IsComparative": "0", "id": "st_196"}, {"end": 23399, "text": "<160> paint on the volume data to design high-dimensional transfer functions.", "rank": 197, "start": 23322, "IsComparative": "1", "id": "st_197"}, {"end": 23412, "text": "Sereda et al.", "rank": 198, "start": 23399, "IsComparative": "0", "id": "st_198"}, {"end": 23493, "text": "<141> compute LH histograms to detect material boundaries and transfer functions.", "rank": 199, "start": 23412, "IsComparative": "1", "id": "st_199"}, {"end": 23506, "text": "Salama et al.", "rank": 200, "start": 23493, "IsComparative": "0", "id": "st_200"}, {"end": 23599, "text": "<137> include abstract semantic attributes to assist in domain-specific visualization design.", "rank": 201, "start": 23506, "IsComparative": "0", "id": "st_201"}, {"end": 23692, "text": "Correa and Ma <23, 24> have recently incorporate size and visibility into transfer functions.", "rank": 202, "start": 23599, "IsComparative": "1", "id": "st_202"}, {"end": 23703, "text": "Ruiz et al.", "rank": 203, "start": 23692, "IsComparative": "0", "id": "st_203"}, {"end": 23780, "text": "<135> generate automatic transfer functions based on information divergences.", "rank": 204, "start": 23703, "IsComparative": "0", "id": "st_204"}]}, {"paragraph_info": {"end": 24689, "start": 23780, "text": "A popular transfer function attribute is the derivatives of the scalar field, often the gradient of the intensity.Kindlmann and Durkin <86> use the derivatives to show better separation of materials and boundaries.Kniss et al.<87> use fixed shape widgets to in- teractively design 2D transfer functions.Roettger et al.<131> create transfer functions by clustering the 2D volume histogram according to the spatial connectivity of the volume dataset.Users interact with a 1D histogram to manipulate the 2D non-parametric seg- ments in Maciejewski et al.s system <105>.Instead of the volume histograms, Selver and Gu zelic  <140> initialize the transfer function by fitting radial basis functions to the histograms of the image slices in a volume dataset.Most recently, Wang et al.<167> learn a Gaussian Mixture Model from the volumetric scalar field and use the resulting ellipses to compose transfer functions.", "rank": 48, "paragraph_comparative_number": 5, "entities": [], "id": "p_48"}, "sentences": [{"end": 23894, "text": "A popular transfer function attribute is the derivatives of the scalar field, often the gradient of the intensity.", "rank": 205, "start": 23780, "IsComparative": "0", "id": "st_205"}, {"end": 23994, "text": "Kindlmann and Durkin <86> use the derivatives to show better separation of materials and boundaries.", "rank": 206, "start": 23894, "IsComparative": "1", "id": "st_206"}, {"end": 24006, "text": "Kniss et al.", "rank": 207, "start": 23994, "IsComparative": "0", "id": "st_207"}, {"end": 24083, "text": "<87> use fixed shape widgets to in- teractively design 2D transfer functions.", "rank": 208, "start": 24006, "IsComparative": "1", "id": "st_208"}, {"end": 24098, "text": "Roettger et al.", "rank": 209, "start": 24083, "IsComparative": "0", "id": "st_209"}, {"end": 24228, "text": "<131> create transfer functions by clustering the 2D volume histogram according to the spatial connectivity of the volume dataset.", "rank": 210, "start": 24098, "IsComparative": "1", "id": "st_210"}, {"end": 24346, "text": "Users interact with a 1D histogram to manipulate the 2D non-parametric seg- ments in Maciejewski et al.s system <105>.", "rank": 211, "start": 24228, "IsComparative": "0", "id": "st_211"}, {"end": 24532, "text": "Instead of the volume histograms, Selver and Gu zelic  <140> initialize the transfer function by fitting radial basis functions to the histograms of the image slices in a volume dataset.", "rank": 212, "start": 24346, "IsComparative": "1", "id": "st_212"}, {"end": 24558, "text": "Most recently, Wang et al.", "rank": 213, "start": 24532, "IsComparative": "0", "id": "st_213"}, {"end": 24689, "text": "<167> learn a Gaussian Mixture Model from the volumetric scalar field and use the resulting ellipses to compose transfer functions.", "rank": 214, "start": 24558, "IsComparative": "1", "id": "st_214"}]}, {"paragraph_info": {"end": 25039, "start": 24689, "text": "In Chapter 4, we show how to automatically identify segments of interest from the intensity-gradient histograms.We organize these segments from coarse to fine to facilitate the exploration process.Our segments are non-parametric and tightly cover the feature space.Users can interact with these segments directly on the intensity-gradient histograms.", "rank": 49, "paragraph_comparative_number": 1, "entities": [], "id": "p_49"}, "sentences": [{"end": 24801, "text": "In Chapter 4, we show how to automatically identify segments of interest from the intensity-gradient histograms.", "rank": 215, "start": 24689, "IsComparative": "0", "id": "st_215"}, {"end": 24886, "text": "We organize these segments from coarse to fine to facilitate the exploration process.", "rank": 216, "start": 24801, "IsComparative": "0", "id": "st_216"}, {"end": 24954, "text": "Our segments are non-parametric and tightly cover the feature space.", "rank": 217, "start": 24886, "IsComparative": "1", "id": "st_217"}, {"end": 25039, "text": "Users can interact with these segments directly on the intensity-gradient histograms.", "rank": 218, "start": 24954, "IsComparative": "0", "id": "st_218"}]}, {"paragraph_info": {"end": 25067, "start": 25039, "text": "2.5 Visual Data Segmentation", "rank": 50, "paragraph_comparative_number": 0, "entities": [], "id": "p_50"}, "sentences": [{"end": 25067, "text": "2.5 Visual Data Segmentation", "rank": 219, "start": 25039, "IsComparative": "0", "id": "st_219"}]}, {"paragraph_info": {"end": 25815, "start": 25067, "text": "Separating 2D images and 3D volumes into meaningful regions is a long-standing and challenging problem.Here we present a small subset of recent results from the vast literature on this topic.Freixenet et al.<37> survey different approaches to segment 2D images.Mean-shift image segmentation <22> treats the image as probability distribution and finds the segmentation according to local maxima.Graph-based segmentation ap- proaches model the pixels as nodes and the image as a connected graph and then they par- tition the graph to solve the segmentation problem.Felzenszwalb and Huttenlocher <32> use a boundary predicate and a greedy algorithm to segment images.Sharon et al.<142> introduce an algebraic multigrid inspired segmentation algorithm.", "rank": 51, "paragraph_comparative_number": 4, "entities": [], "id": "p_51"}, "sentences": [{"end": 25170, "text": "Separating 2D images and 3D volumes into meaningful regions is a long-standing and challenging problem.", "rank": 220, "start": 25067, "IsComparative": "1", "id": "st_220"}, {"end": 25258, "text": "Here we present a small subset of recent results from the vast literature on this topic.", "rank": 221, "start": 25170, "IsComparative": "0", "id": "st_221"}, {"end": 25274, "text": "Freixenet et al.", "rank": 222, "start": 25258, "IsComparative": "0", "id": "st_222"}, {"end": 25328, "text": "<37> survey different approaches to segment 2D images.", "rank": 223, "start": 25274, "IsComparative": "1", "id": "st_223"}, {"end": 25461, "text": "Mean-shift image segmentation <22> treats the image as probability distribution and finds the segmentation according to local maxima.", "rank": 224, "start": 25328, "IsComparative": "1", "id": "st_224"}, {"end": 25630, "text": "Graph-based segmentation ap- proaches model the pixels as nodes and the image as a connected graph and then they par- tition the graph to solve the segmentation problem.", "rank": 225, "start": 25461, "IsComparative": "0", "id": "st_225"}, {"end": 25731, "text": "Felzenszwalb and Huttenlocher <32> use a boundary predicate and a greedy algorithm to segment images.", "rank": 226, "start": 25630, "IsComparative": "1", "id": "st_226"}, {"end": 25744, "text": "Sharon et al.", "rank": 227, "start": 25731, "IsComparative": "0", "id": "st_227"}, {"end": 25815, "text": "<142> introduce an algebraic multigrid inspired segmentation algorithm.", "rank": 228, "start": 25744, "IsComparative": "0", "id": "st_228"}]}, {"paragraph_info": {"end": 27112, "start": 25815, "text": "3D volume segmentation is a natural extension to the 2D image segmentation prob- lem.Huang and Ma <52> apply the region-growing technique to segment volumes.Sher- bondy et al.<143> use programmable graphics hardware to accelerate volume segmenta- tion.Tzeng and Ma <161> cluster volume datasets with the ISODATA algorithm.Seg- mentation of various organs from medical images is an important application.Level-set methods <7, 178> have been used to segment 3D brain images.Grady et al.<44> apply random-walk segmentation to detect organs from medical volumes.2-point and N-point correlation function features <68, 110> have been used to classify 3D tissue im- ages.Fuller et al.<39> use support-vector machines to segment retinal layers.Janoos et al.<69, 70> segment, reconstruct, and visualize dendritic spines in 3D from optical mi- croscopy imaging.The advances in visual computing technologies have enabled segmen- tation and visualization of neurons <49, 164> in brains.Computer segmentation systems are often guided by user interactions <115>.Bartz et al.<9> use a seed point to segment the bronchi in the lungs.Prassni et al.<128> incorporate user guidance to minimize the uncertainties in the brain segmentation.Kniss et al.<88> use supervised manifold distance on brain image segmentation.", "rank": 52, "paragraph_comparative_number": 6, "entities": [], "id": "p_52"}, "sentences": [{"end": 25900, "text": "3D volume segmentation is a natural extension to the 2D image segmentation prob- lem.", "rank": 229, "start": 25815, "IsComparative": "0", "id": "st_229"}, {"end": 25972, "text": "Huang and Ma <52> apply the region-growing technique to segment volumes.", "rank": 230, "start": 25900, "IsComparative": "1", "id": "st_230"}, {"end": 25990, "text": "Sher- bondy et al.", "rank": 231, "start": 25972, "IsComparative": "0", "id": "st_231"}, {"end": 26067, "text": "<143> use programmable graphics hardware to accelerate volume segmenta- tion.", "rank": 232, "start": 25990, "IsComparative": "1", "id": "st_232"}, {"end": 26137, "text": "Tzeng and Ma <161> cluster volume datasets with the ISODATA algorithm.", "rank": 233, "start": 26067, "IsComparative": "0", "id": "st_233"}, {"end": 26218, "text": "Seg- mentation of various organs from medical images is an important application.", "rank": 234, "start": 26137, "IsComparative": "0", "id": "st_234"}, {"end": 26287, "text": "Level-set methods <7, 178> have been used to segment 3D brain images.", "rank": 235, "start": 26218, "IsComparative": "1", "id": "st_235"}, {"end": 26299, "text": "Grady et al.", "rank": 236, "start": 26287, "IsComparative": "0", "id": "st_236"}, {"end": 26373, "text": "<44> apply random-walk segmentation to detect organs from medical volumes.", "rank": 237, "start": 26299, "IsComparative": "0", "id": "st_237"}, {"end": 26479, "text": "2-point and N-point correlation function features <68, 110> have been used to classify 3D tissue im- ages.", "rank": 238, "start": 26373, "IsComparative": "1", "id": "st_238"}, {"end": 26492, "text": "Fuller et al.", "rank": 239, "start": 26479, "IsComparative": "0", "id": "st_239"}, {"end": 26551, "text": "<39> use support-vector machines to segment retinal layers.", "rank": 240, "start": 26492, "IsComparative": "0", "id": "st_240"}, {"end": 26564, "text": "Janoos et al.", "rank": 241, "start": 26551, "IsComparative": "0", "id": "st_241"}, {"end": 26666, "text": "<69, 70> segment, reconstruct, and visualize dendritic spines in 3D from optical mi- croscopy imaging.", "rank": 242, "start": 26564, "IsComparative": "0", "id": "st_242"}, {"end": 26789, "text": "The advances in visual computing technologies have enabled segmen- tation and visualization of neurons <49, 164> in brains.", "rank": 243, "start": 26666, "IsComparative": "0", "id": "st_243"}, {"end": 26863, "text": "Computer segmentation systems are often guided by user interactions <115>.", "rank": 244, "start": 26789, "IsComparative": "0", "id": "st_244"}, {"end": 26875, "text": "Bartz et al.", "rank": 245, "start": 26863, "IsComparative": "0", "id": "st_245"}, {"end": 26932, "text": "<9> use a seed point to segment the bronchi in the lungs.", "rank": 246, "start": 26875, "IsComparative": "1", "id": "st_246"}, {"end": 26946, "text": "Prassni et al.", "rank": 247, "start": 26932, "IsComparative": "0", "id": "st_247"}, {"end": 27034, "text": "<128> incorporate user guidance to minimize the uncertainties in the brain segmentation.", "rank": 248, "start": 26946, "IsComparative": "0", "id": "st_248"}, {"end": 27046, "text": "Kniss et al.", "rank": 249, "start": 27034, "IsComparative": "0", "id": "st_249"}, {"end": 27112, "text": "<88> use supervised manifold distance on brain image segmentation.", "rank": 250, "start": 27046, "IsComparative": "1", "id": "st_250"}]}, {"paragraph_info": {"end": 28037, "start": 27112, "text": "3D volume segmentation is a natural extension to the 2D image segmentation prob- lem.Huang and Ma <52> apply the region growing technique to volume segmenta- tion.Sherbondy et al.<143> accelerate volume segmentation with programmable graphics hardware.Segmentation of organs from medical data is a prime application of volume segmentation.Grady et al.<44> apply random walk segmentation to detect organs from medical volumes.Fuller et al.<39> use support-vector machines to segment retinal layers.Many systems incorporate user guidance to perform interactive segmentation.Bartz et al.<9> use a seeded point to segment the bronchi in the lungs.Prassni et al.<128> incor- porate user guidance to minimize the uncertainties in the segmentation.Kniss et al.<88> use supervised manifold distance to segment volume data.Torsney-Weir et al.<158> esti- mate visual responses to guide the search for the image segmentation parameters.", "rank": 53, "paragraph_comparative_number": 2, "entities": [], "id": "p_53"}, "sentences": [{"end": 27197, "text": "3D volume segmentation is a natural extension to the 2D image segmentation prob- lem.", "rank": 251, "start": 27112, "IsComparative": "0", "id": "st_251"}, {"end": 27275, "text": "Huang and Ma <52> apply the region growing technique to volume segmenta- tion.", "rank": 252, "start": 27197, "IsComparative": "0", "id": "st_252"}, {"end": 27291, "text": "Sherbondy et al.", "rank": 253, "start": 27275, "IsComparative": "0", "id": "st_253"}, {"end": 27364, "text": "<143> accelerate volume segmentation with programmable graphics hardware.", "rank": 254, "start": 27291, "IsComparative": "0", "id": "st_254"}, {"end": 27451, "text": "Segmentation of organs from medical data is a prime application of volume segmentation.", "rank": 255, "start": 27364, "IsComparative": "0", "id": "st_255"}, {"end": 27463, "text": "Grady et al.", "rank": 256, "start": 27451, "IsComparative": "0", "id": "st_256"}, {"end": 27537, "text": "<44> apply random walk segmentation to detect organs from medical volumes.", "rank": 257, "start": 27463, "IsComparative": "0", "id": "st_257"}, {"end": 27550, "text": "Fuller et al.", "rank": 258, "start": 27537, "IsComparative": "0", "id": "st_258"}, {"end": 27609, "text": "<39> use support-vector machines to segment retinal layers.", "rank": 259, "start": 27550, "IsComparative": "0", "id": "st_259"}, {"end": 27684, "text": "Many systems incorporate user guidance to perform interactive segmentation.", "rank": 260, "start": 27609, "IsComparative": "0", "id": "st_260"}, {"end": 27696, "text": "Bartz et al.", "rank": 261, "start": 27684, "IsComparative": "0", "id": "st_261"}, {"end": 27755, "text": "<9> use a seeded point to segment the bronchi in the lungs.", "rank": 262, "start": 27696, "IsComparative": "1", "id": "st_262"}, {"end": 27769, "text": "Prassni et al.", "rank": 263, "start": 27755, "IsComparative": "0", "id": "st_263"}, {"end": 27853, "text": "<128> incor- porate user guidance to minimize the uncertainties in the segmentation.", "rank": 264, "start": 27769, "IsComparative": "0", "id": "st_264"}, {"end": 27865, "text": "Kniss et al.", "rank": 265, "start": 27853, "IsComparative": "0", "id": "st_265"}, {"end": 27926, "text": "<88> use supervised manifold distance to segment volume data.", "rank": 266, "start": 27865, "IsComparative": "1", "id": "st_266"}, {"end": 27945, "text": "Torsney-Weir et al.", "rank": 267, "start": 27926, "IsComparative": "0", "id": "st_267"}, {"end": 28037, "text": "<158> esti- mate visual responses to guide the search for the image segmentation parameters.", "rank": 268, "start": 27945, "IsComparative": "0", "id": "st_268"}]}, {"paragraph_info": {"end": 28413, "start": 28037, "text": "In Chapter 4, we use the popular normalized-cut approach <144> to directly segment the intensity-gradient histogram of a volume data and construct the transfer function.The normalized-cut approach to 2D image segmentation has been extensively used for a variety of applications and it has been mapped on a variety of architectures including multi-core and many-core GPUs <53>.", "rank": 54, "paragraph_comparative_number": 2, "entities": [], "id": "p_54"}, "sentences": [{"end": 28206, "text": "In Chapter 4, we use the popular normalized-cut approach <144> to directly segment the intensity-gradient histogram of a volume data and construct the transfer function.", "rank": 269, "start": 28037, "IsComparative": "1", "id": "st_269"}, {"end": 28413, "text": "The normalized-cut approach to 2D image segmentation has been extensively used for a variety of applications and it has been mapped on a variety of architectures including multi-core and many-core GPUs <53>.", "rank": 270, "start": 28206, "IsComparative": "1", "id": "st_270"}]}, {"paragraph_info": {"end": 28459, "start": 28413, "text": "2.5.1 Atlas-based Segmentation of Brain Images", "rank": 55, "paragraph_comparative_number": 1, "entities": [], "id": "p_55"}, "sentences": [{"end": 28459, "text": "2.5.1 Atlas-based Segmentation of Brain Images", "rank": 271, "start": 28413, "IsComparative": "1", "id": "st_271"}]}, {"paragraph_info": {"end": 29292, "start": 28459, "text": "Segmentation of brain images <34> is an important topic in medical imaging.Atlas- based techniques attempt to register an annotated brain atlas to an input image.The challenge is in devising methods that deform the atlas to fit a single image.Cabezas et al.<16> present a recent survey on atlas-based segmentation of MR brain images.When multiple brain atlases are available, selecting the best atlas to fit a particular image is also of interest <48, 132, 170>.Evans et al.<31> construct a blurred atlas from hundreds of MR brain images.Ju et al.have proposed a geometric framework <76> for landmark-and- atlas-based segmentation <10, 78> on the in situ hybridization gene expression images of mouse brains.In this work, we present a method to extract 3D boundaries of a given brain structure from multiple gene expression profiles.", "rank": 56, "paragraph_comparative_number": 5, "entities": [], "id": "p_56"}, "sentences": [{"end": 28534, "text": "Segmentation of brain images <34> is an important topic in medical imaging.", "rank": 272, "start": 28459, "IsComparative": "1", "id": "st_272"}, {"end": 28621, "text": "Atlas- based techniques attempt to register an annotated brain atlas to an input image.", "rank": 273, "start": 28534, "IsComparative": "1", "id": "st_273"}, {"end": 28702, "text": "The challenge is in devising methods that deform the atlas to fit a single image.", "rank": 274, "start": 28621, "IsComparative": "0", "id": "st_274"}, {"end": 28716, "text": "Cabezas et al.", "rank": 275, "start": 28702, "IsComparative": "0", "id": "st_275"}, {"end": 28792, "text": "<16> present a recent survey on atlas-based segmentation of MR brain images.", "rank": 276, "start": 28716, "IsComparative": "1", "id": "st_276"}, {"end": 28921, "text": "When multiple brain atlases are available, selecting the best atlas to fit a particular image is also of interest <48, 132, 170>.", "rank": 277, "start": 28792, "IsComparative": "1", "id": "st_277"}, {"end": 28933, "text": "Evans et al.", "rank": 278, "start": 28921, "IsComparative": "0", "id": "st_278"}, {"end": 28997, "text": "<31> construct a blurred atlas from hundreds of MR brain images.", "rank": 279, "start": 28933, "IsComparative": "0", "id": "st_279"}, {"end": 29006, "text": "Ju et al.", "rank": 280, "start": 28997, "IsComparative": "0", "id": "st_280"}, {"end": 29167, "text": "have proposed a geometric framework <76> for landmark-and- atlas-based segmentation <10, 78> on the in situ hybridization gene expression images of mouse brains.", "rank": 281, "start": 29006, "IsComparative": "0", "id": "st_281"}, {"end": 29292, "text": "In this work, we present a method to extract 3D boundaries of a given brain structure from multiple gene expression profiles.", "rank": 282, "start": 29167, "IsComparative": "1", "id": "st_282"}]}, {"paragraph_info": {"end": 29339, "start": 29292, "text": "2.5.2 Extracting 3D Surfaces from Scalar Fields", "rank": 57, "paragraph_comparative_number": 1, "entities": [], "id": "p_57"}, "sentences": [{"end": 29339, "text": "2.5.2 Extracting 3D Surfaces from Scalar Fields", "rank": 283, "start": 29292, "IsComparative": "1", "id": "st_283"}]}, {"paragraph_info": {"end": 30050, "start": 29339, "text": "Lorensen and Cline <101> introduced the classical marching cubes algorithm for constructing contour surfaces from a scalar field at a given iso-value.It has been a chal- lenge to locate good iso-surfaces in volumetric scalar fields.Bajaj et al.<8> present the contour spectrum tool for users to select iso-values.Kindlmann and Durkin <86> use scalar field gradients to identify better separation of materials and boundaries.Tang and Medioni <154> show how to use tensor voting to extract surfaces from noisy point clouds and scalar fields.Sereda et al.<141> introduce LH histograms to detect material bound- aries.Bruckner and Mo ller <15> compute a similarity map of iso-surfaces to determine a good iso-value.", "rank": 58, "paragraph_comparative_number": 3, "entities": [], "id": "p_58"}, "sentences": [{"end": 29489, "text": "Lorensen and Cline <101> introduced the classical marching cubes algorithm for constructing contour surfaces from a scalar field at a given iso-value.", "rank": 284, "start": 29339, "IsComparative": "1", "id": "st_284"}, {"end": 29571, "text": "It has been a chal- lenge to locate good iso-surfaces in volumetric scalar fields.", "rank": 285, "start": 29489, "IsComparative": "0", "id": "st_285"}, {"end": 29583, "text": "Bajaj et al.", "rank": 286, "start": 29571, "IsComparative": "0", "id": "st_286"}, {"end": 29652, "text": "<8> present the contour spectrum tool for users to select iso-values.", "rank": 287, "start": 29583, "IsComparative": "0", "id": "st_287"}, {"end": 29763, "text": "Kindlmann and Durkin <86> use scalar field gradients to identify better separation of materials and boundaries.", "rank": 288, "start": 29652, "IsComparative": "1", "id": "st_288"}, {"end": 29878, "text": "Tang and Medioni <154> show how to use tensor voting to extract surfaces from noisy point clouds and scalar fields.", "rank": 289, "start": 29763, "IsComparative": "1", "id": "st_289"}, {"end": 29891, "text": "Sereda et al.", "rank": 290, "start": 29878, "IsComparative": "0", "id": "st_290"}, {"end": 29953, "text": "<141> introduce LH histograms to detect material bound- aries.", "rank": 291, "start": 29891, "IsComparative": "0", "id": "st_291"}, {"end": 30050, "text": "Bruckner and Mo ller <15> compute a similarity map of iso-surfaces to determine a good iso-value.", "rank": 292, "start": 29953, "IsComparative": "0", "id": "st_292"}]}, {"paragraph_info": {"end": 30079, "start": 30050, "text": "2.6 Clustering Moving Objects", "rank": 59, "paragraph_comparative_number": 0, "entities": [], "id": "p_59"}, "sentences": [{"end": 30079, "text": "2.6 Clustering Moving Objects", "rank": 293, "start": 30050, "IsComparative": "0", "id": "st_293"}]}, {"paragraph_info": {"end": 30168, "start": 30079, "text": "Trajectory clustering techniques group similarly-shaped trajectories or sub-trajectories.", "rank": 60, "paragraph_comparative_number": 0, "entities": [], "id": "p_60"}, "sentences": [{"end": 30168, "text": "Trajectory clustering techniques group similarly-shaped trajectories or sub-trajectories.", "rank": 294, "start": 30079, "IsComparative": "0", "id": "st_294"}]}, {"paragraph_info": {"end": 30616, "start": 30168, "text": "Gaffney et al.<40> use a probabilistic regression method to cluster the gross shapes of trajectories.Lee et al.<95> focus on clustering sub-trajectories by first partitioning the trajec- tories into line segments and then group the line segments into clusters.Li et al.<98> ex- tend this partitioning-and-grouping approach to accommodate incremental datasets.Fer- reira et al.<33> show how to cluster trajectories by fitting multiple vector fields.", "rank": 61, "paragraph_comparative_number": 2, "entities": [], "id": "p_61"}, "sentences": [{"end": 30182, "text": "Gaffney et al.", "rank": 295, "start": 30168, "IsComparative": "0", "id": "st_295"}, {"end": 30269, "text": "<40> use a probabilistic regression method to cluster the gross shapes of trajectories.", "rank": 296, "start": 30182, "IsComparative": "1", "id": "st_296"}, {"end": 30279, "text": "Lee et al.", "rank": 297, "start": 30269, "IsComparative": "0", "id": "st_297"}, {"end": 30428, "text": "<95> focus on clustering sub-trajectories by first partitioning the trajec- tories into line segments and then group the line segments into clusters.", "rank": 298, "start": 30279, "IsComparative": "0", "id": "st_298"}, {"end": 30437, "text": "Li et al.", "rank": 299, "start": 30428, "IsComparative": "0", "id": "st_299"}, {"end": 30527, "text": "<98> ex- tend this partitioning-and-grouping approach to accommodate incremental datasets.", "rank": 300, "start": 30437, "IsComparative": "0", "id": "st_300"}, {"end": 30544, "text": "Fer- reira et al.", "rank": 301, "start": 30527, "IsComparative": "0", "id": "st_301"}, {"end": 30616, "text": "<33> show how to cluster trajectories by fitting multiple vector fields.", "rank": 302, "start": 30544, "IsComparative": "1", "id": "st_302"}]}, {"paragraph_info": {"end": 30904, "start": 30616, "text": "Clustering moving objects at different time steps is another related area.Zhang and Lin <173> use the k-center clustering algorithm to cluster buckets of moving objects.Jensen et al.<71> incrementally cluster moving objects by using spatial and velocity in- formation as cluster features.", "rank": 62, "paragraph_comparative_number": 3, "entities": [], "id": "p_62"}, "sentences": [{"end": 30690, "text": "Clustering moving objects at different time steps is another related area.", "rank": 303, "start": 30616, "IsComparative": "1", "id": "st_303"}, {"end": 30785, "text": "Zhang and Lin <173> use the k-center clustering algorithm to cluster buckets of moving objects.", "rank": 304, "start": 30690, "IsComparative": "1", "id": "st_304"}, {"end": 30798, "text": "Jensen et al.", "rank": 305, "start": 30785, "IsComparative": "0", "id": "st_305"}, {"end": 30904, "text": "<71> incrementally cluster moving objects by using spatial and velocity in- formation as cluster features.", "rank": 306, "start": 30798, "IsComparative": "1", "id": "st_306"}]}, {"paragraph_info": {"end": 31721, "start": 30904, "text": "Discovering groups of moving objects has also been an active research area.Gud- mundsson et al.<45> find fixed-radius circular flocks of moving objects with a quadtree.Jeung et al.<72> relax the fixed-radius requirement and discover convoys that are together in consecutive timesteps by filtering and simplifying the trajectories.Li et al.<97> find swarms that are together in non-consecutive timesteps by using forward-backing pruning to reduce the search space.Giannotti et al.<42> discover the frequently visited regions of interest from trajectories.Nanni and Pedreschi <112> cluster trajectories with a focus on time.Pelekis et al.<124> cluster uncertain trajectories.Tang et al.<156> find travel companions from streaming trajectories.Zheng et al.<174> use a density-based approach to detect gathering patterns.", "rank": 63, "paragraph_comparative_number": 4, "entities": [], "id": "p_63"}, "sentences": [{"end": 30979, "text": "Discovering groups of moving objects has also been an active research area.", "rank": 307, "start": 30904, "IsComparative": "0", "id": "st_307"}, {"end": 30999, "text": "Gud- mundsson et al.", "rank": 308, "start": 30979, "IsComparative": "0", "id": "st_308"}, {"end": 31072, "text": "<45> find fixed-radius circular flocks of moving objects with a quadtree.", "rank": 309, "start": 30999, "IsComparative": "0", "id": "st_309"}, {"end": 31084, "text": "Jeung et al.", "rank": 310, "start": 31072, "IsComparative": "0", "id": "st_310"}, {"end": 31234, "text": "<72> relax the fixed-radius requirement and discover convoys that are together in consecutive timesteps by filtering and simplifying the trajectories.", "rank": 311, "start": 31084, "IsComparative": "0", "id": "st_311"}, {"end": 31243, "text": "Li et al.", "rank": 312, "start": 31234, "IsComparative": "0", "id": "st_312"}, {"end": 31367, "text": "<97> find swarms that are together in non-consecutive timesteps by using forward-backing pruning to reduce the search space.", "rank": 313, "start": 31243, "IsComparative": "1", "id": "st_313"}, {"end": 31383, "text": "Giannotti et al.", "rank": 314, "start": 31367, "IsComparative": "0", "id": "st_314"}, {"end": 31458, "text": "<42> discover the frequently visited regions of interest from trajectories.", "rank": 315, "start": 31383, "IsComparative": "1", "id": "st_315"}, {"end": 31526, "text": "Nanni and Pedreschi <112> cluster trajectories with a focus on time.", "rank": 316, "start": 31458, "IsComparative": "1", "id": "st_316"}, {"end": 31540, "text": "Pelekis et al.", "rank": 317, "start": 31526, "IsComparative": "0", "id": "st_317"}, {"end": 31577, "text": "<124> cluster uncertain trajectories.", "rank": 318, "start": 31540, "IsComparative": "0", "id": "st_318"}, {"end": 31588, "text": "Tang et al.", "rank": 319, "start": 31577, "IsComparative": "0", "id": "st_319"}, {"end": 31645, "text": "<156> find travel companions from streaming trajectories.", "rank": 320, "start": 31588, "IsComparative": "0", "id": "st_320"}, {"end": 31657, "text": "Zheng et al.", "rank": 321, "start": 31645, "IsComparative": "0", "id": "st_321"}, {"end": 31721, "text": "<174> use a density-based approach to detect gathering patterns.", "rank": 322, "start": 31657, "IsComparative": "1", "id": "st_322"}]}, {"paragraph_info": {"end": 32023, "start": 31721, "text": "Zheng et al.have collected a huge dataset of GPS trajectories <175>, including thousands of taxi trajectories for improving driving directions <172>.More recently, they have released a new system for taxi ridesharing <103>.Zheng and Zhou <176> have edited a book on computing with spatial trajectories.", "rank": 64, "paragraph_comparative_number": 2, "entities": [], "id": "p_64"}, "sentences": [{"end": 31733, "text": "Zheng et al.", "rank": 323, "start": 31721, "IsComparative": "0", "id": "st_323"}, {"end": 31870, "text": "have collected a huge dataset of GPS trajectories <175>, including thousands of taxi trajectories for improving driving directions <172>.", "rank": 324, "start": 31733, "IsComparative": "1", "id": "st_324"}, {"end": 31944, "text": "More recently, they have released a new system for taxi ridesharing <103>.", "rank": 325, "start": 31870, "IsComparative": "0", "id": "st_325"}, {"end": 32023, "text": "Zheng and Zhou <176> have edited a book on computing with spatial trajectories.", "rank": 326, "start": 31944, "IsComparative": "1", "id": "st_326"}]}, {"paragraph_info": {"end": 32058, "start": 32023, "text": "2.7 Approximating Complex Distances", "rank": 65, "paragraph_comparative_number": 0, "entities": [], "id": "p_65"}, "sentences": [{"end": 32058, "text": "2.7 Approximating Complex Distances", "rank": 327, "start": 32023, "IsComparative": "0", "id": "st_327"}]}, {"paragraph_info": {"end": 32311, "start": 32058, "text": "We show how we can use a newly developed computational geometry technique called approximate kernel distance to cluster trajectories.In general, kernel methods project input data points into higher dimensions, for better separation of dissimilar points.", "rank": 66, "paragraph_comparative_number": 2, "entities": [], "id": "p_66"}, "sentences": [{"end": 32191, "text": "We show how we can use a newly developed computational geometry technique called approximate kernel distance to cluster trajectories.", "rank": 328, "start": 32058, "IsComparative": "1", "id": "st_328"}, {"end": 32311, "text": "In general, kernel methods project input data points into higher dimensions, for better separation of dissimilar points.", "rank": 329, "start": 32191, "IsComparative": "1", "id": "st_329"}]}, {"paragraph_info": {"end": 32961, "start": 32311, "text": "This approach has been widely used in machine learning <130, 139> to find non-linear classifiers and underlying subspace manifolds.Similarly, the kernel distance method uses a lifting map to project data points into a higher dimensional space and computes the distances there.This method has been used for comparing point sets, curves, and surfaces.Vaillant and Glaunes <162> have used this method to compare surfaces of human face meshes.Joshi et al.<75> have established the bounds for the lifting map requirement.They have also shown how to select a coreset of points and how to estimate translation and rotation to align two different point sets.", "rank": 67, "paragraph_comparative_number": 4, "entities": [], "id": "p_67"}, "sentences": [{"end": 32442, "text": "This approach has been widely used in machine learning <130, 139> to find non-linear classifiers and underlying subspace manifolds.", "rank": 330, "start": 32311, "IsComparative": "1", "id": "st_330"}, {"end": 32587, "text": "Similarly, the kernel distance method uses a lifting map to project data points into a higher dimensional space and computes the distances there.", "rank": 331, "start": 32442, "IsComparative": "1", "id": "st_331"}, {"end": 32660, "text": "This method has been used for comparing point sets, curves, and surfaces.", "rank": 332, "start": 32587, "IsComparative": "0", "id": "st_332"}, {"end": 32750, "text": "Vaillant and Glaunes <162> have used this method to compare surfaces of human face meshes.", "rank": 333, "start": 32660, "IsComparative": "1", "id": "st_333"}, {"end": 32762, "text": "Joshi et al.", "rank": 334, "start": 32750, "IsComparative": "0", "id": "st_334"}, {"end": 32827, "text": "<75> have established the bounds for the lifting map requirement.", "rank": 335, "start": 32762, "IsComparative": "0", "id": "st_335"}, {"end": 32961, "text": "They have also shown how to select a coreset of points and how to estimate translation and rotation to align two different point sets.", "rank": 336, "start": 32827, "IsComparative": "1", "id": "st_336"}]}, {"paragraph_info": {"end": 34015, "start": 32961, "text": "Comparing distributions has received significant attention in the machine learning, data mining and computer vision communities.One of the popular distance functions to compare distributions and weighted point sets in general is the Earth Mover Distance (EMD).EMD has been popularized by the computer vision community for comparing histograms in content-based image and video retrieval <134>.Yet computing the Earth movers distance requires solving a transportation optimization problem with the O(n3) Hungarian algorithm.Many approximation techniques have been proposed.Ling and Okada <99> empirically show that EMD can be computed in O(n2) time with L1 distance.Shirdhonkar and Jacobs <145> compute an approximation to the EMD in O(n) time by using the sum of the absolute weighted wavelet coefficients of the difference histogram.While these approximations work in L1 space, Andoni et al.<2> show how to embed EMD into well-behaved norm spaces of high dimensions.Applegate et al.<3> have shown a wavelet approximation for EMD on generalized manifolds.", "rank": 68, "paragraph_comparative_number": 5, "entities": [], "id": "p_68"}, "sentences": [{"end": 33089, "text": "Comparing distributions has received significant attention in the machine learning, data mining and computer vision communities.", "rank": 337, "start": 32961, "IsComparative": "1", "id": "st_337"}, {"end": 33221, "text": "One of the popular distance functions to compare distributions and weighted point sets in general is the Earth Mover Distance (EMD).", "rank": 338, "start": 33089, "IsComparative": "1", "id": "st_338"}, {"end": 33353, "text": "EMD has been popularized by the computer vision community for comparing histograms in content-based image and video retrieval <134>.", "rank": 339, "start": 33221, "IsComparative": "0", "id": "st_339"}, {"end": 33483, "text": "Yet computing the Earth movers distance requires solving a transportation optimization problem with the O(n3) Hungarian algorithm.", "rank": 340, "start": 33353, "IsComparative": "0", "id": "st_340"}, {"end": 33532, "text": "Many approximation techniques have been proposed.", "rank": 341, "start": 33483, "IsComparative": "1", "id": "st_341"}, {"end": 33625, "text": "Ling and Okada <99> empirically show that EMD can be computed in O(n2) time with L1 distance.", "rank": 342, "start": 33532, "IsComparative": "0", "id": "st_342"}, {"end": 33794, "text": "Shirdhonkar and Jacobs <145> compute an approximation to the EMD in O(n) time by using the sum of the absolute weighted wavelet coefficients of the difference histogram.", "rank": 343, "start": 33625, "IsComparative": "1", "id": "st_343"}, {"end": 33852, "text": "While these approximations work in L1 space, Andoni et al.", "rank": 344, "start": 33794, "IsComparative": "0", "id": "st_344"}, {"end": 33927, "text": "<2> show how to embed EMD into well-behaved norm spaces of high dimensions.", "rank": 345, "start": 33852, "IsComparative": "0", "id": "st_345"}, {"end": 33943, "text": "Applegate et al.", "rank": 346, "start": 33927, "IsComparative": "0", "id": "st_346"}, {"end": 34015, "text": "<3> have shown a wavelet approximation for EMD on generalized manifolds.", "rank": 347, "start": 33943, "IsComparative": "1", "id": "st_347"}]}, {"paragraph_info": {"end": 34024, "start": 34015, "text": "Chapter 3", "rank": 69, "paragraph_comparative_number": 0, "entities": [], "id": "p_69"}, "sentences": [{"end": 34024, "text": "Chapter 3", "rank": 348, "start": 34015, "IsComparative": "0", "id": "st_348"}]}, {"paragraph_info": {"end": 34083, "start": 34024, "text": "Saliency-assisted Navigation of Very Large Landscape Images", "rank": 70, "paragraph_comparative_number": 1, "entities": [], "id": "p_70"}, "sentences": [{"end": 34083, "text": "Saliency-assisted Navigation of Very Large Landscape Images", "rank": 349, "start": 34024, "IsComparative": "1", "id": "st_349"}]}, {"paragraph_info": {"end": 35366, "start": 34083, "text": "We are seeing a significant growth in the interest and relevance of very large images.One of the reasons behind this trend is the development of systems that can automatically capture and stitch photographs to create images of unprecedented detail ranging from a few gigapixels <21, 90, 179> to even a few terapixels <46>.Recent advances in consumer- grade robotic image acquisition from companies such as Gigapan have further energized social network communities that are interested in building, sharing, and collectively ex- ploring such large images.Some relevant work on processing of very large images in- cludes a streaming multigrid solver for gigapixel scale out-of-core gradient-domain image processing by Kazhdan and Hoppe <79>.More recently, Summa et al.<150> present pro- gressive processing of high-resolution images with interactive previews.Kopf et al.<90> discuss how to naturally display the stitched image by cylindrical projections.Luan et al.<102> adaptively annotate these very large images by text and audio according to the viewing position and scale.While these are very interesting first steps in computational processing and display of very large images, this chapter addresses a different challenge for such large images  their effective visual navigation.", "rank": 71, "paragraph_comparative_number": 5, "entities": [], "id": "p_71"}, "sentences": [{"end": 34169, "text": "We are seeing a significant growth in the interest and relevance of very large images.", "rank": 350, "start": 34083, "IsComparative": "1", "id": "st_350"}, {"end": 34405, "text": "One of the reasons behind this trend is the development of systems that can automatically capture and stitch photographs to create images of unprecedented detail ranging from a few gigapixels <21, 90, 179> to even a few terapixels <46>.", "rank": 351, "start": 34169, "IsComparative": "0", "id": "st_351"}, {"end": 34636, "text": "Recent advances in consumer- grade robotic image acquisition from companies such as Gigapan have further energized social network communities that are interested in building, sharing, and collectively ex- ploring such large images.", "rank": 352, "start": 34405, "IsComparative": "0", "id": "st_352"}, {"end": 34821, "text": "Some relevant work on processing of very large images in- cludes a streaming multigrid solver for gigapixel scale out-of-core gradient-domain image processing by Kazhdan and Hoppe <79>.", "rank": 353, "start": 34636, "IsComparative": "1", "id": "st_353"}, {"end": 34848, "text": "More recently, Summa et al.", "rank": 354, "start": 34821, "IsComparative": "0", "id": "st_354"}, {"end": 34939, "text": "<150> present pro- gressive processing of high-resolution images with interactive previews.", "rank": 355, "start": 34848, "IsComparative": "0", "id": "st_355"}, {"end": 34950, "text": "Kopf et al.", "rank": 356, "start": 34939, "IsComparative": "0", "id": "st_356"}, {"end": 35034, "text": "<90> discuss how to naturally display the stitched image by cylindrical projections.", "rank": 357, "start": 34950, "IsComparative": "1", "id": "st_357"}, {"end": 35045, "text": "Luan et al.", "rank": 358, "start": 35034, "IsComparative": "0", "id": "st_358"}, {"end": 35157, "text": "<102> adaptively annotate these very large images by text and audio according to the viewing position and scale.", "rank": 359, "start": 35045, "IsComparative": "1", "id": "st_359"}, {"end": 35366, "text": "While these are very interesting first steps in computational processing and display of very large images, this chapter addresses a different challenge for such large images  their effective visual navigation.", "rank": 360, "start": 35157, "IsComparative": "1", "id": "st_360"}]}, {"paragraph_info": {"end": 36219, "start": 35366, "text": "Consider a gigapixel image shown in Figure 3.1 .The successive zooms give an indication of the level of detail in such images.When viewing such images, users typ- ically pan at the coarse level and occasionally zoom in to see the fine details.Panning at the finest level of detail is too tedious and panning at the coarsest level of detail does not have enough information for the user to know where to zoom in.Just to convey the magnitude of the problem, let us consider some numbers.Imagine a user is visualizing a 4 Gigapixel image on a 2 Megapixel monitor.This would suggest that every monitor pixel is representing 2000 image pixels and the observable image on the monitor is a mere 0.05% of the total dataset.Further, if it takes a user just a couple of seconds to scan the monitor, it will take more than an hour to scan through the entire image.", "rank": 72, "paragraph_comparative_number": 5, "entities": [], "id": "p_72"}, "sentences": [{"end": 35414, "text": "Consider a gigapixel image shown in Figure 3.1 .", "rank": 361, "start": 35366, "IsComparative": "0", "id": "st_361"}, {"end": 35492, "text": "The successive zooms give an indication of the level of detail in such images.", "rank": 362, "start": 35414, "IsComparative": "1", "id": "st_362"}, {"end": 35609, "text": "When viewing such images, users typ- ically pan at the coarse level and occasionally zoom in to see the fine details.", "rank": 363, "start": 35492, "IsComparative": "0", "id": "st_363"}, {"end": 35777, "text": "Panning at the finest level of detail is too tedious and panning at the coarsest level of detail does not have enough information for the user to know where to zoom in.", "rank": 364, "start": 35609, "IsComparative": "1", "id": "st_364"}, {"end": 35851, "text": "Just to convey the magnitude of the problem, let us consider some numbers.", "rank": 365, "start": 35777, "IsComparative": "1", "id": "st_365"}, {"end": 35926, "text": "Imagine a user is visualizing a 4 Gigapixel image on a 2 Megapixel monitor.", "rank": 366, "start": 35851, "IsComparative": "0", "id": "st_366"}, {"end": 36081, "text": "This would suggest that every monitor pixel is representing 2000 image pixels and the observable image on the monitor is a mere 0.05% of the total dataset.", "rank": 367, "start": 35926, "IsComparative": "1", "id": "st_367"}, {"end": 36219, "text": "Further, if it takes a user just a couple of seconds to scan the monitor, it will take more than an hour to scan through the entire image.", "rank": 368, "start": 36081, "IsComparative": "1", "id": "st_368"}]}, {"paragraph_info": {"end": 37095, "start": 36219, "text": "In this chapter, we leverage principles of visualization to ease the task of navigat- ing very large landscape images.In visual exploration of very large images the biggest challenge involves identifying the most salient content and visually presenting this infor- mation to the user.Just as the transfer function design in traditional visualization uses opacity to identify what data to show and color to emphasize, we present data-driven techniques to identify and emphasize potential areas of interest in very large images.Our techniques are relevant for visualization of datasets when the data size is several orders of magnitude larger than what the display device can accomodate.We use techniques based on visual knowledge discovery to help in user navigation and adaptive context- and scale-dependent visual overlays to assist in spatial localization of salient detail.", "rank": 73, "paragraph_comparative_number": 2, "entities": [], "id": "p_73"}, "sentences": [{"end": 36337, "text": "In this chapter, we leverage principles of visualization to ease the task of navigat- ing very large landscape images.", "rank": 369, "start": 36219, "IsComparative": "1", "id": "st_369"}, {"end": 36503, "text": "In visual exploration of very large images the biggest challenge involves identifying the most salient content and visually presenting this infor- mation to the user.", "rank": 370, "start": 36337, "IsComparative": "1", "id": "st_370"}, {"end": 36745, "text": "Just as the transfer function design in traditional visualization uses opacity to identify what data to show and color to emphasize, we present data-driven techniques to identify and emphasize potential areas of interest in very large images.", "rank": 371, "start": 36503, "IsComparative": "0", "id": "st_371"}, {"end": 36904, "text": "Our techniques are relevant for visualization of datasets when the data size is several orders of magnitude larger than what the display device can accomodate.", "rank": 372, "start": 36745, "IsComparative": "0", "id": "st_372"}, {"end": 37095, "text": "We use techniques based on visual knowledge discovery to help in user navigation and adaptive context- and scale-dependent visual overlays to assist in spatial localization of salient detail.", "rank": 373, "start": 36904, "IsComparative": "0", "id": "st_373"}]}, {"paragraph_info": {"end": 37105, "start": 37095, "text": "Challenges", "rank": 74, "paragraph_comparative_number": 1, "entities": [], "id": "p_74"}, "sentences": [{"end": 37105, "text": "Challenges", "rank": 374, "start": 37095, "IsComparative": "1", "id": "st_374"}]}, {"paragraph_info": {"end": 37209, "start": 37105, "text": "The interactive visual exploration of very high-resolution large-scale images presents three challenges:", "rank": 75, "paragraph_comparative_number": 1, "entities": [], "id": "p_75"}, "sentences": [{"end": 37209, "text": "The interactive visual exploration of very high-resolution large-scale images presents three challenges:", "rank": 375, "start": 37105, "IsComparative": "1", "id": "st_375"}]}, {"paragraph_info": {"end": 38057, "start": 37209, "text": "1.Visual Scalability: The visual scalability challenge arises from the inability of the human visual system to take in all the details that are present in a very large image.This arises from a fundamental limitation of the retina as well as the display hardware which have not kept pace with our ability to acquire ever larger images.Figure 3.2 shows the growth in resolution of the mainstream consumer-grade LCD displays against camera sensors in recent years.The display resolutions correspond to the highest-resolution mon- itors sold by a mainstream vendor (such as Dell and Apple) and the camera-sensor sizes correspond to the highest-resolution entry-level SLR cameras manufactured by Canon, Nikon, or Sony.It is easy to see how the resolution growth of these off-the-shelf cameras has clearly outpaced the resolution of the display monitors.", "rank": 76, "paragraph_comparative_number": 5, "entities": [], "id": "p_76"}, "sentences": [{"end": 37211, "text": "1.", "rank": 376, "start": 37209, "IsComparative": "1", "id": "st_376"}, {"end": 37383, "text": "Visual Scalability: The visual scalability challenge arises from the inability of the human visual system to take in all the details that are present in a very large image.", "rank": 377, "start": 37211, "IsComparative": "1", "id": "st_377"}, {"end": 37543, "text": "This arises from a fundamental limitation of the retina as well as the display hardware which have not kept pace with our ability to acquire ever larger images.", "rank": 378, "start": 37383, "IsComparative": "1", "id": "st_378"}, {"end": 37670, "text": "Figure 3.2 shows the growth in resolution of the mainstream consumer-grade LCD displays against camera sensors in recent years.", "rank": 379, "start": 37543, "IsComparative": "0", "id": "st_379"}, {"end": 37922, "text": "The display resolutions correspond to the highest-resolution mon- itors sold by a mainstream vendor (such as Dell and Apple) and the camera-sensor sizes correspond to the highest-resolution entry-level SLR cameras manufactured by Canon, Nikon, or Sony.", "rank": 380, "start": 37670, "IsComparative": "1", "id": "st_380"}, {"end": 38057, "text": "It is easy to see how the resolution growth of these off-the-shelf cameras has clearly outpaced the resolution of the display monitors.", "rank": 381, "start": 37922, "IsComparative": "1", "id": "st_381"}]}, {"paragraph_info": {"end": 38617, "start": 38057, "text": "2.Information Scalability: The challenge here is to design effective computational 20 algorithms to identify nuggets of useful visual information that hide in large-scale im- ages.In very large images, most of the image data is innocuous and unimportant and even considering it wastes precious time and resources.Often relatively small regions in such very large images are accorded a very high information value by human observers.Identification of such informative regions in very large images that largely match human expectations is an ambitious challenge.", "rank": 77, "paragraph_comparative_number": 3, "entities": [], "id": "p_77"}, "sentences": [{"end": 38059, "text": "2.", "rank": 382, "start": 38057, "IsComparative": "1", "id": "st_382"}, {"end": 38237, "text": "Information Scalability: The challenge here is to design effective computational 20 algorithms to identify nuggets of useful visual information that hide in large-scale im- ages.", "rank": 383, "start": 38059, "IsComparative": "1", "id": "st_383"}, {"end": 38370, "text": "In very large images, most of the image data is innocuous and unimportant and even considering it wastes precious time and resources.", "rank": 384, "start": 38237, "IsComparative": "1", "id": "st_384"}, {"end": 38489, "text": "Often relatively small regions in such very large images are accorded a very high information value by human observers.", "rank": 385, "start": 38370, "IsComparative": "0", "id": "st_385"}, {"end": 38617, "text": "Identification of such informative regions in very large images that largely match human expectations is an ambitious challenge.", "rank": 386, "start": 38489, "IsComparative": "0", "id": "st_386"}]}, {"paragraph_info": {"end": 39067, "start": 38617, "text": "3.Data Scalability: The sheer data size of these images poses a computational chal- lenge.Processing such large images along with their auxiliary data structures often necessitate out-of-core methods as well as designing of algorithms that are cache- and memory-efficient.Even routine image-processing operations for very large images re- quire a careful mapping to the many-core and multi-core processor architectures for any reasonable performance.", "rank": 78, "paragraph_comparative_number": 3, "entities": [], "id": "p_78"}, "sentences": [{"end": 38619, "text": "3.", "rank": 387, "start": 38617, "IsComparative": "1", "id": "st_387"}, {"end": 38707, "text": "Data Scalability: The sheer data size of these images poses a computational chal- lenge.", "rank": 388, "start": 38619, "IsComparative": "1", "id": "st_388"}, {"end": 38889, "text": "Processing such large images along with their auxiliary data structures often necessitate out-of-core methods as well as designing of algorithms that are cache- and memory-efficient.", "rank": 389, "start": 38707, "IsComparative": "1", "id": "st_389"}, {"end": 39067, "text": "Even routine image-processing operations for very large images re- quire a careful mapping to the many-core and multi-core processor architectures for any reasonable performance.", "rank": 390, "start": 38889, "IsComparative": "0", "id": "st_390"}]}, {"paragraph_info": {"end": 39238, "start": 39067, "text": "Contributions We present the first steps towards addressing the above challenges for interactive visual exploration of very large images.We outline our main contributions:", "rank": 79, "paragraph_comparative_number": 1, "entities": [], "id": "p_79"}, "sentences": [{"end": 39204, "text": "Contributions We present the first steps towards addressing the above challenges for interactive visual exploration of very large images.", "rank": 391, "start": 39067, "IsComparative": "0", "id": "st_391"}, {"end": 39238, "text": "We outline our main contributions:", "rank": 392, "start": 39204, "IsComparative": "1", "id": "st_392"}]}, {"paragraph_info": {"end": 39651, "start": 39238, "text": "1.We extend classical computational image saliency to very large images.Users of- ten navigate across three or more orders of magnitude scale differences  from the overview to the finest-scale views while viewing a very large image.Classical algo- rithms for multi-scale image saliency break down at handling such a large span of visual scales.We discuss the issues involved and present a solution in Section 3.2.", "rank": 80, "paragraph_comparative_number": 3, "entities": [], "id": "p_80"}, "sentences": [{"end": 39240, "text": "1.", "rank": 393, "start": 39238, "IsComparative": "1", "id": "st_393"}, {"end": 39310, "text": "We extend classical computational image saliency to very large images.", "rank": 394, "start": 39240, "IsComparative": "0", "id": "st_394"}, {"end": 39470, "text": "Users of- ten navigate across three or more orders of magnitude scale differences  from the overview to the finest-scale views while viewing a very large image.", "rank": 395, "start": 39310, "IsComparative": "1", "id": "st_395"}, {"end": 39582, "text": "Classical algo- rithms for multi-scale image saliency break down at handling such a large span of visual scales.", "rank": 396, "start": 39470, "IsComparative": "1", "id": "st_396"}, {"end": 39651, "text": "We discuss the issues involved and present a solution in Section 3.2.", "rank": 397, "start": 39582, "IsComparative": "0", "id": "st_397"}]}, {"paragraph_info": {"end": 40452, "start": 39651, "text": "2.As discussed above in the information scalability challenge, it is important to iden- tify the regions of interest in very large images that characterize areas of high in- formation value to users.The question of how to effectively characterize visual information content is still far from settled.There are a number of measures of vi- sual information content and often the definition depends on the task at hand.Our goal is not to provide a definitive characterization of the visual information content of a region of an image, which is a very deep question related to the issues of task semantics and knowledge.Instead we present here a fairly general information dis- covery algorithm in Section 3.3, that can serve as a framework for further research with other measures of information content.", "rank": 81, "paragraph_comparative_number": 3, "entities": [], "id": "p_81"}, "sentences": [{"end": 39653, "text": "2.", "rank": 398, "start": 39651, "IsComparative": "1", "id": "st_398"}, {"end": 39850, "text": "As discussed above in the information scalability challenge, it is important to iden- tify the regions of interest in very large images that characterize areas of high in- formation value to users.", "rank": 399, "start": 39653, "IsComparative": "0", "id": "st_399"}, {"end": 39951, "text": "The question of how to effectively characterize visual information content is still far from settled.", "rank": 400, "start": 39850, "IsComparative": "1", "id": "st_400"}, {"end": 40067, "text": "There are a number of measures of vi- sual information content and often the definition depends on the task at hand.", "rank": 401, "start": 39951, "IsComparative": "0", "id": "st_401"}, {"end": 40267, "text": "Our goal is not to provide a definitive characterization of the visual information content of a region of an image, which is a very deep question related to the issues of task semantics and knowledge.", "rank": 402, "start": 40067, "IsComparative": "1", "id": "st_402"}, {"end": 40452, "text": "Instead we present here a fairly general information dis- covery algorithm in Section 3.3, that can serve as a framework for further research with other measures of information content.", "rank": 403, "start": 40267, "IsComparative": "0", "id": "st_403"}]}, {"paragraph_info": {"end": 41046, "start": 40452, "text": "3.Interactive visual exploration of very large images requires a careful balancing of computational analysis and user preferences.Too much reliance on automatic intelligence-extraction algorithms is currently not feasible since it is often very dif- ficult to codify semantics of what a user is looking for.At the same time a purely interactive visual exploration without any computational assistance proves to be te- dious and overwhelming due to the sheer scope of the data that is being visualized.We present an interactive visual exploration and information discovery system in Section 3.4.", "rank": 82, "paragraph_comparative_number": 3, "entities": [], "id": "p_82"}, "sentences": [{"end": 40454, "text": "3.", "rank": 404, "start": 40452, "IsComparative": "1", "id": "st_404"}, {"end": 40582, "text": "Interactive visual exploration of very large images requires a careful balancing of computational analysis and user preferences.", "rank": 405, "start": 40454, "IsComparative": "1", "id": "st_405"}, {"end": 40759, "text": "Too much reliance on automatic intelligence-extraction algorithms is currently not feasible since it is often very dif- ficult to codify semantics of what a user is looking for.", "rank": 406, "start": 40582, "IsComparative": "0", "id": "st_406"}, {"end": 40953, "text": "At the same time a purely interactive visual exploration without any computational assistance proves to be te- dious and overwhelming due to the sheer scope of the data that is being visualized.", "rank": 407, "start": 40759, "IsComparative": "1", "id": "st_407"}, {"end": 41046, "text": "We present an interactive visual exploration and information discovery system in Section 3.4.", "rank": 408, "start": 40953, "IsComparative": "0", "id": "st_408"}]}, {"paragraph_info": {"end": 41175, "start": 41046, "text": "4.Data scalability is an important issue when dealing with very large images and we present advances in this area in Section 3.5.", "rank": 83, "paragraph_comparative_number": 2, "entities": [], "id": "p_83"}, "sentences": [{"end": 41048, "text": "4.", "rank": 409, "start": 41046, "IsComparative": "1", "id": "st_409"}, {"end": 41175, "text": "Data scalability is an important issue when dealing with very large images and we present advances in this area in Section 3.5.", "rank": 410, "start": 41048, "IsComparative": "1", "id": "st_410"}]}, {"paragraph_info": {"end": 41295, "start": 41175, "text": "5.We present and compare our results with those from a social community of gi- gapixel image enthusiasts in Section 3.6.", "rank": 84, "paragraph_comparative_number": 2, "entities": [], "id": "p_84"}, "sentences": [{"end": 41177, "text": "5.", "rank": 411, "start": 41175, "IsComparative": "1", "id": "st_411"}, {"end": 41295, "text": "We present and compare our results with those from a social community of gi- gapixel image enthusiasts in Section 3.6.", "rank": 412, "start": 41177, "IsComparative": "1", "id": "st_412"}]}, {"paragraph_info": {"end": 41307, "start": 41295, "text": "3.1 Overview", "rank": 85, "paragraph_comparative_number": 0, "entities": [], "id": "p_85"}, "sentences": [{"end": 41307, "text": "3.1 Overview", "rank": 413, "start": 41295, "IsComparative": "0", "id": "st_413"}]}, {"paragraph_info": {"end": 41553, "start": 41307, "text": "The goal of this chapter is to carry out computationally-assisted navigation of very large images.We leverage the principles of visual saliency and statistical similarity to outline a three-step approach.Fig.3.3 shows an overview of our approach.", "rank": 86, "paragraph_comparative_number": 2, "entities": [], "id": "p_86"}, "sentences": [{"end": 41405, "text": "The goal of this chapter is to carry out computationally-assisted navigation of very large images.", "rank": 414, "start": 41307, "IsComparative": "1", "id": "st_414"}, {"end": 41511, "text": "We leverage the principles of visual saliency and statistical similarity to outline a three-step approach.", "rank": 415, "start": 41405, "IsComparative": "0", "id": "st_415"}, {"end": 41515, "text": "Fig.", "rank": 416, "start": 41511, "IsComparative": "0", "id": "st_416"}, {"end": 41553, "text": "3.3 shows an overview of our approach.", "rank": 417, "start": 41515, "IsComparative": "1", "id": "st_417"}]}, {"paragraph_info": {"end": 41797, "start": 41553, "text": "Our first goal is to identify regions of interesting detail in very large images.The challenges here are in dealing with the dramatic span of visual scales and the sheer amount of data as well as information.Our approach addresses each of them.", "rank": 87, "paragraph_comparative_number": 2, "entities": [], "id": "p_87"}, "sentences": [{"end": 41634, "text": "Our first goal is to identify regions of interesting detail in very large images.", "rank": 418, "start": 41553, "IsComparative": "1", "id": "st_418"}, {"end": 41761, "text": "The challenges here are in dealing with the dramatic span of visual scales and the sheer amount of data as well as information.", "rank": 419, "start": 41634, "IsComparative": "0", "id": "st_419"}, {"end": 41797, "text": "Our approach addresses each of them.", "rank": 420, "start": 41761, "IsComparative": "1", "id": "st_420"}]}, {"paragraph_info": {"end": 42386, "start": 41797, "text": "Visual Scalability: Traditional algorithms for multi-scale image saliency work well for small images up to a few megapixels but do not scale up well to gigapixels and beyond.To address this we augment the traditional multi-scale image saliency approach with a sliding window over scales to effectively work with very large images.Our approach only requires Gaussian convolutions on images.It is highly parallelizable and scales linearly with the size of the image.The sliding-window saliency map phase of our approach discovers thousands of locally salient regions from billions of pixels.", "rank": 88, "paragraph_comparative_number": 4, "entities": [], "id": "p_88"}, "sentences": [{"end": 41971, "text": "Visual Scalability: Traditional algorithms for multi-scale image saliency work well for small images up to a few megapixels but do not scale up well to gigapixels and beyond.", "rank": 421, "start": 41797, "IsComparative": "1", "id": "st_421"}, {"end": 42127, "text": "To address this we augment the traditional multi-scale image saliency approach with a sliding window over scales to effectively work with very large images.", "rank": 422, "start": 41971, "IsComparative": "1", "id": "st_422"}, {"end": 42186, "text": "Our approach only requires Gaussian convolutions on images.", "rank": 423, "start": 42127, "IsComparative": "1", "id": "st_423"}, {"end": 42261, "text": "It is highly parallelizable and scales linearly with the size of the image.", "rank": 424, "start": 42186, "IsComparative": "1", "id": "st_424"}, {"end": 42386, "text": "The sliding-window saliency map phase of our approach discovers thousands of locally salient regions from billions of pixels.", "rank": 425, "start": 42261, "IsComparative": "0", "id": "st_425"}]}, {"paragraph_info": {"end": 43349, "start": 42386, "text": "Information Scalability: Typical landscape images comprise of a large number of nat- ural elements such as clouds, rocks, grass, and trees.In this chapter we assume that such repeating scene elements are not of interest to the viewers.We characterize all image regions using automatic color-structure descriptors.We then argue that the most interest- ing regions are the ones that are the most different from their k nearest neighbors (k-NN) in such color-structure feature space.We have empirically observed that this definition works well for landscape images.Other descriptors may be found to be more suitable for other datasets.We use a spatial index to accelerate the k-nearest-neighbor queries.This indexing and querying process grows as O(nlogn), where n is the number of salient re- gions identified by the sliding-window saliency step.For gigapixel images n is typically of the order of a few tens of thousands.We refer to this step as anomaly detection.", "rank": 89, "paragraph_comparative_number": 7, "entities": [], "id": "p_89"}, "sentences": [{"end": 42525, "text": "Information Scalability: Typical landscape images comprise of a large number of nat- ural elements such as clouds, rocks, grass, and trees.", "rank": 426, "start": 42386, "IsComparative": "1", "id": "st_426"}, {"end": 42621, "text": "In this chapter we assume that such repeating scene elements are not of interest to the viewers.", "rank": 427, "start": 42525, "IsComparative": "1", "id": "st_427"}, {"end": 42699, "text": "We characterize all image regions using automatic color-structure descriptors.", "rank": 428, "start": 42621, "IsComparative": "1", "id": "st_428"}, {"end": 42866, "text": "We then argue that the most interest- ing regions are the ones that are the most different from their k nearest neighbors (k-NN) in such color-structure feature space.", "rank": 429, "start": 42699, "IsComparative": "1", "id": "st_429"}, {"end": 42948, "text": "We have empirically observed that this definition works well for landscape images.", "rank": 430, "start": 42866, "IsComparative": "0", "id": "st_430"}, {"end": 43018, "text": "Other descriptors may be found to be more suitable for other datasets.", "rank": 431, "start": 42948, "IsComparative": "0", "id": "st_431"}, {"end": 43086, "text": "We use a spatial index to accelerate the k-nearest-neighbor queries.", "rank": 432, "start": 43018, "IsComparative": "1", "id": "st_432"}, {"end": 43230, "text": "This indexing and querying process grows as O(nlogn), where n is the number of salient re- gions identified by the sliding-window saliency step.", "rank": 433, "start": 43086, "IsComparative": "1", "id": "st_433"}, {"end": 43306, "text": "For gigapixel images n is typically of the order of a few tens of thousands.", "rank": 434, "start": 43230, "IsComparative": "0", "id": "st_434"}, {"end": 43349, "text": "We refer to this step as anomaly detection.", "rank": 435, "start": 43306, "IsComparative": "1", "id": "st_435"}]}, {"paragraph_info": {"end": 44362, "start": 43349, "text": "Interactive Visual Exploration: We have developed an interactive visualization envi- ronment to assist in exploration of very large images.We facilitate users to be aware of details that are a fraction of the screen pixel by ensuring that the overlays for such regions are large enough to be visible at every scale.The users can then explore and inspect all such regions interactively.We also have an automatic mode of the system in which the users are led through a smooth camera fly-through over all the informative regions in the image in order of their uniqueness as determined by the Visual and Information Scalabil- ity stages of the algorithm.If a user comes across a region of the image that the system claims is important, but the user finds to be unimportant, the user can identify all similar regions (using a slider) and discard them interactively.The spatial index structure built to address the Information Scalability stage of the algorithm allows this operation to occur within a few milliseconds.", "rank": 90, "paragraph_comparative_number": 2, "entities": [], "id": "p_90"}, "sentences": [{"end": 43488, "text": "Interactive Visual Exploration: We have developed an interactive visualization envi- ronment to assist in exploration of very large images.", "rank": 436, "start": 43349, "IsComparative": "0", "id": "st_436"}, {"end": 43664, "text": "We facilitate users to be aware of details that are a fraction of the screen pixel by ensuring that the overlays for such regions are large enough to be visible at every scale.", "rank": 437, "start": 43488, "IsComparative": "0", "id": "st_437"}, {"end": 43734, "text": "The users can then explore and inspect all such regions interactively.", "rank": 438, "start": 43664, "IsComparative": "0", "id": "st_438"}, {"end": 43999, "text": "We also have an automatic mode of the system in which the users are led through a smooth camera fly-through over all the informative regions in the image in order of their uniqueness as determined by the Visual and Information Scalabil- ity stages of the algorithm.", "rank": 439, "start": 43734, "IsComparative": "1", "id": "st_439"}, {"end": 44209, "text": "If a user comes across a region of the image that the system claims is important, but the user finds to be unimportant, the user can identify all similar regions (using a slider) and discard them interactively.", "rank": 440, "start": 43999, "IsComparative": "1", "id": "st_440"}, {"end": 44362, "text": "The spatial index structure built to address the Information Scalability stage of the algorithm allows this operation to occur within a few milliseconds.", "rank": 441, "start": 44209, "IsComparative": "0", "id": "st_441"}]}, {"paragraph_info": {"end": 44700, "start": 44362, "text": "Data Scalability: The size of the very large images together with their auxiliary data- structures imposes a significant computational and storage burden.We have used a num- ber of approaches to ameliorate this problem including out-of-core computation, efficient storage of salient regions, and building the a clipmap-based image viewer.", "rank": 91, "paragraph_comparative_number": 1, "entities": [], "id": "p_91"}, "sentences": [{"end": 44516, "text": "Data Scalability: The size of the very large images together with their auxiliary data- structures imposes a significant computational and storage burden.", "rank": 442, "start": 44362, "IsComparative": "1", "id": "st_442"}, {"end": 44700, "text": "We have used a num- ber of approaches to ameliorate this problem including out-of-core computation, efficient storage of salient regions, and building the a clipmap-based image viewer.", "rank": 443, "start": 44516, "IsComparative": "0", "id": "st_443"}]}, {"paragraph_info": {"end": 44727, "start": 44700, "text": "3.2 Sliding-Window Saliency", "rank": 92, "paragraph_comparative_number": 0, "entities": [], "id": "p_92"}, "sentences": [{"end": 44727, "text": "3.2 Sliding-Window Saliency", "rank": 444, "start": 44700, "IsComparative": "0", "id": "st_444"}]}, {"paragraph_info": {"end": 45101, "start": 44727, "text": "A very high resolution image is particularly interesting because it exceeds what the human eye can see at a given spot.In a very large image we can zoom from seeing the big picture to scrutinizing the finest details.Figure 3.4 shows three different views of an image at three different scales.We note that the cars seen in Figure 3.4(c) are not discernible in Figure 3.4(a).", "rank": 93, "paragraph_comparative_number": 2, "entities": [], "id": "p_93"}, "sentences": [{"end": 44846, "text": "A very high resolution image is particularly interesting because it exceeds what the human eye can see at a given spot.", "rank": 445, "start": 44727, "IsComparative": "0", "id": "st_445"}, {"end": 44943, "text": "In a very large image we can zoom from seeing the big picture to scrutinizing the finest details.", "rank": 446, "start": 44846, "IsComparative": "1", "id": "st_446"}, {"end": 45020, "text": "Figure 3.4 shows three different views of an image at three different scales.", "rank": 447, "start": 44943, "IsComparative": "1", "id": "st_447"}, {"end": 45101, "text": "We note that the cars seen in Figure 3.4(c) are not discernible in Figure 3.4(a).", "rank": 448, "start": 45020, "IsComparative": "0", "id": "st_448"}]}, {"paragraph_info": {"end": 45133, "start": 45101, "text": "3.2.1 Traditional Image Saliency", "rank": 94, "paragraph_comparative_number": 0, "entities": [], "id": "p_94"}, "sentences": [{"end": 45133, "text": "3.2.1 Traditional Image Saliency", "rank": 449, "start": 45101, "IsComparative": "0", "id": "st_449"}]}, {"paragraph_info": {"end": 46198, "start": 45133, "text": "A saliency map shows which part of an image is likely to attract the most atten- tion of the low-level human visual system.Itti et al.<60> have proposed a computational model of visual saliency by using multiscale image processing.Multiscale image process- ing techniques analyze an image at different scales to simulate the retinal receptive fields.Their image saliency model aggregates the results from three features of an image  in- tensity, color opponencies, and orientation.We have found that the use of the orientation features decreases the quality of our results as it ends up enhancing naturally occurring structures with strong edges such as cracks in rocks or trees, that end up becoming too salient.In this chapter we only consider the intensity and the two color-opponency at- tributes for computing image saliency.The intensity (FI ) is the average of primary colors, red, green, and blue.The color opponency attribute contains two sub channels, Red- Green(FR) and Blue-Yellow(FB).The details on computation of these attributes can be found in <60>.", "rank": 95, "paragraph_comparative_number": 4, "entities": [], "id": "p_95"}, "sentences": [{"end": 45256, "text": "A saliency map shows which part of an image is likely to attract the most atten- tion of the low-level human visual system.", "rank": 450, "start": 45133, "IsComparative": "1", "id": "st_450"}, {"end": 45267, "text": "Itti et al.", "rank": 451, "start": 45256, "IsComparative": "0", "id": "st_451"}, {"end": 45364, "text": "<60> have proposed a computational model of visual saliency by using multiscale image processing.", "rank": 452, "start": 45267, "IsComparative": "1", "id": "st_452"}, {"end": 45483, "text": "Multiscale image process- ing techniques analyze an image at different scales to simulate the retinal receptive fields.", "rank": 453, "start": 45364, "IsComparative": "0", "id": "st_453"}, {"end": 45614, "text": "Their image saliency model aggregates the results from three features of an image  in- tensity, color opponencies, and orientation.", "rank": 454, "start": 45483, "IsComparative": "1", "id": "st_454"}, {"end": 45846, "text": "We have found that the use of the orientation features decreases the quality of our results as it ends up enhancing naturally occurring structures with strong edges such as cracks in rocks or trees, that end up becoming too salient.", "rank": 455, "start": 45614, "IsComparative": "0", "id": "st_455"}, {"end": 45963, "text": "In this chapter we only consider the intensity and the two color-opponency at- tributes for computing image saliency.", "rank": 456, "start": 45846, "IsComparative": "0", "id": "st_456"}, {"end": 46038, "text": "The intensity (FI ) is the average of primary colors, red, green, and blue.", "rank": 457, "start": 45963, "IsComparative": "1", "id": "st_457"}, {"end": 46130, "text": "The color opponency attribute contains two sub channels, Red- Green(FR) and Blue-Yellow(FB).", "rank": 458, "start": 46038, "IsComparative": "0", "id": "st_458"}, {"end": 46198, "text": "The details on computation of these attributes can be found in <60>.", "rank": 459, "start": 46130, "IsComparative": "0", "id": "st_459"}]}, {"paragraph_info": {"end": 46292, "start": 46198, "text": "We next briefly review the traditional algorithm for computing the saliency map S of an image.", "rank": 96, "paragraph_comparative_number": 0, "entities": [], "id": "p_96"}, "sentences": [{"end": 46292, "text": "We next briefly review the traditional algorithm for computing the saliency map S of an image.", "rank": 460, "start": 46198, "IsComparative": "0", "id": "st_460"}]}, {"paragraph_info": {"end": 46880, "start": 46292, "text": "Then, we convolve the feature images Fi with Gaussian kernels, G, at different scales j. We find contrasting regions by computing the difference of Gaussians (DoG) images at each scale, Gi,j.We compute the DoG images at scales <,4>,<,8>.The DoG op- eration mimics the contrast detecting receptive fields of retinal ganglion cells.Figure 3.5 shows the DoG operation extracts contrasting cars from the background.N is a normal- ization function that promotes the peak salient regions <59>.The saliency map, S, is an aggregation of the normalized DoG images.We use  = 2.0 in our experiments.", "rank": 97, "paragraph_comparative_number": 3, "entities": [], "id": "p_97"}, "sentences": [{"end": 46483, "text": "Then, we convolve the feature images Fi with Gaussian kernels, G, at different scales j. We find contrasting regions by computing the difference of Gaussians (DoG) images at each scale, Gi,j.", "rank": 461, "start": 46292, "IsComparative": "0", "id": "st_461"}, {"end": 46529, "text": "We compute the DoG images at scales <,4>,<,8>.", "rank": 462, "start": 46483, "IsComparative": "0", "id": "st_462"}, {"end": 46622, "text": "The DoG op- eration mimics the contrast detecting receptive fields of retinal ganglion cells.", "rank": 463, "start": 46529, "IsComparative": "0", "id": "st_463"}, {"end": 46703, "text": "Figure 3.5 shows the DoG operation extracts contrasting cars from the background.", "rank": 464, "start": 46622, "IsComparative": "0", "id": "st_464"}, {"end": 46779, "text": "N is a normal- ization function that promotes the peak salient regions <59>.", "rank": 465, "start": 46703, "IsComparative": "1", "id": "st_465"}, {"end": 46847, "text": "The saliency map, S, is an aggregation of the normalized DoG images.", "rank": 466, "start": 46779, "IsComparative": "1", "id": "st_466"}, {"end": 46880, "text": "We use  = 2.0 in our experiments.", "rank": 467, "start": 46847, "IsComparative": "1", "id": "st_467"}]}, {"paragraph_info": {"end": 46912, "start": 46880, "text": "3.2.2 Sliding Window Aggregation", "rank": 98, "paragraph_comparative_number": 0, "entities": [], "id": "p_98"}, "sentences": [{"end": 46912, "text": "3.2.2 Sliding Window Aggregation", "rank": 468, "start": 46880, "IsComparative": "0", "id": "st_468"}]}, {"paragraph_info": {"end": 48664, "start": 46912, "text": "To see the difficulties introduced by the traditional saliency method, consider the saliency map for the parking lot image in Figure 3.4 computed by Ittis et al.<60> method.If we aggregate the saliency at all the levels of detail, we obtain the salient region in Figure 3.6(a).We observe that mostly the center of the parking lot has been included, while most of the surrounding cars have been excluded.It is interesting to note that if we analyze the saliency maps at each scale we find that cars are salient at fine scales ,2,4 and the parking lot is salient at scales 16,32,64.This can be seen in Figures 3.6(b)(d).Therefore even though the saliency maps at individual scales were able to correctly identify the constituent salient elements, the overall aggregation ended up suppressing a number of them.The reason behind this is that if the salient regions at two different scales overlap, this overlap tends to disproportionately promote the overall salience of that region.Such events are infrequent or otherwise are not of great concern when the image sizes are relatively small.However, this no longer holds true in very large images.As shown in Figure 3.4, an observer would recognize the parking lot and the cars independently of each other at different scales.Therefore we believe that it is inappropriate to aggregate the saliency of the cars and the parking lot together since they are detected by DoG filters that are 16 scales of difference apart.The key observation here is that while simulating the multiscale capabilities of the human visual system, we have to be aware that our eyes have a finite resolution.Therefore we should limit the number of scales in multiscale image processing based on the limits of the human visual system.", "rank": 99, "paragraph_comparative_number": 4, "entities": [], "id": "p_99"}, "sentences": [{"end": 47073, "text": "To see the difficulties introduced by the traditional saliency method, consider the saliency map for the parking lot image in Figure 3.4 computed by Ittis et al.", "rank": 469, "start": 46912, "IsComparative": "0", "id": "st_469"}, {"end": 47085, "text": "<60> method.", "rank": 470, "start": 47073, "IsComparative": "0", "id": "st_470"}, {"end": 47189, "text": "If we aggregate the saliency at all the levels of detail, we obtain the salient region in Figure 3.6(a).", "rank": 471, "start": 47085, "IsComparative": "0", "id": "st_471"}, {"end": 47315, "text": "We observe that mostly the center of the parking lot has been included, while most of the surrounding cars have been excluded.", "rank": 472, "start": 47189, "IsComparative": "0", "id": "st_472"}, {"end": 47492, "text": "It is interesting to note that if we analyze the saliency maps at each scale we find that cars are salient at fine scales ,2,4 and the parking lot is salient at scales 16,32,64.", "rank": 473, "start": 47315, "IsComparative": "0", "id": "st_473"}, {"end": 47530, "text": "This can be seen in Figures 3.6(b)(d).", "rank": 474, "start": 47492, "IsComparative": "0", "id": "st_474"}, {"end": 47719, "text": "Therefore even though the saliency maps at individual scales were able to correctly identify the constituent salient elements, the overall aggregation ended up suppressing a number of them.", "rank": 475, "start": 47530, "IsComparative": "1", "id": "st_475"}, {"end": 47891, "text": "The reason behind this is that if the salient regions at two different scales overlap, this overlap tends to disproportionately promote the overall salience of that region.", "rank": 476, "start": 47719, "IsComparative": "1", "id": "st_476"}, {"end": 47998, "text": "Such events are infrequent or otherwise are not of great concern when the image sizes are relatively small.", "rank": 477, "start": 47891, "IsComparative": "0", "id": "st_477"}, {"end": 48054, "text": "However, this no longer holds true in very large images.", "rank": 478, "start": 47998, "IsComparative": "0", "id": "st_478"}, {"end": 48183, "text": "As shown in Figure 3.4, an observer would recognize the parking lot and the cars independently of each other at different scales.", "rank": 479, "start": 48054, "IsComparative": "0", "id": "st_479"}, {"end": 48374, "text": "Therefore we believe that it is inappropriate to aggregate the saliency of the cars and the parking lot together since they are detected by DoG filters that are 16 scales of difference apart.", "rank": 480, "start": 48183, "IsComparative": "1", "id": "st_480"}, {"end": 48539, "text": "The key observation here is that while simulating the multiscale capabilities of the human visual system, we have to be aware that our eyes have a finite resolution.", "rank": 481, "start": 48374, "IsComparative": "1", "id": "st_481"}, {"end": 48664, "text": "Therefore we should limit the number of scales in multiscale image processing based on the limits of the human visual system.", "rank": 482, "start": 48539, "IsComparative": "0", "id": "st_482"}]}, {"paragraph_info": {"end": 49337, "start": 48664, "text": "To address the above, we introduce a sliding-window approach to build saliency maps at multiple scales with limited aggre- gation.In this approach by limiting the scales of saliency aggregation we produce multiple maps that simulate the zooming op- eration.This allows views of drastically dif- ferent scales to be analyzed virtually inde- pendently of each other.For example, we can extract cars from the aggregation of nor- malized maps at scales < , 2 , 4 >.Fig- ure 3.6(b) shows the resulting saliency map.It highlights most of the cars without high- lighting the parking lot.We separate salient regions at widely different scales by limiting the aggregation procedure.", "rank": 100, "paragraph_comparative_number": 3, "entities": [], "id": "p_100"}, "sentences": [{"end": 48794, "text": "To address the above, we introduce a sliding-window approach to build saliency maps at multiple scales with limited aggre- gation.", "rank": 483, "start": 48664, "IsComparative": "0", "id": "st_483"}, {"end": 48921, "text": "In this approach by limiting the scales of saliency aggregation we produce multiple maps that simulate the zooming op- eration.", "rank": 484, "start": 48794, "IsComparative": "1", "id": "st_484"}, {"end": 49028, "text": "This allows views of drastically dif- ferent scales to be analyzed virtually inde- pendently of each other.", "rank": 485, "start": 48921, "IsComparative": "1", "id": "st_485"}, {"end": 49125, "text": "For example, we can extract cars from the aggregation of nor- malized maps at scales < , 2 , 4 >.", "rank": 486, "start": 49028, "IsComparative": "1", "id": "st_486"}, {"end": 49174, "text": "Fig- ure 3.6(b) shows the resulting saliency map.", "rank": 487, "start": 49125, "IsComparative": "0", "id": "st_487"}, {"end": 49244, "text": "It highlights most of the cars without high- lighting the parking lot.", "rank": 488, "start": 49174, "IsComparative": "0", "id": "st_488"}, {"end": 49337, "text": "We separate salient regions at widely different scales by limiting the aggregation procedure.", "rank": 489, "start": 49244, "IsComparative": "0", "id": "st_489"}]}, {"paragraph_info": {"end": 49661, "start": 49337, "text": "This sliding window approach ensures overlapping regions from drastically different scales do not interfere with one another.We seek a scale difference  that truly reflects the human visual system.We use  = 4 j in this chapter.We next use arguments from the human visual system theory to suggest why this may be appropriate.", "rank": 101, "paragraph_comparative_number": 1, "entities": [], "id": "p_101"}, "sentences": [{"end": 49462, "text": "This sliding window approach ensures overlapping regions from drastically different scales do not interfere with one another.", "rank": 490, "start": 49337, "IsComparative": "0", "id": "st_490"}, {"end": 49534, "text": "We seek a scale difference  that truly reflects the human visual system.", "rank": 491, "start": 49462, "IsComparative": "0", "id": "st_491"}, {"end": 49564, "text": "We use  = 4 j in this chapter.", "rank": 492, "start": 49534, "IsComparative": "0", "id": "st_492"}, {"end": 49661, "text": "We next use arguments from the human visual system theory to suggest why this may be appropriate.", "rank": 493, "start": 49564, "IsComparative": "1", "id": "st_493"}]}, {"paragraph_info": {"end": 50323, "start": 49661, "text": "Human Visual System Considerations We would like to use the scales in multiscale image processing based on the sensitivity difference between foveal and peripheral vision.Perceptual studies have shown that the fovea is the most sensitive region of the retina and the sensitivity drops as the view angle increases.Let us assume that we are viewing an image on a 30-inch monitor at 1 meter.In this case, the view angle subtended from the edge of the monitor to the center of the screen is about 20.At 20, our retina retains approximately 1/5th of the foveal resolution.Therefore, we have decided to compute the saliency maps with images within the 4 scales (  4 ).", "rank": 102, "paragraph_comparative_number": 4, "entities": [], "id": "p_102"}, "sentences": [{"end": 49832, "text": "Human Visual System Considerations We would like to use the scales in multiscale image processing based on the sensitivity difference between foveal and peripheral vision.", "rank": 494, "start": 49661, "IsComparative": "1", "id": "st_494"}, {"end": 49974, "text": "Perceptual studies have shown that the fovea is the most sensitive region of the retina and the sensitivity drops as the view angle increases.", "rank": 495, "start": 49832, "IsComparative": "0", "id": "st_495"}, {"end": 50049, "text": "Let us assume that we are viewing an image on a 30-inch monitor at 1 meter.", "rank": 496, "start": 49974, "IsComparative": "0", "id": "st_496"}, {"end": 50157, "text": "In this case, the view angle subtended from the edge of the monitor to the center of the screen is about 20.", "rank": 497, "start": 50049, "IsComparative": "1", "id": "st_497"}, {"end": 50228, "text": "At 20, our retina retains approximately 1/5th of the foveal resolution.", "rank": 498, "start": 50157, "IsComparative": "1", "id": "st_498"}, {"end": 50323, "text": "Therefore, we have decided to compute the saliency maps with images within the 4 scales (  4 ).", "rank": 499, "start": 50228, "IsComparative": "1", "id": "st_499"}]}, {"paragraph_info": {"end": 50348, "start": 50323, "text": "3.3 Information Discovery", "rank": 103, "paragraph_comparative_number": 0, "entities": [], "id": "p_103"}, "sentences": [{"end": 50348, "text": "3.3 Information Discovery", "rank": 500, "start": 50323, "IsComparative": "0", "id": "st_500"}]}, {"paragraph_info": {"end": 51370, "start": 50348, "text": "It is difficult to quantify the visual information content of a region.Some very interesting advances have been made in this field recently.Ja nicke et al.<66, 65, 67> have extended the idea of local statistical complexity to measure the local information content of a region.This provides an application-independent, purely mathematical measurement of information.More recently, a very interesting and expansive treatment of how saliency and information theory can be adapted and adopted for visualization has been carried out by Chen and Ja nicke <18, 64>.In this chapter we wish to slightly side-step the deeply intriguing topic of how to quantify visual information content of a region in the general case, and instead talk about what we have found to work well for large-scale landscape images.We hope that further advances in the field of visual information quantification will seamlessly replace the method that we outline next to work with a wide variety of very large image databases beyond just landscape images.", "rank": 104, "paragraph_comparative_number": 4, "entities": [], "id": "p_104"}, "sentences": [{"end": 50419, "text": "It is difficult to quantify the visual information content of a region.", "rank": 501, "start": 50348, "IsComparative": "1", "id": "st_501"}, {"end": 50488, "text": "Some very interesting advances have been made in this field recently.", "rank": 502, "start": 50419, "IsComparative": "0", "id": "st_502"}, {"end": 50503, "text": "Ja nicke et al.", "rank": 503, "start": 50488, "IsComparative": "0", "id": "st_503"}, {"end": 50624, "text": "<66, 65, 67> have extended the idea of local statistical complexity to measure the local information content of a region.", "rank": 504, "start": 50503, "IsComparative": "1", "id": "st_504"}, {"end": 50713, "text": "This provides an application-independent, purely mathematical measurement of information.", "rank": 505, "start": 50624, "IsComparative": "0", "id": "st_505"}, {"end": 50906, "text": "More recently, a very interesting and expansive treatment of how saliency and information theory can be adapted and adopted for visualization has been carried out by Chen and Ja nicke <18, 64>.", "rank": 506, "start": 50713, "IsComparative": "0", "id": "st_506"}, {"end": 51147, "text": "In this chapter we wish to slightly side-step the deeply intriguing topic of how to quantify visual information content of a region in the general case, and instead talk about what we have found to work well for large-scale landscape images.", "rank": 507, "start": 50906, "IsComparative": "1", "id": "st_507"}, {"end": 51370, "text": "We hope that further advances in the field of visual information quantification will seamlessly replace the method that we outline next to work with a wide variety of very large image databases beyond just landscape images.", "rank": 508, "start": 51147, "IsComparative": "1", "id": "st_508"}]}, {"paragraph_info": {"end": 51843, "start": 51370, "text": "In this chapter we have decided to adopt the approach that the most important re- gions of an image are those that are the most different from every other region.In other words, we are interested in identifying the outliers, or the anomalies, in a very large im- age.As seen in Figure 3.7, the sliding-window saliency aggregation step identifies a large number of salient regions.They range from patches of grass on the ground, to cracks between the rocks in the mountains.", "rank": 105, "paragraph_comparative_number": 1, "entities": [], "id": "p_105"}, "sentences": [{"end": 51532, "text": "In this chapter we have decided to adopt the approach that the most important re- gions of an image are those that are the most different from every other region.", "rank": 509, "start": 51370, "IsComparative": "1", "id": "st_509"}, {"end": 51637, "text": "In other words, we are interested in identifying the outliers, or the anomalies, in a very large im- age.", "rank": 510, "start": 51532, "IsComparative": "0", "id": "st_510"}, {"end": 51750, "text": "As seen in Figure 3.7, the sliding-window saliency aggregation step identifies a large number of salient regions.", "rank": 511, "start": 51637, "IsComparative": "0", "id": "st_511"}, {"end": 51843, "text": "They range from patches of grass on the ground, to cracks between the rocks in the mountains.", "rank": 512, "start": 51750, "IsComparative": "0", "id": "st_512"}]}, {"paragraph_info": {"end": 51873, "start": 51843, "text": "3.3.1 Image Region Descriptors", "rank": 106, "paragraph_comparative_number": 0, "entities": [], "id": "p_106"}, "sentences": [{"end": 51873, "text": "3.3.1 Image Region Descriptors", "rank": 513, "start": 51843, "IsComparative": "0", "id": "st_513"}]}, {"paragraph_info": {"end": 52081, "start": 51873, "text": "To be able to quantify differences amongst different image regions we need to first identify what we mean by an image region and then we need to settle on the space in which such differences will be measured.", "rank": 107, "paragraph_comparative_number": 1, "entities": [], "id": "p_107"}, "sentences": [{"end": 52081, "text": "To be able to quantify differences amongst different image regions we need to first identify what we mean by an image region and then we need to settle on the space in which such differences will be measured.", "rank": 514, "start": 51873, "IsComparative": "1", "id": "st_514"}]}, {"paragraph_info": {"end": 52479, "start": 52081, "text": "To identify an image region, we fit oriented ellipses to the salient regions that were detected in the previous section.We then fit bounding boxes to the ellipses, pad them by a few extra pixels (we have used 20 pixels for all the examples in this chapter) to ensure that the padded bounding boxes fully enclose the salient regions.These bounding boxes then represent the image regions of interest.", "rank": 108, "paragraph_comparative_number": 1, "entities": [], "id": "p_108"}, "sentences": [{"end": 52201, "text": "To identify an image region, we fit oriented ellipses to the salient regions that were detected in the previous section.", "rank": 515, "start": 52081, "IsComparative": "0", "id": "st_515"}, {"end": 52413, "text": "We then fit bounding boxes to the ellipses, pad them by a few extra pixels (we have used 20 pixels for all the examples in this chapter) to ensure that the padded bounding boxes fully enclose the salient regions.", "rank": 516, "start": 52201, "IsComparative": "1", "id": "st_516"}, {"end": 52479, "text": "These bounding boxes then represent the image regions of interest.", "rank": 517, "start": 52413, "IsComparative": "0", "id": "st_517"}]}, {"paragraph_info": {"end": 53086, "start": 52479, "text": "To achieve rotational invariance, we use histograms of the color-space of the pixels belonging to the region of interest.We have tested a number of color spaces  RGB, HSV, CIELab and found that neither of them were very discriminative.We also experimented with shape and orientation descriptors and found that they were excessively discrimi- native.This search led us towards a descriptor that would represent both color as well as statistical structural information of an image region and would have a discriminating ability that would lie between the two extremes (color-based and edge-based descriptors).", "rank": 109, "paragraph_comparative_number": 3, "entities": [], "id": "p_109"}, "sentences": [{"end": 52600, "text": "To achieve rotational invariance, we use histograms of the color-space of the pixels belonging to the region of interest.", "rank": 518, "start": 52479, "IsComparative": "1", "id": "st_518"}, {"end": 52714, "text": "We have tested a number of color spaces  RGB, HSV, CIELab and found that neither of them were very discriminative.", "rank": 519, "start": 52600, "IsComparative": "0", "id": "st_519"}, {"end": 52828, "text": "We also experimented with shape and orientation descriptors and found that they were excessively discrimi- native.", "rank": 520, "start": 52714, "IsComparative": "1", "id": "st_520"}, {"end": 53086, "text": "This search led us towards a descriptor that would represent both color as well as statistical structural information of an image region and would have a discriminating ability that would lie between the two extremes (color-based and edge-based descriptors).", "rank": 521, "start": 52828, "IsComparative": "1", "id": "st_521"}]}, {"paragraph_info": {"end": 54124, "start": 53086, "text": "The MPEG-7 color-structure image descriptor represents both color and structural information.The MPEG-7 is an ISO standard for describing multimedia content data and facilitates information retrieval.It consists of generic descriptors that cover many basic visual features, such as color, texture, and shape.The MPEG-7 color-structure descriptor embeds color structure information into the descriptor by counting color frequencies in a moving window of 8  8 pixels.Color values are represented in the double-coned HMMD color space, which is quantized non-uniformly into 64 bins.The range of histogram is normalized to 0  255.The resulting descriptor is a 64-dimensional vector.We follow the recommendation of MPEG-7 standard and compare them using the Euclidean L2 norm distance.p and q are the descriptors of two image patches and D(p,q) is the distance in between the descriptors.We compute the MPEG-7 color-structure descriptor for each image patch using the software provided by the BilVideo-7 <5> video indexing and retrieval system.", "rank": 110, "paragraph_comparative_number": 5, "entities": [], "id": "p_110"}, "sentences": [{"end": 53179, "text": "The MPEG-7 color-structure image descriptor represents both color and structural information.", "rank": 522, "start": 53086, "IsComparative": "0", "id": "st_522"}, {"end": 53286, "text": "The MPEG-7 is an ISO standard for describing multimedia content data and facilitates information retrieval.", "rank": 523, "start": 53179, "IsComparative": "1", "id": "st_523"}, {"end": 53394, "text": "It consists of generic descriptors that cover many basic visual features, such as color, texture, and shape.", "rank": 524, "start": 53286, "IsComparative": "0", "id": "st_524"}, {"end": 53551, "text": "The MPEG-7 color-structure descriptor embeds color structure information into the descriptor by counting color frequencies in a moving window of 8  8 pixels.", "rank": 525, "start": 53394, "IsComparative": "1", "id": "st_525"}, {"end": 53664, "text": "Color values are represented in the double-coned HMMD color space, which is quantized non-uniformly into 64 bins.", "rank": 526, "start": 53551, "IsComparative": "1", "id": "st_526"}, {"end": 53711, "text": "The range of histogram is normalized to 0  255.", "rank": 527, "start": 53664, "IsComparative": "0", "id": "st_527"}, {"end": 53763, "text": "The resulting descriptor is a 64-dimensional vector.", "rank": 528, "start": 53711, "IsComparative": "0", "id": "st_528"}, {"end": 53865, "text": "We follow the recommendation of MPEG-7 standard and compare them using the Euclidean L2 norm distance.", "rank": 529, "start": 53763, "IsComparative": "1", "id": "st_529"}, {"end": 53968, "text": "p and q are the descriptors of two image patches and D(p,q) is the distance in between the descriptors.", "rank": 530, "start": 53865, "IsComparative": "1", "id": "st_530"}, {"end": 54124, "text": "We compute the MPEG-7 color-structure descriptor for each image patch using the software provided by the BilVideo-7 <5> video indexing and retrieval system.", "rank": 531, "start": 53968, "IsComparative": "0", "id": "st_531"}]}, {"paragraph_info": {"end": 54167, "start": 54124, "text": "3.3.2 k-Nearest-Neighbors Anomaly Detection", "rank": 111, "paragraph_comparative_number": 1, "entities": [], "id": "p_111"}, "sentences": [{"end": 54167, "text": "3.3.2 k-Nearest-Neighbors Anomaly Detection", "rank": 532, "start": 54124, "IsComparative": "1", "id": "st_532"}]}, {"paragraph_info": {"end": 54737, "start": 54167, "text": "We compute the uniqueness of each region by considering its k-nearest-neighbors P is a set of image patch descriptors.The uniqueness of image patch p, U(p), is its average distance to its k-nearest neighbors, q1 ...qk.Repetitive regions with many close neighbors have a low average distance.Regions such as humans, signs, or vehicles should be distinct from the other regions and have a high average distance.We identify the unique regions of interest by their high average distances.We select the top 3% of salient regions as the regions of interest in our experiments.", "rank": 112, "paragraph_comparative_number": 3, "entities": [], "id": "p_112"}, "sentences": [{"end": 54285, "text": "We compute the uniqueness of each region by considering its k-nearest-neighbors P is a set of image patch descriptors.", "rank": 533, "start": 54167, "IsComparative": "1", "id": "st_533"}, {"end": 54385, "text": "The uniqueness of image patch p, U(p), is its average distance to its k-nearest neighbors, q1 ...qk.", "rank": 534, "start": 54285, "IsComparative": "1", "id": "st_534"}, {"end": 54458, "text": "Repetitive regions with many close neighbors have a low average distance.", "rank": 535, "start": 54385, "IsComparative": "0", "id": "st_535"}, {"end": 54576, "text": "Regions such as humans, signs, or vehicles should be distinct from the other regions and have a high average distance.", "rank": 536, "start": 54458, "IsComparative": "0", "id": "st_536"}, {"end": 54651, "text": "We identify the unique regions of interest by their high average distances.", "rank": 537, "start": 54576, "IsComparative": "0", "id": "st_537"}, {"end": 54737, "text": "We select the top 3% of salient regions as the regions of interest in our experiments.", "rank": 538, "start": 54651, "IsComparative": "1", "id": "st_538"}]}, {"paragraph_info": {"end": 55568, "start": 54737, "text": "Approximate nearest-neighbor data structures accelerate the k-nearest-neighbor search <138>.The biggest overhead in the k-nearest-neighbors anomaly detection is the need to retrieve k-nearest-neighbors for each region.Linear search of the k-nearest-neighbor queries is computationally expensive.Research in computational geometry provides many spatial data structures to facilitate this nearest neighbor querying.The approximated nearest- neighbors index significantly accelerates this search process.The sum of distances to the top k-approximated nearest-neighbors provides a reliable uniqueness estimate of each re- gion.Our implementation uses a randomized KD-Tree index in the flann library <111> through the OpenCV library.tection phase.This process reduces the 18 thousand salient regions to just about 500 anomalous regions.", "rank": 113, "paragraph_comparative_number": 5, "entities": [], "id": "p_113"}, "sentences": [{"end": 54829, "text": "Approximate nearest-neighbor data structures accelerate the k-nearest-neighbor search <138>.", "rank": 539, "start": 54737, "IsComparative": "0", "id": "st_539"}, {"end": 54955, "text": "The biggest overhead in the k-nearest-neighbors anomaly detection is the need to retrieve k-nearest-neighbors for each region.", "rank": 540, "start": 54829, "IsComparative": "1", "id": "st_540"}, {"end": 55032, "text": "Linear search of the k-nearest-neighbor queries is computationally expensive.", "rank": 541, "start": 54955, "IsComparative": "1", "id": "st_541"}, {"end": 55150, "text": "Research in computational geometry provides many spatial data structures to facilitate this nearest neighbor querying.", "rank": 542, "start": 55032, "IsComparative": "0", "id": "st_542"}, {"end": 55238, "text": "The approximated nearest- neighbors index significantly accelerates this search process.", "rank": 543, "start": 55150, "IsComparative": "0", "id": "st_543"}, {"end": 55360, "text": "The sum of distances to the top k-approximated nearest-neighbors provides a reliable uniqueness estimate of each re- gion.", "rank": 544, "start": 55238, "IsComparative": "1", "id": "st_544"}, {"end": 55465, "text": "Our implementation uses a randomized KD-Tree index in the flann library <111> through the OpenCV library.", "rank": 545, "start": 55360, "IsComparative": "1", "id": "st_545"}, {"end": 55479, "text": "tection phase.", "rank": 546, "start": 55465, "IsComparative": "0", "id": "st_546"}, {"end": 55568, "text": "This process reduces the 18 thousand salient regions to just about 500 anomalous regions.", "rank": 547, "start": 55479, "IsComparative": "1", "id": "st_547"}]}, {"paragraph_info": {"end": 55597, "start": 55568, "text": "3.4 Interactive Visualization", "rank": 114, "paragraph_comparative_number": 0, "entities": [], "id": "p_114"}, "sentences": [{"end": 55597, "text": "3.4 Interactive Visualization", "rank": 548, "start": 55568, "IsComparative": "0", "id": "st_548"}]}, {"paragraph_info": {"end": 55858, "start": 55597, "text": "We guide users to explore the image through the detected regions and interactive visualization.We visualize the detected regions, provide automatic fly-through, and allow interactive user refinement.We highlight three features to assist large image exploration.", "rank": 115, "paragraph_comparative_number": 1, "entities": [], "id": "p_115"}, "sentences": [{"end": 55692, "text": "We guide users to explore the image through the detected regions and interactive visualization.", "rank": 549, "start": 55597, "IsComparative": "0", "id": "st_549"}, {"end": 55796, "text": "We visualize the detected regions, provide automatic fly-through, and allow interactive user refinement.", "rank": 550, "start": 55692, "IsComparative": "0", "id": "st_550"}, {"end": 55858, "text": "We highlight three features to assist large image exploration.", "rank": 551, "start": 55796, "IsComparative": "1", "id": "st_551"}]}, {"paragraph_info": {"end": 55919, "start": 55858, "text": "Adaptive scaling ensures the regions of interest are visible.", "rank": 116, "paragraph_comparative_number": 0, "entities": [], "id": "p_116"}, "sentences": [{"end": 55919, "text": "Adaptive scaling ensures the regions of interest are visible.", "rank": 552, "start": 55858, "IsComparative": "0", "id": "st_552"}]}, {"paragraph_info": {"end": 56050, "start": 55919, "text": "Automatic exploration guides the user to discover the unique regions of the image.User interaction refines the computed detections.", "rank": 117, "paragraph_comparative_number": 0, "entities": [], "id": "p_117"}, "sentences": [{"end": 56001, "text": "Automatic exploration guides the user to discover the unique regions of the image.", "rank": 553, "start": 55919, "IsComparative": "0", "id": "st_553"}, {"end": 56050, "text": "User interaction refines the computed detections.", "rank": 554, "start": 56001, "IsComparative": "0", "id": "st_554"}]}, {"paragraph_info": {"end": 56088, "start": 56050, "text": "3.4.1 Visualizing the Detected Regions", "rank": 118, "paragraph_comparative_number": 0, "entities": [], "id": "p_118"}, "sentences": [{"end": 56088, "text": "3.4.1 Visualizing the Detected Regions", "rank": 555, "start": 56050, "IsComparative": "0", "id": "st_555"}]}, {"paragraph_info": {"end": 56471, "start": 56088, "text": "We want the users to see the detected regions from the macro view of the image and also allow them to zoom-in to inspect.We believe maintaining the zooming procedure gives the users a much more natural context.Small regions are invisible at the macro view, therefore the corresponding overlay regions are also too small to be seen.We need to visualize these regions more effectively.", "rank": 119, "paragraph_comparative_number": 1, "entities": [], "id": "p_119"}, "sentences": [{"end": 56209, "text": "We want the users to see the detected regions from the macro view of the image and also allow them to zoom-in to inspect.", "rank": 556, "start": 56088, "IsComparative": "0", "id": "st_556"}, {"end": 56298, "text": "We believe maintaining the zooming procedure gives the users a much more natural context.", "rank": 557, "start": 56209, "IsComparative": "0", "id": "st_557"}, {"end": 56419, "text": "Small regions are invisible at the macro view, therefore the corresponding overlay regions are also too small to be seen.", "rank": 558, "start": 56298, "IsComparative": "1", "id": "st_558"}, {"end": 56471, "text": "We need to visualize these regions more effectively.", "rank": 559, "start": 56419, "IsComparative": "0", "id": "st_559"}]}, {"paragraph_info": {"end": 57095, "start": 56471, "text": "We adaptively scale the overlay tags on the detected regions to ensure the most unique regions are visible.We compute the scale,  , as follows: uniqueness of region r as determined by equation 3.3 and # regions is the number of regions identified at the end of the anomaly detection phase.Thus, the greater the unique- ness of a region r, the greater the  (r) would be.As we zoom into an image, sr increases and  (r) gradually decreases, and the overlay tags will be shown in their actual size once sr  sm.We color the overlay tags from cyan to magenta (the most unique) according to their rank of uniqueness (equation 3.3).", "rank": 120, "paragraph_comparative_number": 3, "entities": [], "id": "p_120"}, "sentences": [{"end": 56578, "text": "We adaptively scale the overlay tags on the detected regions to ensure the most unique regions are visible.", "rank": 560, "start": 56471, "IsComparative": "0", "id": "st_560"}, {"end": 56760, "text": "We compute the scale,  , as follows: uniqueness of region r as determined by equation 3.3 and # regions is the number of regions identified at the end of the anomaly detection phase.", "rank": 561, "start": 56578, "IsComparative": "0", "id": "st_561"}, {"end": 56840, "text": "Thus, the greater the unique- ness of a region r, the greater the  (r) would be.", "rank": 562, "start": 56760, "IsComparative": "1", "id": "st_562"}, {"end": 56977, "text": "As we zoom into an image, sr increases and  (r) gradually decreases, and the overlay tags will be shown in their actual size once sr  sm.", "rank": 563, "start": 56840, "IsComparative": "1", "id": "st_563"}, {"end": 57095, "text": "We color the overlay tags from cyan to magenta (the most unique) according to their rank of uniqueness (equation 3.3).", "rank": 564, "start": 56977, "IsComparative": "1", "id": "st_564"}]}, {"paragraph_info": {"end": 57122, "start": 57095, "text": "3.4.2 Automatic Exploration", "rank": 121, "paragraph_comparative_number": 0, "entities": [], "id": "p_121"}, "sentences": [{"end": 57122, "text": "3.4.2 Automatic Exploration", "rank": 565, "start": 57095, "IsComparative": "0", "id": "st_565"}]}, {"paragraph_info": {"end": 57652, "start": 57122, "text": "Our system guides the users to fly through the detected regions.This helps the users to start exploring the image when they know little about it.It smoothly pans and zooms into the detected regions according to their uniqueness.We achieve this by sorting the regions in descending order of their uniqueness (equation 3.3).This forms a natu- ral exploration sequence that starts from the most unique regions.If users come across misidentified regions during the fly-through, they can suppress the regions by interactive refinement.", "rank": 122, "paragraph_comparative_number": 3, "entities": [], "id": "p_122"}, "sentences": [{"end": 57186, "text": "Our system guides the users to fly through the detected regions.", "rank": 566, "start": 57122, "IsComparative": "1", "id": "st_566"}, {"end": 57267, "text": "This helps the users to start exploring the image when they know little about it.", "rank": 567, "start": 57186, "IsComparative": "0", "id": "st_567"}, {"end": 57350, "text": "It smoothly pans and zooms into the detected regions according to their uniqueness.", "rank": 568, "start": 57267, "IsComparative": "1", "id": "st_568"}, {"end": 57444, "text": "We achieve this by sorting the regions in descending order of their uniqueness (equation 3.3).", "rank": 569, "start": 57350, "IsComparative": "1", "id": "st_569"}, {"end": 57529, "text": "This forms a natu- ral exploration sequence that starts from the most unique regions.", "rank": 570, "start": 57444, "IsComparative": "0", "id": "st_570"}, {"end": 57652, "text": "If users come across misidentified regions during the fly-through, they can suppress the regions by interactive refinement.", "rank": 571, "start": 57529, "IsComparative": "0", "id": "st_571"}]}, {"paragraph_info": {"end": 57680, "start": 57652, "text": "3.4.3 Interactive Refinement", "rank": 123, "paragraph_comparative_number": 0, "entities": [], "id": "p_123"}, "sentences": [{"end": 57680, "text": "3.4.3 Interactive Refinement", "rank": 572, "start": 57652, "IsComparative": "0", "id": "st_572"}]}, {"paragraph_info": {"end": 58084, "start": 57680, "text": "Automated systems recognize a lot of regions of interest but they may also make mistakes.Our system allows the users to refine the results by selecting misidentified regions and deleting them.This mechanism allows the users to refine the automatic result but it can be tedious when users need to delete multiple regions.We provide interactions in our system to batch delete misidentified similar regions.", "rank": 124, "paragraph_comparative_number": 3, "entities": [], "id": "p_124"}, "sentences": [{"end": 57769, "text": "Automated systems recognize a lot of regions of interest but they may also make mistakes.", "rank": 573, "start": 57680, "IsComparative": "0", "id": "st_573"}, {"end": 57872, "text": "Our system allows the users to refine the results by selecting misidentified regions and deleting them.", "rank": 574, "start": 57769, "IsComparative": "1", "id": "st_574"}, {"end": 58000, "text": "This mechanism allows the users to refine the automatic result but it can be tedious when users need to delete multiple regions.", "rank": 575, "start": 57872, "IsComparative": "1", "id": "st_575"}, {"end": 58084, "text": "We provide interactions in our system to batch delete misidentified similar regions.", "rank": 576, "start": 58000, "IsComparative": "1", "id": "st_576"}]}, {"paragraph_info": {"end": 58904, "start": 58084, "text": "The user may delete a batch of misidentified regions that are similar in a single interaction.Figure 3.9 illustrates this mechanism.This select-slide-delete mechanism can remove many misidentified similar regions at once.In the first step the user identifies a set of regions that in the opinion of the user have been misidentified by the system.Amongst these regions, the user selects one representative region in the second step.This is highlighted by the system.In the third step the user adjusts a slider control to change the similarity distance from the one misidentified representative region to others that are like it.The system interactively highlights other regions that it detects to be similar to the misidentified region.Once the highlighted regions match the users intent, they can be deleted all at once.", "rank": 125, "paragraph_comparative_number": 0, "entities": [], "id": "p_125"}, "sentences": [{"end": 58178, "text": "The user may delete a batch of misidentified regions that are similar in a single interaction.", "rank": 577, "start": 58084, "IsComparative": "0", "id": "st_577"}, {"end": 58216, "text": "Figure 3.9 illustrates this mechanism.", "rank": 578, "start": 58178, "IsComparative": "0", "id": "st_578"}, {"end": 58305, "text": "This select-slide-delete mechanism can remove many misidentified similar regions at once.", "rank": 579, "start": 58216, "IsComparative": "0", "id": "st_579"}, {"end": 58430, "text": "In the first step the user identifies a set of regions that in the opinion of the user have been misidentified by the system.", "rank": 580, "start": 58305, "IsComparative": "0", "id": "st_580"}, {"end": 58515, "text": "Amongst these regions, the user selects one representative region in the second step.", "rank": 581, "start": 58430, "IsComparative": "0", "id": "st_581"}, {"end": 58549, "text": "This is highlighted by the system.", "rank": 582, "start": 58515, "IsComparative": "0", "id": "st_582"}, {"end": 58711, "text": "In the third step the user adjusts a slider control to change the similarity distance from the one misidentified representative region to others that are like it.", "rank": 583, "start": 58549, "IsComparative": "0", "id": "st_583"}, {"end": 58819, "text": "The system interactively highlights other regions that it detects to be similar to the misidentified region.", "rank": 584, "start": 58711, "IsComparative": "0", "id": "st_584"}, {"end": 58904, "text": "Once the highlighted regions match the users intent, they can be deleted all at once.", "rank": 585, "start": 58819, "IsComparative": "0", "id": "st_585"}]}, {"paragraph_info": {"end": 59631, "start": 58904, "text": "The spatial index and color-structure descriptors of regions provide the interactive search capability.The anomaly detection spatial index is used in this step to provide fast similarity queries for regions.The system expands the region selection by querying the spatial index for regions that are similar to the user selection.The slider thresholds the number of regions retrieved.The spatial index performs a fast nearest-neighbor query to retrieve similar regions.The system includes these regions in the selection and performs these operations at an interactive speed.Figure 3.10 shows our results after a few user interactions.The number of detected regions reduces from 500 to about 300 with just three such interactions.", "rank": 126, "paragraph_comparative_number": 4, "entities": [], "id": "p_126"}, "sentences": [{"end": 59007, "text": "The spatial index and color-structure descriptors of regions provide the interactive search capability.", "rank": 586, "start": 58904, "IsComparative": "0", "id": "st_586"}, {"end": 59111, "text": "The anomaly detection spatial index is used in this step to provide fast similarity queries for regions.", "rank": 587, "start": 59007, "IsComparative": "0", "id": "st_587"}, {"end": 59232, "text": "The system expands the region selection by querying the spatial index for regions that are similar to the user selection.", "rank": 588, "start": 59111, "IsComparative": "1", "id": "st_588"}, {"end": 59286, "text": "The slider thresholds the number of regions retrieved.", "rank": 589, "start": 59232, "IsComparative": "0", "id": "st_589"}, {"end": 59371, "text": "The spatial index performs a fast nearest-neighbor query to retrieve similar regions.", "rank": 590, "start": 59286, "IsComparative": "1", "id": "st_590"}, {"end": 59476, "text": "The system includes these regions in the selection and performs these operations at an interactive speed.", "rank": 591, "start": 59371, "IsComparative": "0", "id": "st_591"}, {"end": 59536, "text": "Figure 3.10 shows our results after a few user interactions.", "rank": 592, "start": 59476, "IsComparative": "1", "id": "st_592"}, {"end": 59631, "text": "The number of detected regions reduces from 500 to about 300 with just three such interactions.", "rank": 593, "start": 59536, "IsComparative": "1", "id": "st_593"}]}, {"paragraph_info": {"end": 59651, "start": 59631, "text": "3.5 Data Scalability", "rank": 127, "paragraph_comparative_number": 1, "entities": [], "id": "p_127"}, "sentences": [{"end": 59651, "text": "3.5 Data Scalability", "rank": 594, "start": 59631, "IsComparative": "1", "id": "st_594"}]}, {"paragraph_info": {"end": 59878, "start": 59651, "text": "Processing many gigabytes of image data requires out-of-core algorithms and tech- niques.We pay special attention to memory constraints when we implement our saliency computation, storage of results, and our interactive viewer.", "rank": 128, "paragraph_comparative_number": 1, "entities": [], "id": "p_128"}, "sentences": [{"end": 59740, "text": "Processing many gigabytes of image data requires out-of-core algorithms and tech- niques.", "rank": 595, "start": 59651, "IsComparative": "0", "id": "st_595"}, {"end": 59878, "text": "We pay special attention to memory constraints when we implement our saliency computation, storage of results, and our interactive viewer.", "rank": 596, "start": 59740, "IsComparative": "1", "id": "st_596"}]}, {"paragraph_info": {"end": 59920, "start": 59878, "text": "3.5.1 Out-of-core GPU Saliency Computation", "rank": 129, "paragraph_comparative_number": 0, "entities": [], "id": "p_129"}, "sentences": [{"end": 59920, "text": "3.5.1 Out-of-core GPU Saliency Computation", "rank": 597, "start": 59878, "IsComparative": "0", "id": "st_597"}]}, {"paragraph_info": {"end": 60147, "start": 59920, "text": "We use GPUs to accelerate image saliency computation.The required operations for Difference of Gaussians (DoG): image filtering, addition, subtraction, and resizing are highly parallelizable and suitable for GPU implementation.", "rank": 130, "paragraph_comparative_number": 0, "entities": [], "id": "p_130"}, "sentences": [{"end": 59973, "text": "We use GPUs to accelerate image saliency computation.", "rank": 598, "start": 59920, "IsComparative": "0", "id": "st_598"}, {"end": 60147, "text": "The required operations for Difference of Gaussians (DoG): image filtering, addition, subtraction, and resizing are highly parallelizable and suitable for GPU implementation.", "rank": 599, "start": 59973, "IsComparative": "0", "id": "st_599"}]}, {"paragraph_info": {"end": 60730, "start": 60147, "text": "We compute a Gaussian pyramid to approximate the Gaussian blurred images at different scales.We repeatedly downsize the image by a scale of two and convolve it with a fixed Gaussian kernel of scale .We store the x scale Gaussian image at level log2(x) of the pyramid.The DoG images can be computed by simply finding the differ- ence of Gaussians images between two levels.The non-linear normalization function N iteratively applies the DoG operation <59> to promote the peak regions.We compute each of these normalized maps once and use them to compose sliding-window saliency maps .", "rank": 131, "paragraph_comparative_number": 4, "entities": [], "id": "p_131"}, "sentences": [{"end": 60240, "text": "We compute a Gaussian pyramid to approximate the Gaussian blurred images at different scales.", "rank": 600, "start": 60147, "IsComparative": "0", "id": "st_600"}, {"end": 60346, "text": "We repeatedly downsize the image by a scale of two and convolve it with a fixed Gaussian kernel of scale .", "rank": 601, "start": 60240, "IsComparative": "1", "id": "st_601"}, {"end": 60414, "text": "We store the x scale Gaussian image at level log2(x) of the pyramid.", "rank": 602, "start": 60346, "IsComparative": "0", "id": "st_602"}, {"end": 60519, "text": "The DoG images can be computed by simply finding the differ- ence of Gaussians images between two levels.", "rank": 603, "start": 60414, "IsComparative": "1", "id": "st_603"}, {"end": 60630, "text": "The non-linear normalization function N iteratively applies the DoG operation <59> to promote the peak regions.", "rank": 604, "start": 60519, "IsComparative": "1", "id": "st_604"}, {"end": 60730, "text": "We compute each of these normalized maps once and use them to compose sliding-window saliency maps .", "rank": 605, "start": 60630, "IsComparative": "1", "id": "st_605"}]}, {"paragraph_info": {"end": 61055, "start": 60730, "text": "A significant problem in processing very large images (which currently are a few gigapixels) is that the entire image will not fit in the GPU or main memory.To address this, we divide each image into small tiles (256  256).We load the image tiles into the GPU independently for addition, subtraction, and resizing operations.", "rank": 132, "paragraph_comparative_number": 1, "entities": [], "id": "p_132"}, "sentences": [{"end": 60887, "text": "A significant problem in processing very large images (which currently are a few gigapixels) is that the entire image will not fit in the GPU or main memory.", "rank": 606, "start": 60730, "IsComparative": "0", "id": "st_606"}, {"end": 60953, "text": "To address this, we divide each image into small tiles (256  256).", "rank": 607, "start": 60887, "IsComparative": "1", "id": "st_607"}, {"end": 61055, "text": "We load the image tiles into the GPU independently for addition, subtraction, and resizing operations.", "rank": 608, "start": 60953, "IsComparative": "0", "id": "st_608"}]}, {"paragraph_info": {"end": 61830, "start": 61055, "text": "Gaussian filtering requires information on image boundaries.Filtering each tile without overlap results in loss of information at the tile boundaries.To address this we load these tiles into the GPU with overlaps for filtering.For every sub-image that is to be filtered we load two extra rows of tiles (top and bottom) and two extra columns of tiles (left and right) that surround the sub-image.We fill the GPU memory with the largest possible sub-image (with additional surrounding overlapping tiles) to ensure effi- cient processing and minimize re-filtering of overlapping tiles.Depending on the loading order, either one row or one column will be used for filtering the next consecutive set of tiles.The ability to independently filter these tiles allows parallelization.", "rank": 133, "paragraph_comparative_number": 3, "entities": [], "id": "p_133"}, "sentences": [{"end": 61115, "text": "Gaussian filtering requires information on image boundaries.", "rank": 609, "start": 61055, "IsComparative": "1", "id": "st_609"}, {"end": 61205, "text": "Filtering each tile without overlap results in loss of information at the tile boundaries.", "rank": 610, "start": 61115, "IsComparative": "1", "id": "st_610"}, {"end": 61282, "text": "To address this we load these tiles into the GPU with overlaps for filtering.", "rank": 611, "start": 61205, "IsComparative": "0", "id": "st_611"}, {"end": 61450, "text": "For every sub-image that is to be filtered we load two extra rows of tiles (top and bottom) and two extra columns of tiles (left and right) that surround the sub-image.", "rank": 612, "start": 61282, "IsComparative": "0", "id": "st_612"}, {"end": 61637, "text": "We fill the GPU memory with the largest possible sub-image (with additional surrounding overlapping tiles) to ensure effi- cient processing and minimize re-filtering of overlapping tiles.", "rank": 613, "start": 61450, "IsComparative": "1", "id": "st_613"}, {"end": 61759, "text": "Depending on the loading order, either one row or one column will be used for filtering the next consecutive set of tiles.", "rank": 614, "start": 61637, "IsComparative": "0", "id": "st_614"}, {"end": 61830, "text": "The ability to independently filter these tiles allows parallelization.", "rank": 615, "start": 61759, "IsComparative": "0", "id": "st_615"}]}, {"paragraph_info": {"end": 61960, "start": 61830, "text": "In our implementation, we use the NVIDIA performance primitives for GPU Gaus- sian filtering, resizing, addition, and subtraction.", "rank": 134, "paragraph_comparative_number": 1, "entities": [], "id": "p_134"}, "sentences": [{"end": 61960, "text": "In our implementation, we use the NVIDIA performance primitives for GPU Gaus- sian filtering, resizing, addition, and subtraction.", "rank": 616, "start": 61830, "IsComparative": "1", "id": "st_616"}]}, {"paragraph_info": {"end": 61989, "start": 61960, "text": "3.5.2 Salient Regions Storage", "rank": 135, "paragraph_comparative_number": 0, "entities": [], "id": "p_135"}, "sentences": [{"end": 61989, "text": "3.5.2 Salient Regions Storage", "rank": 617, "start": 61960, "IsComparative": "0", "id": "st_617"}]}, {"paragraph_info": {"end": 62330, "start": 61989, "text": "We store ellipses to approximate salient regions to ease storage.The sliding-windows saliency maps incur a storage burden.Similar to storing mipmaps, it takes 11 times the 3 image size to store the saliency maps at all levels.Although it is a constant factor increase, doubling the storage of the already very large images poses a challenge.", "rank": 136, "paragraph_comparative_number": 4, "entities": [], "id": "p_136"}, "sentences": [{"end": 62054, "text": "We store ellipses to approximate salient regions to ease storage.", "rank": 618, "start": 61989, "IsComparative": "1", "id": "st_618"}, {"end": 62111, "text": "The sliding-windows saliency maps incur a storage burden.", "rank": 619, "start": 62054, "IsComparative": "1", "id": "st_619"}, {"end": 62215, "text": "Similar to storing mipmaps, it takes 11 times the 3 image size to store the saliency maps at all levels.", "rank": 620, "start": 62111, "IsComparative": "1", "id": "st_620"}, {"end": 62330, "text": "Although it is a constant factor increase, doubling the storage of the already very large images poses a challenge.", "rank": 621, "start": 62215, "IsComparative": "1", "id": "st_621"}]}, {"paragraph_info": {"end": 62838, "start": 62330, "text": "To address this, we first threshold the sliding-window saliency maps and locate con- tinuous regions, also sometimes referred to as blobs.The open-source library cvblob provides blob detection in our implementation.We carry out local Principal Component Analysis (PCA) to fit ellipses to these regions.This allows us to reduce the storage of each region from hundreds of pixels to a few parameters (center, orientation, and principal axes intercepts of each ellipse).The threshold of our experiments is 0.25.", "rank": 137, "paragraph_comparative_number": 4, "entities": [], "id": "p_137"}, "sentences": [{"end": 62468, "text": "To address this, we first threshold the sliding-window saliency maps and locate con- tinuous regions, also sometimes referred to as blobs.", "rank": 622, "start": 62330, "IsComparative": "1", "id": "st_622"}, {"end": 62545, "text": "The open-source library cvblob provides blob detection in our implementation.", "rank": 623, "start": 62468, "IsComparative": "1", "id": "st_623"}, {"end": 62632, "text": "We carry out local Principal Component Analysis (PCA) to fit ellipses to these regions.", "rank": 624, "start": 62545, "IsComparative": "0", "id": "st_624"}, {"end": 62797, "text": "This allows us to reduce the storage of each region from hundreds of pixels to a few parameters (center, orientation, and principal axes intercepts of each ellipse).", "rank": 625, "start": 62632, "IsComparative": "1", "id": "st_625"}, {"end": 62838, "text": "The threshold of our experiments is 0.25.", "rank": 626, "start": 62797, "IsComparative": "1", "id": "st_626"}]}, {"paragraph_info": {"end": 62862, "start": 62838, "text": "3.5.3 Tiled Image Viewer", "rank": 138, "paragraph_comparative_number": 0, "entities": [], "id": "p_138"}, "sentences": [{"end": 62862, "text": "3.5.3 Tiled Image Viewer", "rank": 627, "start": 62838, "IsComparative": "0", "id": "st_627"}]}, {"paragraph_info": {"end": 64206, "start": 62862, "text": "Very large images presented in this chapter do not fit in the GPU or main memory for display.Each gigapixel in RGB format takes three gigabytes of memory in an uncom- pressed format for rendering.Images with even a few gigapixels exceed the GPU or main memory of a workstation.We have implemented an out-of-core tiled-image viewer.Our viewer fetches only what can be seen at an appropriate scale from the disk.This is similar in spirit to the concept of a clipmap <157>.To carry this out we build a mipmap pyramid of the image.We divide the images on each level into tiles of 256  256.We load the re- quired image tiles according to the viewing parameters.We pre-fetch two extra rows and columns of image tiles surrounding the viewing region to provide smooth panning.Load- ing images from the immediately nearby scales prepares for the zooming operation.We store these images in a texture array.This array is independent of the display arrangement of the textures.We map each texture to an array location by a hash function.The loaded texture can be reused on different views without any memory movement.The memory usage of the viewer is independent of the size of the image.It is related to the size of the viewing window on the screen only.Our viewer needs 350 megabytes for viewing a five gigapixel image with a few hundred overlay regions.", "rank": 139, "paragraph_comparative_number": 7, "entities": [], "id": "p_139"}, "sentences": [{"end": 62955, "text": "Very large images presented in this chapter do not fit in the GPU or main memory for display.", "rank": 628, "start": 62862, "IsComparative": "0", "id": "st_628"}, {"end": 63058, "text": "Each gigapixel in RGB format takes three gigabytes of memory in an uncom- pressed format for rendering.", "rank": 629, "start": 62955, "IsComparative": "1", "id": "st_629"}, {"end": 63139, "text": "Images with even a few gigapixels exceed the GPU or main memory of a workstation.", "rank": 630, "start": 63058, "IsComparative": "0", "id": "st_630"}, {"end": 63193, "text": "We have implemented an out-of-core tiled-image viewer.", "rank": 631, "start": 63139, "IsComparative": "0", "id": "st_631"}, {"end": 63272, "text": "Our viewer fetches only what can be seen at an appropriate scale from the disk.", "rank": 632, "start": 63193, "IsComparative": "1", "id": "st_632"}, {"end": 63332, "text": "This is similar in spirit to the concept of a clipmap <157>.", "rank": 633, "start": 63272, "IsComparative": "1", "id": "st_633"}, {"end": 63389, "text": "To carry this out we build a mipmap pyramid of the image.", "rank": 634, "start": 63332, "IsComparative": "0", "id": "st_634"}, {"end": 63447, "text": "We divide the images on each level into tiles of 256  256.", "rank": 635, "start": 63389, "IsComparative": "0", "id": "st_635"}, {"end": 63518, "text": "We load the re- quired image tiles according to the viewing parameters.", "rank": 636, "start": 63447, "IsComparative": "0", "id": "st_636"}, {"end": 63630, "text": "We pre-fetch two extra rows and columns of image tiles surrounding the viewing region to provide smooth panning.", "rank": 637, "start": 63518, "IsComparative": "1", "id": "st_637"}, {"end": 63717, "text": "Load- ing images from the immediately nearby scales prepares for the zooming operation.", "rank": 638, "start": 63630, "IsComparative": "1", "id": "st_638"}, {"end": 63758, "text": "We store these images in a texture array.", "rank": 639, "start": 63717, "IsComparative": "0", "id": "st_639"}, {"end": 63827, "text": "This array is independent of the display arrangement of the textures.", "rank": 640, "start": 63758, "IsComparative": "0", "id": "st_640"}, {"end": 63887, "text": "We map each texture to an array location by a hash function.", "rank": 641, "start": 63827, "IsComparative": "0", "id": "st_641"}, {"end": 63967, "text": "The loaded texture can be reused on different views without any memory movement.", "rank": 642, "start": 63887, "IsComparative": "0", "id": "st_642"}, {"end": 64038, "text": "The memory usage of the viewer is independent of the size of the image.", "rank": 643, "start": 63967, "IsComparative": "0", "id": "st_643"}, {"end": 64105, "text": "It is related to the size of the viewing window on the screen only.", "rank": 644, "start": 64038, "IsComparative": "1", "id": "st_644"}, {"end": 64206, "text": "Our viewer needs 350 megabytes for viewing a five gigapixel image with a few hundred overlay regions.", "rank": 645, "start": 64105, "IsComparative": "1", "id": "st_645"}]}, {"paragraph_info": {"end": 64217, "start": 64206, "text": "3.6 Results", "rank": 140, "paragraph_comparative_number": 0, "entities": [], "id": "p_140"}, "sentences": [{"end": 64217, "text": "3.6 Results", "rank": 646, "start": 64206, "IsComparative": "0", "id": "st_646"}]}, {"paragraph_info": {"end": 64533, "start": 64217, "text": "We evaluate our approach on four multi-gigapixel images.We report the regions identified by our system and compare them against web community tags.We also report timings of our experiments.We perform our experiments on the Linux platform with one Intel E5420 CPU, 4GB RAM, and one NVIDIA GeForce GTX 295 GPU (895MB).", "rank": 141, "paragraph_comparative_number": 3, "entities": [], "id": "p_141"}, "sentences": [{"end": 64273, "text": "We evaluate our approach on four multi-gigapixel images.", "rank": 647, "start": 64217, "IsComparative": "1", "id": "st_647"}, {"end": 64364, "text": "We report the regions identified by our system and compare them against web community tags.", "rank": 648, "start": 64273, "IsComparative": "0", "id": "st_648"}, {"end": 64406, "text": "We also report timings of our experiments.", "rank": 649, "start": 64364, "IsComparative": "1", "id": "st_649"}, {"end": 64533, "text": "We perform our experiments on the Linux platform with one Intel E5420 CPU, 4GB RAM, and one NVIDIA GeForce GTX 295 GPU (895MB).", "rank": 650, "start": 64406, "IsComparative": "1", "id": "st_650"}]}, {"paragraph_info": {"end": 64547, "start": 64533, "text": "3.6.1 Datasets", "rank": 142, "paragraph_comparative_number": 0, "entities": [], "id": "p_142"}, "sentences": [{"end": 64547, "text": "3.6.1 Datasets", "rank": 651, "start": 64533, "IsComparative": "0", "id": "st_651"}]}, {"paragraph_info": {"end": 65313, "start": 64547, "text": "Digital image stitching and consumer grade robotics have made panoramic photog- raphy very popular.Compact digital cameras can stitch multiple consecutive pictures into a panorama.Robotic devices such as the Gigapan EPIC can take hundreds of pictures automatically for image stitching.These products allow consumers to create images of several gigapixels.Community panorama websites such as Gigapan and HDView have gained much popularity on the Internet.Users around the world upload their panoramic pictures to these websites.The web community of panoramic photography enthusiasts then explore, tag, and comment on interesting regions in these images.We downloaded four gigapixel images from the Gigapan website as shown in Figure 3.11, 3.12, and dis- cussed below.", "rank": 143, "paragraph_comparative_number": 2, "entities": [], "id": "p_143"}, "sentences": [{"end": 64646, "text": "Digital image stitching and consumer grade robotics have made panoramic photog- raphy very popular.", "rank": 652, "start": 64547, "IsComparative": "0", "id": "st_652"}, {"end": 64727, "text": "Compact digital cameras can stitch multiple consecutive pictures into a panorama.", "rank": 653, "start": 64646, "IsComparative": "0", "id": "st_653"}, {"end": 64832, "text": "Robotic devices such as the Gigapan EPIC can take hundreds of pictures automatically for image stitching.", "rank": 654, "start": 64727, "IsComparative": "0", "id": "st_654"}, {"end": 64902, "text": "These products allow consumers to create images of several gigapixels.", "rank": 655, "start": 64832, "IsComparative": "0", "id": "st_655"}, {"end": 65001, "text": "Community panorama websites such as Gigapan and HDView have gained much popularity on the Internet.", "rank": 656, "start": 64902, "IsComparative": "0", "id": "st_656"}, {"end": 65074, "text": "Users around the world upload their panoramic pictures to these websites.", "rank": 657, "start": 65001, "IsComparative": "1", "id": "st_657"}, {"end": 65199, "text": "The web community of panoramic photography enthusiasts then explore, tag, and comment on interesting regions in these images.", "rank": 658, "start": 65074, "IsComparative": "1", "id": "st_658"}, {"end": 65313, "text": "We downloaded four gigapixel images from the Gigapan website as shown in Figure 3.11, 3.12, and dis- cussed below.", "rank": 659, "start": 65199, "IsComparative": "0", "id": "st_659"}]}, {"paragraph_info": {"end": 65663, "start": 65313, "text": "Grimsel Pass : The Grimsel Pass is a high mountain pass in Switzerland.It connects the valley of Rhone River in the canton of Valais and the Haslital in the canton of Bern.The picture shows an overview of the mountain area, the lake, and the road network.There are distinctive areas with building constructions, hotels, and numerous cars on the road.", "rank": 144, "paragraph_comparative_number": 0, "entities": [], "id": "p_144"}, "sentences": [{"end": 65384, "text": "Grimsel Pass : The Grimsel Pass is a high mountain pass in Switzerland.", "rank": 660, "start": 65313, "IsComparative": "0", "id": "st_660"}, {"end": 65485, "text": "It connects the valley of Rhone River in the canton of Valais and the Haslital in the canton of Bern.", "rank": 661, "start": 65384, "IsComparative": "0", "id": "st_661"}, {"end": 65568, "text": "The picture shows an overview of the mountain area, the lake, and the road network.", "rank": 662, "start": 65485, "IsComparative": "0", "id": "st_662"}, {"end": 65663, "text": "There are distinctive areas with building constructions, hotels, and numerous cars on the road.", "rank": 663, "start": 65568, "IsComparative": "0", "id": "st_663"}]}, {"paragraph_info": {"end": 66112, "start": 65663, "text": "Royal Gorge Bridge : The Royal Gorge Bridge is the highest suspension bridge in the world.This tourist attraction is located in a theme park near Canon City, Colorado, shown in the top right of the picture.The Royal Gorge Route Railroad is a heritage railroad offering scenic and historical train-rides, shown at the bottom left of the picture.The picture shows the valley of Arkansas River with the Royal Gorge Bridge and a small town on the right.", "rank": 145, "paragraph_comparative_number": 1, "entities": [], "id": "p_145"}, "sentences": [{"end": 65753, "text": "Royal Gorge Bridge : The Royal Gorge Bridge is the highest suspension bridge in the world.", "rank": 664, "start": 65663, "IsComparative": "0", "id": "st_664"}, {"end": 65869, "text": "This tourist attraction is located in a theme park near Canon City, Colorado, shown in the top right of the picture.", "rank": 665, "start": 65753, "IsComparative": "0", "id": "st_665"}, {"end": 66007, "text": "The Royal Gorge Route Railroad is a heritage railroad offering scenic and historical train-rides, shown at the bottom left of the picture.", "rank": 666, "start": 65869, "IsComparative": "0", "id": "st_666"}, {"end": 66112, "text": "The picture shows the valley of Arkansas River with the Royal Gorge Bridge and a small town on the right.", "rank": 667, "start": 66007, "IsComparative": "1", "id": "st_667"}]}, {"paragraph_info": {"end": 66214, "start": 66112, "text": "Cacti : This picture shows a cactus field in Arizona.A few hikers are hidden among thousands of cacti.", "rank": 146, "paragraph_comparative_number": 0, "entities": [], "id": "p_146"}, "sentences": [{"end": 66165, "text": "Cacti : This picture shows a cactus field in Arizona.", "rank": 668, "start": 66112, "IsComparative": "0", "id": "st_668"}, {"end": 66214, "text": "A few hikers are hidden among thousands of cacti.", "rank": 669, "start": 66165, "IsComparative": "0", "id": "st_669"}]}, {"paragraph_info": {"end": 66435, "start": 66214, "text": "Main Mt.Whitney Trail : This is a trail in the Sequoia National Park, California.This image of mountains and lakes includes many hikers.They all took the challenge to hike the highest peak (14,497) in the lower 48 states.", "rank": 147, "paragraph_comparative_number": 2, "entities": [], "id": "p_147"}, "sentences": [{"end": 66222, "text": "Main Mt.", "rank": 670, "start": 66214, "IsComparative": "0", "id": "st_670"}, {"end": 66295, "text": "Whitney Trail : This is a trail in the Sequoia National Park, California.", "rank": 671, "start": 66222, "IsComparative": "0", "id": "st_671"}, {"end": 66350, "text": "This image of mountains and lakes includes many hikers.", "rank": 672, "start": 66295, "IsComparative": "1", "id": "st_672"}, {"end": 66435, "text": "They all took the challenge to hike the highest peak (14,497) in the lower 48 states.", "rank": 673, "start": 66350, "IsComparative": "1", "id": "st_673"}]}, {"paragraph_info": {"end": 66451, "start": 66435, "text": "3.6.2 Evaluation", "rank": 148, "paragraph_comparative_number": 0, "entities": [], "id": "p_148"}, "sentences": [{"end": 66451, "text": "3.6.2 Evaluation", "rank": 674, "start": 66435, "IsComparative": "0", "id": "st_674"}]}, {"paragraph_info": {"end": 66861, "start": 66451, "text": "We show a sample of the detected regions in Figure 3.11 and 3.11.We tag the locations with numbers and show the detected region in the corresponding thumbnails.We overlay the ellipses onto detected regions.Our system identifies a variety of regions at multiple scales.It locates humans, vehicles, buildings and even special features of the landscape such as a glacier.This shows the generality of our approach.", "rank": 149, "paragraph_comparative_number": 3, "entities": [], "id": "p_149"}, "sentences": [{"end": 66516, "text": "We show a sample of the detected regions in Figure 3.11 and 3.11.", "rank": 675, "start": 66451, "IsComparative": "0", "id": "st_675"}, {"end": 66611, "text": "We tag the locations with numbers and show the detected region in the corresponding thumbnails.", "rank": 676, "start": 66516, "IsComparative": "1", "id": "st_676"}, {"end": 66657, "text": "We overlay the ellipses onto detected regions.", "rank": 677, "start": 66611, "IsComparative": "0", "id": "st_677"}, {"end": 66719, "text": "Our system identifies a variety of regions at multiple scales.", "rank": 678, "start": 66657, "IsComparative": "1", "id": "st_678"}, {"end": 66819, "text": "It locates humans, vehicles, buildings and even special features of the landscape such as a glacier.", "rank": 679, "start": 66719, "IsComparative": "0", "id": "st_679"}, {"end": 66861, "text": "This shows the generality of our approach.", "rank": 680, "start": 66819, "IsComparative": "1", "id": "st_680"}]}, {"paragraph_info": {"end": 67175, "start": 66861, "text": "In the Grimsel Pass picture (Figure 3.11(a)), the system detects buildings in thumb- nails 1 and 8.Thumbnail 2 shows a blue Swiss Tardis.Cars, coaches, and road signs are found in thumbnails 3, 4, and 5.Thumbnail 6 shows a glacier in the mountain.Thumbnail 7 gives a view of the parking lot example in Section 3.2.", "rank": 150, "paragraph_comparative_number": 0, "entities": [], "id": "p_150"}, "sentences": [{"end": 66960, "text": "In the Grimsel Pass picture (Figure 3.11(a)), the system detects buildings in thumb- nails 1 and 8.", "rank": 681, "start": 66861, "IsComparative": "0", "id": "st_681"}, {"end": 66998, "text": "Thumbnail 2 shows a blue Swiss Tardis.", "rank": 682, "start": 66960, "IsComparative": "0", "id": "st_682"}, {"end": 67064, "text": "Cars, coaches, and road signs are found in thumbnails 3, 4, and 5.", "rank": 683, "start": 66998, "IsComparative": "0", "id": "st_683"}, {"end": 67108, "text": "Thumbnail 6 shows a glacier in the mountain.", "rank": 684, "start": 67064, "IsComparative": "0", "id": "st_684"}, {"end": 67175, "text": "Thumbnail 7 gives a view of the parking lot example in Section 3.2.", "rank": 685, "start": 67108, "IsComparative": "0", "id": "st_685"}]}, {"paragraph_info": {"end": 67589, "start": 67175, "text": "In the lower left of the Royal Gorge Bridge picture (Figure 3.11(b)), the system finds a train and a river rafting boat along the Arkansas river in thumbnails 1 and 2.We see two cable cars in thumbnails 3 and 4; the one in 3 has just departed the station whereas the one in 4 is much closer to the camera.Thumbnails 5 and 6 show a caravan and a restaurant sign around the town.Thumbnail 7 shows tourists and flags.", "rank": 151, "paragraph_comparative_number": 3, "entities": [], "id": "p_151"}, "sentences": [{"end": 67342, "text": "In the lower left of the Royal Gorge Bridge picture (Figure 3.11(b)), the system finds a train and a river rafting boat along the Arkansas river in thumbnails 1 and 2.", "rank": 686, "start": 67175, "IsComparative": "1", "id": "st_686"}, {"end": 67480, "text": "We see two cable cars in thumbnails 3 and 4; the one in 3 has just departed the station whereas the one in 4 is much closer to the camera.", "rank": 687, "start": 67342, "IsComparative": "1", "id": "st_687"}, {"end": 67552, "text": "Thumbnails 5 and 6 show a caravan and a restaurant sign around the town.", "rank": 688, "start": 67480, "IsComparative": "0", "id": "st_688"}, {"end": 67589, "text": "Thumbnail 7 shows tourists and flags.", "rank": 689, "start": 67552, "IsComparative": "1", "id": "st_689"}]}, {"paragraph_info": {"end": 67955, "start": 67589, "text": "We found a few hikers among the cacti in Figure 3.12(a).Thumbnail 1 shows the back of a hiker; the system has identified him by his jeans.Thumbnail 2 shows a double image of two hikers, who probably moved and were captured at two instances.The hiker in thumbnail 3 was using a camera.We find a man sitting in thumbnail 4.Two other hikers are detected in thumbnail 5.", "rank": 152, "paragraph_comparative_number": 3, "entities": [], "id": "p_152"}, "sentences": [{"end": 67645, "text": "We found a few hikers among the cacti in Figure 3.12(a).", "rank": 690, "start": 67589, "IsComparative": "1", "id": "st_690"}, {"end": 67727, "text": "Thumbnail 1 shows the back of a hiker; the system has identified him by his jeans.", "rank": 691, "start": 67645, "IsComparative": "1", "id": "st_691"}, {"end": 67829, "text": "Thumbnail 2 shows a double image of two hikers, who probably moved and were captured at two instances.", "rank": 692, "start": 67727, "IsComparative": "1", "id": "st_692"}, {"end": 67873, "text": "The hiker in thumbnail 3 was using a camera.", "rank": 693, "start": 67829, "IsComparative": "0", "id": "st_693"}, {"end": 67910, "text": "We find a man sitting in thumbnail 4.", "rank": 694, "start": 67873, "IsComparative": "0", "id": "st_694"}, {"end": 67955, "text": "Two other hikers are detected in thumbnail 5.", "rank": 695, "start": 67910, "IsComparative": "0", "id": "st_695"}]}, {"paragraph_info": {"end": 68291, "start": 67955, "text": "Although Mt.Whitney (Figure 3.12(b)) is a popular hiking spot, we detect more than the hikers.Thumbnail 1 and 4 show a bridge and the Alpine lake.We found 4 hikers in thumbnails 2 and 5.A hiking backpack is shown in thumbnail 3.We are able to detect 12 out of 13 hikers in this picture.detection, and user-guided interactive refinement.", "rank": 153, "paragraph_comparative_number": 2, "entities": [], "id": "p_153"}, "sentences": [{"end": 67967, "text": "Although Mt.", "rank": 696, "start": 67955, "IsComparative": "0", "id": "st_696"}, {"end": 68049, "text": "Whitney (Figure 3.12(b)) is a popular hiking spot, we detect more than the hikers.", "rank": 697, "start": 67967, "IsComparative": "0", "id": "st_697"}, {"end": 68101, "text": "Thumbnail 1 and 4 show a bridge and the Alpine lake.", "rank": 698, "start": 68049, "IsComparative": "0", "id": "st_698"}, {"end": 68141, "text": "We found 4 hikers in thumbnails 2 and 5.", "rank": 699, "start": 68101, "IsComparative": "1", "id": "st_699"}, {"end": 68183, "text": "A hiking backpack is shown in thumbnail 3.", "rank": 700, "start": 68141, "IsComparative": "0", "id": "st_700"}, {"end": 68241, "text": "We are able to detect 12 out of 13 hikers in this picture.", "rank": 701, "start": 68183, "IsComparative": "1", "id": "st_701"}, {"end": 68291, "text": "detection, and user-guided interactive refinement.", "rank": 702, "start": 68241, "IsComparative": "0", "id": "st_702"}]}, {"paragraph_info": {"end": 68726, "start": 68291, "text": "The running time for the sliding-window saliency computation averages to 2.5 hours per gigapixel.Since the saliency computation routines are parallelizable, we expect a cluster of machines can easily process each gigapixel within a few minutes.k-nearest neighbor anomaly detection takes less than a minute.This is considerably faster than the recent image saliency techniques in Section 2.2.This pre-processing can be computed offline.", "rank": 154, "paragraph_comparative_number": 1, "entities": [], "id": "p_154"}, "sentences": [{"end": 68388, "text": "The running time for the sliding-window saliency computation averages to 2.5 hours per gigapixel.", "rank": 703, "start": 68291, "IsComparative": "1", "id": "st_703"}, {"end": 68535, "text": "Since the saliency computation routines are parallelizable, we expect a cluster of machines can easily process each gigapixel within a few minutes.", "rank": 704, "start": 68388, "IsComparative": "0", "id": "st_704"}, {"end": 68597, "text": "k-nearest neighbor anomaly detection takes less than a minute.", "rank": 705, "start": 68535, "IsComparative": "0", "id": "st_705"}, {"end": 68682, "text": "This is considerably faster than the recent image saliency techniques in Section 2.2.", "rank": 706, "start": 68597, "IsComparative": "0", "id": "st_706"}, {"end": 68726, "text": "This pre-processing can be computed offline.", "rank": 707, "start": 68682, "IsComparative": "0", "id": "st_707"}]}, {"paragraph_info": {"end": 69113, "start": 68726, "text": "The k-nearest neighbor anomaly detection reduces thousands of salient regions to a few hundreds while it also enables the interactive refinement process.The interactive select-slide-delete refinement process (searching, and redrawing) takes only tens of mil- liseconds.In contrast, when we try to interactively refine thousands of salient regions, each interaction takes several seconds.", "rank": 155, "paragraph_comparative_number": 1, "entities": [], "id": "p_155"}, "sentences": [{"end": 68879, "text": "The k-nearest neighbor anomaly detection reduces thousands of salient regions to a few hundreds while it also enables the interactive refinement process.", "rank": 708, "start": 68726, "IsComparative": "0", "id": "st_708"}, {"end": 68995, "text": "The interactive select-slide-delete refinement process (searching, and redrawing) takes only tens of mil- liseconds.", "rank": 709, "start": 68879, "IsComparative": "0", "id": "st_709"}, {"end": 69113, "text": "In contrast, when we try to interactively refine thousands of salient regions, each interaction takes several seconds.", "rank": 710, "start": 68995, "IsComparative": "1", "id": "st_710"}]}, {"paragraph_info": {"end": 69225, "start": 69113, "text": "Chapter 4 Hierarchical Exploration of Volumes using Multilevel Segmentation of the Intensity-Gradient Histograms", "rank": 156, "paragraph_comparative_number": 0, "entities": [], "id": "p_156"}, "sentences": [{"end": 69225, "text": "Chapter 4 Hierarchical Exploration of Volumes using Multilevel Segmentation of the Intensity-Gradient Histograms", "rank": 711, "start": 69113, "IsComparative": "0", "id": "st_711"}]}, {"paragraph_info": {"end": 70046, "start": 69225, "text": "Identifying and visualizing meaningful features in large volume datasets remains a significant challenge <73>.Visualization of the features that you know are in the data is hard.It is even harder to find the features that you do not know are there.While we have made significant strides in building up a substantial body of knowledge over the last two decades in direct volume rendering, much of these advances have addressed issues surrounding how to depict the data; what to depict remains an important problem.We seek a visualization approach that highlights meaningful information, guides users to explore, and allows the users to associate high-level knowledge with low-level raw data.We carry this out by visually segmenting the intensity-gradient histogram of a volumetric dataset into a hierarchy for exploration.", "rank": 157, "paragraph_comparative_number": 3, "entities": [], "id": "p_157"}, "sentences": [{"end": 69335, "text": "Identifying and visualizing meaningful features in large volume datasets remains a significant challenge <73>.", "rank": 712, "start": 69225, "IsComparative": "1", "id": "st_712"}, {"end": 69403, "text": "Visualization of the features that you know are in the data is hard.", "rank": 713, "start": 69335, "IsComparative": "0", "id": "st_713"}, {"end": 69473, "text": "It is even harder to find the features that you do not know are there.", "rank": 714, "start": 69403, "IsComparative": "0", "id": "st_714"}, {"end": 69738, "text": "While we have made significant strides in building up a substantial body of knowledge over the last two decades in direct volume rendering, much of these advances have addressed issues surrounding how to depict the data; what to depict remains an important problem.", "rank": 715, "start": 69473, "IsComparative": "1", "id": "st_715"}, {"end": 69915, "text": "We seek a visualization approach that highlights meaningful information, guides users to explore, and allows the users to associate high-level knowledge with low-level raw data.", "rank": 716, "start": 69738, "IsComparative": "1", "id": "st_716"}, {"end": 70046, "text": "We carry this out by visually segmenting the intensity-gradient histogram of a volumetric dataset into a hierarchy for exploration.", "rank": 717, "start": 69915, "IsComparative": "0", "id": "st_717"}]}, {"paragraph_info": {"end": 70151, "start": 70046, "text": "We first outline the three most important components of the data exploration chal- lenge facing us today.", "rank": 158, "paragraph_comparative_number": 0, "entities": [], "id": "p_158"}, "sentences": [{"end": 70151, "text": "We first outline the three most important components of the data exploration chal- lenge facing us today.", "rank": 718, "start": 70046, "IsComparative": "0", "id": "st_718"}]}, {"paragraph_info": {"end": 70596, "start": 70151, "text": "Information Challenge: Detecting and displaying meaningful features, trends, and anamolies in data is an important challenge in visualization.This is becoming an in- creasingly significant challenge as our ability to acquire data is surpassing our ability to meaningfully analyze it.In this chapter we seek a way to locate and visualize data with the highest information content using simple statistically-based information-theoretic mea- sures.", "rank": 159, "paragraph_comparative_number": 2, "entities": [], "id": "p_159"}, "sentences": [{"end": 70293, "text": "Information Challenge: Detecting and displaying meaningful features, trends, and anamolies in data is an important challenge in visualization.", "rank": 719, "start": 70151, "IsComparative": "1", "id": "st_719"}, {"end": 70434, "text": "This is becoming an in- creasingly significant challenge as our ability to acquire data is surpassing our ability to meaningfully analyze it.", "rank": 720, "start": 70293, "IsComparative": "1", "id": "st_720"}, {"end": 70596, "text": "In this chapter we seek a way to locate and visualize data with the highest information content using simple statistically-based information-theoretic mea- sures.", "rank": 721, "start": 70434, "IsComparative": "0", "id": "st_721"}]}, {"paragraph_info": {"end": 71023, "start": 70596, "text": "Completeness Challenge: Exhaustive data exploration is a tedious and time-intensive exercise and yet is important to ensure that we do not overlook any important features in the data.We need mechanisms that facilitate a complete data exploration.In this chapter we show how to construct a exploration hierarchy to accomplish this goal using a top-down subdivision strategy to cover the entire feature space of a volume dataset.", "rank": 160, "paragraph_comparative_number": 0, "entities": [], "id": "p_160"}, "sentences": [{"end": 70779, "text": "Completeness Challenge: Exhaustive data exploration is a tedious and time-intensive exercise and yet is important to ensure that we do not overlook any important features in the data.", "rank": 722, "start": 70596, "IsComparative": "0", "id": "st_722"}, {"end": 70842, "text": "We need mechanisms that facilitate a complete data exploration.", "rank": 723, "start": 70779, "IsComparative": "0", "id": "st_723"}, {"end": 71023, "text": "In this chapter we show how to construct a exploration hierarchy to accomplish this goal using a top-down subdivision strategy to cover the entire feature space of a volume dataset.", "rank": 724, "start": 70842, "IsComparative": "0", "id": "st_724"}]}, {"paragraph_info": {"end": 71578, "start": 71023, "text": "Semantic Challenge: Current computational approaches may identify potentially in- formative regions by using low-level attributes such as statistics of data, the derivatives of the scalar field, or even embed the data into its own principal dimensions or mani- fold.However semantically driven navigation of the data is still a task that designated for the user.We facilitate addressing this challenge by providing an intuitive and interactive volume exploration interface that is based on natural groupings that are often seen to be semantically related.", "rank": 161, "paragraph_comparative_number": 1, "entities": [], "id": "p_161"}, "sentences": [{"end": 71289, "text": "Semantic Challenge: Current computational approaches may identify potentially in- formative regions by using low-level attributes such as statistics of data, the derivatives of the scalar field, or even embed the data into its own principal dimensions or mani- fold.", "rank": 725, "start": 71023, "IsComparative": "1", "id": "st_725"}, {"end": 71385, "text": "However semantically driven navigation of the data is still a task that designated for the user.", "rank": 726, "start": 71289, "IsComparative": "0", "id": "st_726"}, {"end": 71578, "text": "We facilitate addressing this challenge by providing an intuitive and interactive volume exploration interface that is based on natural groupings that are often seen to be semantically related.", "rank": 727, "start": 71385, "IsComparative": "0", "id": "st_727"}]}, {"paragraph_info": {"end": 72260, "start": 71578, "text": "In practice, users manually search for regions of interest by inspecting different areas of a feature space.Popular exploration subspaces for such a feature space include 1D density and 2D intensity-gradient.Histograms are often used to aid this search and have been implemented in several popular visualization packages, such as, Voreen <108>, VisIt <19>, and ImageVis3D <35>.For example, ImageVis3D provides a trapezoidal tool for this exploration task in Figure 4.1.We mimic this user search process by applying image segmentation to divide the histogram into intuitive regions at multiple scales.We show how to effectively discover regions of interest by traversing a hierarchy.", "rank": 162, "paragraph_comparative_number": 2, "entities": [], "id": "p_162"}, "sentences": [{"end": 71686, "text": "In practice, users manually search for regions of interest by inspecting different areas of a feature space.", "rank": 728, "start": 71578, "IsComparative": "0", "id": "st_728"}, {"end": 71786, "text": "Popular exploration subspaces for such a feature space include 1D density and 2D intensity-gradient.", "rank": 729, "start": 71686, "IsComparative": "1", "id": "st_729"}, {"end": 71955, "text": "Histograms are often used to aid this search and have been implemented in several popular visualization packages, such as, Voreen <108>, VisIt <19>, and ImageVis3D <35>.", "rank": 730, "start": 71786, "IsComparative": "1", "id": "st_730"}, {"end": 72047, "text": "For example, ImageVis3D provides a trapezoidal tool for this exploration task in Figure 4.1.", "rank": 731, "start": 71955, "IsComparative": "0", "id": "st_731"}, {"end": 72178, "text": "We mimic this user search process by applying image segmentation to divide the histogram into intuitive regions at multiple scales.", "rank": 732, "start": 72047, "IsComparative": "0", "id": "st_732"}, {"end": 72260, "text": "We show how to effectively discover regions of interest by traversing a hierarchy.", "rank": 733, "start": 72178, "IsComparative": "0", "id": "st_733"}]}, {"paragraph_info": {"end": 72273, "start": 72260, "text": "Contributions", "rank": 163, "paragraph_comparative_number": 1, "entities": [], "id": "p_163"}, "sentences": [{"end": 72273, "text": "Contributions", "rank": 734, "start": 72260, "IsComparative": "1", "id": "st_734"}]}, {"paragraph_info": {"end": 72421, "start": 72273, "text": "We present a visual-data-driven approach to volume data exploration.Users explore a hierarchy to search for regions of interest from coarse to fine.", "rank": 164, "paragraph_comparative_number": 1, "entities": [], "id": "p_164"}, "sentences": [{"end": 72341, "text": "We present a visual-data-driven approach to volume data exploration.", "rank": 735, "start": 72273, "IsComparative": "1", "id": "st_735"}, {"end": 72421, "text": "Users explore a hierarchy to search for regions of interest from coarse to fine.", "rank": 736, "start": 72341, "IsComparative": "0", "id": "st_736"}]}, {"paragraph_info": {"end": 72829, "start": 72421, "text": "We address the information challenge by extracting informative regions using im- age segmentation on reduced statistics.We mimic user explorations by visually segmenting the 2D histograms.We show these automatic 2D histogram segments well-approximate meaningful 3D volume segments.These segments fit the shape of the histogram and cover the entire domain.We discuss this segmentation approach in Section 4.2.", "rank": 165, "paragraph_comparative_number": 2, "entities": [], "id": "p_165"}, "sentences": [{"end": 72541, "text": "We address the information challenge by extracting informative regions using im- age segmentation on reduced statistics.", "rank": 737, "start": 72421, "IsComparative": "1", "id": "st_737"}, {"end": 72609, "text": "We mimic user explorations by visually segmenting the 2D histograms.", "rank": 738, "start": 72541, "IsComparative": "1", "id": "st_738"}, {"end": 72702, "text": "We show these automatic 2D histogram segments well-approximate meaningful 3D volume segments.", "rank": 739, "start": 72609, "IsComparative": "0", "id": "st_739"}, {"end": 72776, "text": "These segments fit the shape of the histogram and cover the entire domain.", "rank": 740, "start": 72702, "IsComparative": "0", "id": "st_740"}, {"end": 72829, "text": "We discuss this segmentation approach in Section 4.2.", "rank": 741, "start": 72776, "IsComparative": "0", "id": "st_741"}]}, {"paragraph_info": {"end": 73127, "start": 72829, "text": "We address the completeness challenge by constructing a complete exploration hi- erarchy.This hierarchy organizes segments of different scales from coarse to fine.We progressively visualize the volume dataset by traversing this hierarchy.We show the construction of this hierarchy in Section 4.3.1.", "rank": 166, "paragraph_comparative_number": 0, "entities": [], "id": "p_166"}, "sentences": [{"end": 72918, "text": "We address the completeness challenge by constructing a complete exploration hi- erarchy.", "rank": 742, "start": 72829, "IsComparative": "0", "id": "st_742"}, {"end": 72992, "text": "This hierarchy organizes segments of different scales from coarse to fine.", "rank": 743, "start": 72918, "IsComparative": "0", "id": "st_743"}, {"end": 73067, "text": "We progressively visualize the volume dataset by traversing this hierarchy.", "rank": 744, "start": 72992, "IsComparative": "0", "id": "st_744"}, {"end": 73127, "text": "We show the construction of this hierarchy in Section 4.3.1.", "rank": 745, "start": 73067, "IsComparative": "0", "id": "st_745"}]}, {"paragraph_info": {"end": 73363, "start": 73127, "text": "Weguidetheexplorationbyusinginformation-theoreticmeasuresofthevolumetric data segments.We evaluate the entropies of the segments and the information gains of the subdivisions.We show how they can assist the exploration in Section 4.3.2.", "rank": 167, "paragraph_comparative_number": 1, "entities": [], "id": "p_167"}, "sentences": [{"end": 73214, "text": "Weguidetheexplorationbyusinginformation-theoreticmeasuresofthevolumetric data segments.", "rank": 746, "start": 73127, "IsComparative": "1", "id": "st_746"}, {"end": 73302, "text": "We evaluate the entropies of the segments and the information gains of the subdivisions.", "rank": 747, "start": 73214, "IsComparative": "0", "id": "st_747"}, {"end": 73363, "text": "We show how they can assist the exploration in Section 4.3.2.", "rank": 748, "start": 73302, "IsComparative": "0", "id": "st_748"}]}, {"paragraph_info": {"end": 73610, "start": 73363, "text": "We address the semantic challenge by providing intuitive interactions to explore segments at different scales.Users can effectively identify regions of interest by traversing the hierarchy of segments.This interaction is detailed in Section 4.3.3.", "rank": 168, "paragraph_comparative_number": 1, "entities": [], "id": "p_168"}, "sentences": [{"end": 73473, "text": "We address the semantic challenge by providing intuitive interactions to explore segments at different scales.", "rank": 749, "start": 73363, "IsComparative": "1", "id": "st_749"}, {"end": 73564, "text": "Users can effectively identify regions of interest by traversing the hierarchy of segments.", "rank": 750, "start": 73473, "IsComparative": "0", "id": "st_750"}, {"end": 73610, "text": "This interaction is detailed in Section 4.3.3.", "rank": 751, "start": 73564, "IsComparative": "0", "id": "st_751"}]}, {"paragraph_info": {"end": 73620, "start": 73610, "text": "Comparison", "rank": 169, "paragraph_comparative_number": 1, "entities": [], "id": "p_169"}, "sentences": [{"end": 73620, "text": "Comparison", "rank": 752, "start": 73610, "IsComparative": "1", "id": "st_752"}]}, {"paragraph_info": {"end": 74130, "start": 73620, "text": "We show a visual comparison of the Tooth dataset in Figure 4.1.The correspond- ing segments and histograms in the intensity-gradient domain are shown beneath the rendered image.Figure 4.1(a) shows a user-specified visualization in ImageVis3D.In Figure 4.1(b), spatial transfer function <131> connects voxels and histogram pixels in a bottom-up fashion and oversegments the histogram into many regions.Our top-down segmentation is progressive and only divides the histogram into a manageable number of segments.", "rank": 170, "paragraph_comparative_number": 2, "entities": [], "id": "p_170"}, "sentences": [{"end": 73683, "text": "We show a visual comparison of the Tooth dataset in Figure 4.1.", "rank": 753, "start": 73620, "IsComparative": "0", "id": "st_753"}, {"end": 73797, "text": "The correspond- ing segments and histograms in the intensity-gradient domain are shown beneath the rendered image.", "rank": 754, "start": 73683, "IsComparative": "0", "id": "st_754"}, {"end": 73862, "text": "Figure 4.1(a) shows a user-specified visualization in ImageVis3D.", "rank": 755, "start": 73797, "IsComparative": "0", "id": "st_755"}, {"end": 74021, "text": "In Figure 4.1(b), spatial transfer function <131> connects voxels and histogram pixels in a bottom-up fashion and oversegments the histogram into many regions.", "rank": 756, "start": 73862, "IsComparative": "1", "id": "st_756"}, {"end": 74130, "text": "Our top-down segmentation is progressive and only divides the histogram into a manageable number of segments.", "rank": 757, "start": 74021, "IsComparative": "1", "id": "st_757"}]}, {"paragraph_info": {"end": 74683, "start": 74130, "text": "Region-growing techniques with parametric shapes show limited coverage.Fig- ure 4.1(b) shows the Gaussian mixture transfer function <166, 167>.Automatic fitting produces the left visualization and requires manual resize, translate, rotate, and split op- erations on the transfer-function ellipses to produce the visualization on the right.Our visual segmentation approach produces a small number of freeform segments, that tightly fit the histogram and guarantee a complete coverage.We recursively apply the segmenta- tion to also cover the scale space.", "rank": 171, "paragraph_comparative_number": 2, "entities": [], "id": "p_171"}, "sentences": [{"end": 74201, "text": "Region-growing techniques with parametric shapes show limited coverage.", "rank": 758, "start": 74130, "IsComparative": "0", "id": "st_758"}, {"end": 74273, "text": "Fig- ure 4.1(b) shows the Gaussian mixture transfer function <166, 167>.", "rank": 759, "start": 74201, "IsComparative": "0", "id": "st_759"}, {"end": 74469, "text": "Automatic fitting produces the left visualization and requires manual resize, translate, rotate, and split op- erations on the transfer-function ellipses to produce the visualization on the right.", "rank": 760, "start": 74273, "IsComparative": "1", "id": "st_760"}, {"end": 74613, "text": "Our visual segmentation approach produces a small number of freeform segments, that tightly fit the histogram and guarantee a complete coverage.", "rank": 761, "start": 74469, "IsComparative": "1", "id": "st_761"}, {"end": 74683, "text": "We recursively apply the segmenta- tion to also cover the scale space.", "rank": 762, "start": 74613, "IsComparative": "0", "id": "st_762"}]}, {"paragraph_info": {"end": 74879, "start": 74683, "text": "Figure 4.1(c) shows our results.We show the tooth surfaces by identifying and hid- ing solid segments of tooth holding material, dentine, and the enamel.The key advantages of our approach include:", "rank": 172, "paragraph_comparative_number": 2, "entities": [], "id": "p_172"}, "sentences": [{"end": 74715, "text": "Figure 4.1(c) shows our results.", "rank": 763, "start": 74683, "IsComparative": "1", "id": "st_763"}, {"end": 74836, "text": "We show the tooth surfaces by identifying and hid- ing solid segments of tooth holding material, dentine, and the enamel.", "rank": 764, "start": 74715, "IsComparative": "0", "id": "st_764"}, {"end": 74879, "text": "The key advantages of our approach include:", "rank": 765, "start": 74836, "IsComparative": "1", "id": "st_765"}]}, {"paragraph_info": {"end": 75020, "start": 74879, "text": "Assisting region search by visually segmenting the intensity-gradient histogram into collectively exhaustive and mutually exclusive segments.", "rank": 173, "paragraph_comparative_number": 1, "entities": [], "id": "p_173"}, "sentences": [{"end": 75020, "text": "Assisting region search by visually segmenting the intensity-gradient histogram into collectively exhaustive and mutually exclusive segments.", "rank": 766, "start": 74879, "IsComparative": "1", "id": "st_766"}]}, {"paragraph_info": {"end": 75102, "start": 75020, "text": "The multilevel segmentation hierarchy completely covers the dataset at all scales.", "rank": 174, "paragraph_comparative_number": 0, "entities": [], "id": "p_174"}, "sentences": [{"end": 75102, "text": "The multilevel segmentation hierarchy completely covers the dataset at all scales.", "rank": 767, "start": 75020, "IsComparative": "0", "id": "st_767"}]}, {"paragraph_info": {"end": 75235, "start": 75102, "text": "Users interacts with a familiar and augmented feature space that is intuitive.No new features are introduced to disrupt the workflow.", "rank": 175, "paragraph_comparative_number": 0, "entities": [], "id": "p_175"}, "sentences": [{"end": 75180, "text": "Users interacts with a familiar and augmented feature space that is intuitive.", "rank": 768, "start": 75102, "IsComparative": "0", "id": "st_768"}, {"end": 75235, "text": "No new features are introduced to disrupt the workflow.", "rank": 769, "start": 75180, "IsComparative": "0", "id": "st_769"}]}, {"paragraph_info": {"end": 75247, "start": 75235, "text": "4.1 Overview", "rank": 176, "paragraph_comparative_number": 0, "entities": [], "id": "p_176"}, "sentences": [{"end": 75247, "text": "4.1 Overview", "rank": 770, "start": 75235, "IsComparative": "0", "id": "st_770"}]}, {"paragraph_info": {"end": 75563, "start": 75247, "text": "We segment the intensity-gradient histogram of a volumetric dataset into a hier- archy of regions.We have observed that these regions express meaningful features and boundaries in the 3D volumes.The resulting hierarchy guides users to interactively ex- plore the dataset.Figure 4.2 shows an overview of our approach.", "rank": 177, "paragraph_comparative_number": 3, "entities": [], "id": "p_177"}, "sentences": [{"end": 75345, "text": "We segment the intensity-gradient histogram of a volumetric dataset into a hier- archy of regions.", "rank": 771, "start": 75247, "IsComparative": "1", "id": "st_771"}, {"end": 75442, "text": "We have observed that these regions express meaningful features and boundaries in the 3D volumes.", "rank": 772, "start": 75345, "IsComparative": "0", "id": "st_772"}, {"end": 75518, "text": "The resulting hierarchy guides users to interactively ex- plore the dataset.", "rank": 773, "start": 75442, "IsComparative": "1", "id": "st_773"}, {"end": 75563, "text": "Figure 4.2 shows an overview of our approach.", "rank": 774, "start": 75518, "IsComparative": "1", "id": "st_774"}]}, {"paragraph_info": {"end": 76213, "start": 75563, "text": "Information Challenge: We address the information challenge by segmenting intensity- gradient 2D histograms of a volumetric dataset into potential regions of interest.The histogram is the most commonly used tool to help in transfer function design.Kniss et al.<87> have shown that 2D segments in the intensity-gradient domain correspond to meaningful 3D regions in the dataset.Users recognize these shapes and patterns from the histograms image and explore the corresponding 3D regions.We mimic this user behavior by employing the normalized-cut image segmentation to extract such potential regions of interest from a 2D intensity-gradient histogram.", "rank": 178, "paragraph_comparative_number": 2, "entities": [], "id": "p_178"}, "sentences": [{"end": 75730, "text": "Information Challenge: We address the information challenge by segmenting intensity- gradient 2D histograms of a volumetric dataset into potential regions of interest.", "rank": 775, "start": 75563, "IsComparative": "0", "id": "st_775"}, {"end": 75811, "text": "The histogram is the most commonly used tool to help in transfer function design.", "rank": 776, "start": 75730, "IsComparative": "0", "id": "st_776"}, {"end": 75823, "text": "Kniss et al.", "rank": 777, "start": 75811, "IsComparative": "0", "id": "st_777"}, {"end": 75940, "text": "<87> have shown that 2D segments in the intensity-gradient domain correspond to meaningful 3D regions in the dataset.", "rank": 778, "start": 75823, "IsComparative": "1", "id": "st_778"}, {"end": 76049, "text": "Users recognize these shapes and patterns from the histograms image and explore the corresponding 3D regions.", "rank": 779, "start": 75940, "IsComparative": "1", "id": "st_779"}, {"end": 76213, "text": "We mimic this user behavior by employing the normalized-cut image segmentation to extract such potential regions of interest from a 2D intensity-gradient histogram.", "rank": 780, "start": 76049, "IsComparative": "0", "id": "st_780"}]}, {"paragraph_info": {"end": 76616, "start": 76213, "text": "Completeness Challenge: The normalized-cut segments collectively span the entire intensity-gradient histogram.In order to also cover the scale space, we recursively apply normalized-cut algorithm to obtain segments of different sizes.These segments at differ- ent scales form a multilevel hierarchy from coarse-to-fine levels of detail.We have found this to be highly usable for interactive exploration.", "rank": 179, "paragraph_comparative_number": 1, "entities": [], "id": "p_179"}, "sentences": [{"end": 76323, "text": "Completeness Challenge: The normalized-cut segments collectively span the entire intensity-gradient histogram.", "rank": 781, "start": 76213, "IsComparative": "0", "id": "st_781"}, {"end": 76447, "text": "In order to also cover the scale space, we recursively apply normalized-cut algorithm to obtain segments of different sizes.", "rank": 782, "start": 76323, "IsComparative": "0", "id": "st_782"}, {"end": 76549, "text": "These segments at differ- ent scales form a multilevel hierarchy from coarse-to-fine levels of detail.", "rank": 783, "start": 76447, "IsComparative": "1", "id": "st_783"}, {"end": 76616, "text": "We have found this to be highly usable for interactive exploration.", "rank": 784, "start": 76549, "IsComparative": "0", "id": "st_784"}]}, {"paragraph_info": {"end": 77179, "start": 76616, "text": "Semantic Challenge: To address the semantic challenge, we provide interactive explo- ration with the multilevel segmentation hierarchy.Users traverse through the hierarchy to sift for meaningful features.They can cull away the irrelevant segments and subdivide the relevant segments to explore the details.We evaluate the entropies and information gain in this hierarchy to aid the exploration.These information theoretic measures guide the users in deciding where to explore.The exploration results in a visualization with features at different scales and sizes.", "rank": 180, "paragraph_comparative_number": 2, "entities": [], "id": "p_180"}, "sentences": [{"end": 76751, "text": "Semantic Challenge: To address the semantic challenge, we provide interactive explo- ration with the multilevel segmentation hierarchy.", "rank": 785, "start": 76616, "IsComparative": "0", "id": "st_785"}, {"end": 76820, "text": "Users traverse through the hierarchy to sift for meaningful features.", "rank": 786, "start": 76751, "IsComparative": "0", "id": "st_786"}, {"end": 76922, "text": "They can cull away the irrelevant segments and subdivide the relevant segments to explore the details.", "rank": 787, "start": 76820, "IsComparative": "1", "id": "st_787"}, {"end": 77010, "text": "We evaluate the entropies and information gain in this hierarchy to aid the exploration.", "rank": 788, "start": 76922, "IsComparative": "0", "id": "st_788"}, {"end": 77092, "text": "These information theoretic measures guide the users in deciding where to explore.", "rank": 789, "start": 77010, "IsComparative": "0", "id": "st_789"}, {"end": 77179, "text": "The exploration results in a visualization with features at different scales and sizes.", "rank": 790, "start": 77092, "IsComparative": "1", "id": "st_790"}]}, {"paragraph_info": {"end": 77237, "start": 77179, "text": "4.2 Volume Segmentation by Normalized Cut on 2D Histograms", "rank": 181, "paragraph_comparative_number": 1, "entities": [], "id": "p_181"}, "sentences": [{"end": 77237, "text": "4.2 Volume Segmentation by Normalized Cut on 2D Histograms", "rank": 791, "start": 77179, "IsComparative": "1", "id": "st_791"}]}, {"paragraph_info": {"end": 78102, "start": 77237, "text": "We aim to mimic how users would visually process a intensity-gradient histogram.Given a 3D intensity field, we compute its derivative, the gradient, to form a 2D intensity- gradient histogram.Users locate shapes and patterns from this 2D histogram to decide how to explore the 3D volume.As shown in Figure 4.1(a), users use widgets of different shapes to highlight the intensity-gradient histogram and visualize the regions of interest.We aid this tedious process by using image-segmentation algorithms to cut along the shape of this histogram.Previous work <87, 105, 131, 167> has shown that the continuity in the intensity-gradient domain reasonably approximates the spatial continuity in the dataset.We refer our readers to Kniss et al.s <87> work, for specific examples of how intensity-gradient histogram shapes map to corresponding volume regions in datasets.", "rank": 182, "paragraph_comparative_number": 3, "entities": [], "id": "p_182"}, "sentences": [{"end": 77317, "text": "We aim to mimic how users would visually process a intensity-gradient histogram.", "rank": 792, "start": 77237, "IsComparative": "0", "id": "st_792"}, {"end": 77429, "text": "Given a 3D intensity field, we compute its derivative, the gradient, to form a 2D intensity- gradient histogram.", "rank": 793, "start": 77317, "IsComparative": "1", "id": "st_793"}, {"end": 77524, "text": "Users locate shapes and patterns from this 2D histogram to decide how to explore the 3D volume.", "rank": 794, "start": 77429, "IsComparative": "0", "id": "st_794"}, {"end": 77673, "text": "As shown in Figure 4.1(a), users use widgets of different shapes to highlight the intensity-gradient histogram and visualize the regions of interest.", "rank": 795, "start": 77524, "IsComparative": "0", "id": "st_795"}, {"end": 77781, "text": "We aid this tedious process by using image-segmentation algorithms to cut along the shape of this histogram.", "rank": 796, "start": 77673, "IsComparative": "1", "id": "st_796"}, {"end": 77940, "text": "Previous work <87, 105, 131, 167> has shown that the continuity in the intensity-gradient domain reasonably approximates the spatial continuity in the dataset.", "rank": 797, "start": 77781, "IsComparative": "0", "id": "st_797"}, {"end": 78102, "text": "We refer our readers to Kniss et al.s <87> work, for specific examples of how intensity-gradient histogram shapes map to corresponding volume regions in datasets.", "rank": 798, "start": 77940, "IsComparative": "1", "id": "st_798"}]}, {"paragraph_info": {"end": 79137, "start": 78102, "text": "Normalized-cut image segmentation <144> divides the histogram into continuous shapes that we seek.It models an image as a graph and finds the best way to partition this graph into k components.Every pixel in the image is considered as a node on the graph.The edge weights, w(u, v), between the nodes, u and v, are computed as color and location similarities between the pixels.The closer the pixels, the stronger the edge weight is.The details of the similarity measure we used can be found in <25>.The normalized cut seeks to disconnect the graph, V, into components A,B by removing the edges with the least normalized cost.It therefore partitions the image along the least-similar pixels, while maintaining balanced partitions.where W is the adjacency matrix of the image graph with edge weights w(u, v), D is a diagonal matrix with entries, d(u), and  is an eigenvalue.We can use the resulting eigenvectors, y to partition the graph.Yu and Shi <171> show how to find k partitions by finding k eigenvectors of the eigenvalue problem.", "rank": 183, "paragraph_comparative_number": 6, "entities": [], "id": "p_183"}, "sentences": [{"end": 78200, "text": "Normalized-cut image segmentation <144> divides the histogram into continuous shapes that we seek.", "rank": 799, "start": 78102, "IsComparative": "1", "id": "st_799"}, {"end": 78295, "text": "It models an image as a graph and finds the best way to partition this graph into k components.", "rank": 800, "start": 78200, "IsComparative": "1", "id": "st_800"}, {"end": 78357, "text": "Every pixel in the image is considered as a node on the graph.", "rank": 801, "start": 78295, "IsComparative": "0", "id": "st_801"}, {"end": 78479, "text": "The edge weights, w(u, v), between the nodes, u and v, are computed as color and location similarities between the pixels.", "rank": 802, "start": 78357, "IsComparative": "0", "id": "st_802"}, {"end": 78534, "text": "The closer the pixels, the stronger the edge weight is.", "rank": 803, "start": 78479, "IsComparative": "0", "id": "st_803"}, {"end": 78601, "text": "The details of the similarity measure we used can be found in <25>.", "rank": 804, "start": 78534, "IsComparative": "0", "id": "st_804"}, {"end": 78727, "text": "The normalized cut seeks to disconnect the graph, V, into components A,B by removing the edges with the least normalized cost.", "rank": 805, "start": 78601, "IsComparative": "0", "id": "st_805"}, {"end": 78831, "text": "It therefore partitions the image along the least-similar pixels, while maintaining balanced partitions.", "rank": 806, "start": 78727, "IsComparative": "1", "id": "st_806"}, {"end": 78974, "text": "where W is the adjacency matrix of the image graph with edge weights w(u, v), D is a diagonal matrix with entries, d(u), and  is an eigenvalue.", "rank": 807, "start": 78831, "IsComparative": "1", "id": "st_807"}, {"end": 79038, "text": "We can use the resulting eigenvectors, y to partition the graph.", "rank": 808, "start": 78974, "IsComparative": "1", "id": "st_808"}, {"end": 79137, "text": "Yu and Shi <171> show how to find k partitions by finding k eigenvectors of the eigenvalue problem.", "rank": 809, "start": 79038, "IsComparative": "1", "id": "st_809"}]}, {"paragraph_info": {"end": 80157, "start": 79137, "text": "We segment the intensity-gradient histogram using a normalized-cut approach to mimic a semantically meaningful segmentation of the volume dataset.We construct a 2D histogram from the volume dataset.We compress the dynamic range of the frequencies by taking the log, such that the statistics can be represented by a grayscale image.We trade the 3D spatial connectivity information for a compact abstraction in the form of a 2D histogram.The size of the histogram representation is independent of the size of the volume; it is only dependent on the bin sizes and precision, which can be controlled during the histogram construction.The normalized-cut segmentation procedure divides a 2D histogram into multiple segments.These non-parametric segments fit the histogram tightly as they completely cover the histograms intensity-gradient domain.In our exper- iments, we construct a 256  256 histogram from the dataset and store the histogram as a grayscale image.We compute the normalized cut using Cour et al.<25>s software.", "rank": 184, "paragraph_comparative_number": 4, "entities": [], "id": "p_184"}, "sentences": [{"end": 79283, "text": "We segment the intensity-gradient histogram using a normalized-cut approach to mimic a semantically meaningful segmentation of the volume dataset.", "rank": 810, "start": 79137, "IsComparative": "1", "id": "st_810"}, {"end": 79335, "text": "We construct a 2D histogram from the volume dataset.", "rank": 811, "start": 79283, "IsComparative": "0", "id": "st_811"}, {"end": 79468, "text": "We compress the dynamic range of the frequencies by taking the log, such that the statistics can be represented by a grayscale image.", "rank": 812, "start": 79335, "IsComparative": "0", "id": "st_812"}, {"end": 79573, "text": "We trade the 3D spatial connectivity information for a compact abstraction in the form of a 2D histogram.", "rank": 813, "start": 79468, "IsComparative": "0", "id": "st_813"}, {"end": 79767, "text": "The size of the histogram representation is independent of the size of the volume; it is only dependent on the bin sizes and precision, which can be controlled during the histogram construction.", "rank": 814, "start": 79573, "IsComparative": "1", "id": "st_814"}, {"end": 79855, "text": "The normalized-cut segmentation procedure divides a 2D histogram into multiple segments.", "rank": 815, "start": 79767, "IsComparative": "1", "id": "st_815"}, {"end": 79977, "text": "These non-parametric segments fit the histogram tightly as they completely cover the histograms intensity-gradient domain.", "rank": 816, "start": 79855, "IsComparative": "0", "id": "st_816"}, {"end": 80095, "text": "In our exper- iments, we construct a 256  256 histogram from the dataset and store the histogram as a grayscale image.", "rank": 817, "start": 79977, "IsComparative": "1", "id": "st_817"}, {"end": 80142, "text": "We compute the normalized cut using Cour et al.", "rank": 818, "start": 80095, "IsComparative": "0", "id": "st_818"}, {"end": 80157, "text": "<25>s software.", "rank": 819, "start": 80142, "IsComparative": "0", "id": "st_819"}]}, {"paragraph_info": {"end": 80185, "start": 80157, "text": "4.3 Hierarchical Exploration", "rank": 185, "paragraph_comparative_number": 0, "entities": [], "id": "p_185"}, "sentences": [{"end": 80185, "text": "4.3 Hierarchical Exploration", "rank": 820, "start": 80157, "IsComparative": "0", "id": "st_820"}]}, {"paragraph_info": {"end": 80442, "start": 80185, "text": "We recursively segment the histogram to form a hierarchy for interactive explo- ration.A common problem in segmentation is determining the desired number of seg- ments, k. Searching for an appropriate k by repeating the segmentation is a tedious exer- cise.", "rank": 186, "paragraph_comparative_number": 1, "entities": [], "id": "p_186"}, "sentences": [{"end": 80272, "text": "We recursively segment the histogram to form a hierarchy for interactive explo- ration.", "rank": 821, "start": 80185, "IsComparative": "1", "id": "st_821"}, {"end": 80442, "text": "A common problem in segmentation is determining the desired number of seg- ments, k. Searching for an appropriate k by repeating the segmentation is a tedious exer- cise.", "rank": 822, "start": 80272, "IsComparative": "0", "id": "st_822"}]}, {"paragraph_info": {"end": 80895, "start": 80442, "text": "Furthermore, as k increases, the new segments may not subdivide any region of interest.For example, Figure 4.4 shows the segmentation of the Tooth dataset with k = 4 and k = 5.We see an additional segment that divides up the box instead of the tooth as k increases from 4 to 5.The newly-divided segments represent the empty space and the material that holds the tooth.Although these are legitimate segments, most users would prefer to segment the tooth.", "rank": 187, "paragraph_comparative_number": 3, "entities": [], "id": "p_187"}, "sentences": [{"end": 80529, "text": "Furthermore, as k increases, the new segments may not subdivide any region of interest.", "rank": 823, "start": 80442, "IsComparative": "1", "id": "st_823"}, {"end": 80618, "text": "For example, Figure 4.4 shows the segmentation of the Tooth dataset with k = 4 and k = 5.", "rank": 824, "start": 80529, "IsComparative": "0", "id": "st_824"}, {"end": 80719, "text": "We see an additional segment that divides up the box instead of the tooth as k increases from 4 to 5.", "rank": 825, "start": 80618, "IsComparative": "1", "id": "st_825"}, {"end": 80810, "text": "The newly-divided segments represent the empty space and the material that holds the tooth.", "rank": 826, "start": 80719, "IsComparative": "0", "id": "st_826"}, {"end": 80895, "text": "Although these are legitimate segments, most users would prefer to segment the tooth.", "rank": 827, "start": 80810, "IsComparative": "1", "id": "st_827"}]}, {"paragraph_info": {"end": 80934, "start": 80895, "text": "4.3.1 Multilevel Segmentation Hierarchy", "rank": 188, "paragraph_comparative_number": 0, "entities": [], "id": "p_188"}, "sentences": [{"end": 80934, "text": "4.3.1 Multilevel Segmentation Hierarchy", "rank": 828, "start": 80895, "IsComparative": "0", "id": "st_828"}]}, {"paragraph_info": {"end": 81454, "start": 80934, "text": "To eliminate the need for a predetermined k, we recursively apply normalized cuts to segment the histogram and build a binary hierarchy.This hierarchy guides users to explore the histogram segments from coarse to fine details.Users interactively subdivide and explore selective regions of interest.For example, the users may interactively subdivide the tooth while keeping the box intact.This segmentation hierarchy covers the entire intensity-gradient domain at all different scales to ensure an exhaustive exploration.", "rank": 189, "paragraph_comparative_number": 1, "entities": [], "id": "p_189"}, "sentences": [{"end": 81070, "text": "To eliminate the need for a predetermined k, we recursively apply normalized cuts to segment the histogram and build a binary hierarchy.", "rank": 829, "start": 80934, "IsComparative": "1", "id": "st_829"}, {"end": 81160, "text": "This hierarchy guides users to explore the histogram segments from coarse to fine details.", "rank": 830, "start": 81070, "IsComparative": "0", "id": "st_830"}, {"end": 81232, "text": "Users interactively subdivide and explore selective regions of interest.", "rank": 831, "start": 81160, "IsComparative": "0", "id": "st_831"}, {"end": 81322, "text": "For example, the users may interactively subdivide the tooth while keeping the box intact.", "rank": 832, "start": 81232, "IsComparative": "0", "id": "st_832"}, {"end": 81454, "text": "This segmentation hierarchy covers the entire intensity-gradient domain at all different scales to ensure an exhaustive exploration.", "rank": 833, "start": 81322, "IsComparative": "0", "id": "st_833"}]}, {"paragraph_info": {"end": 82206, "start": 81454, "text": "Any cut through this segmentation hierarchy covers the entire dataset.We can traverse this hierarchy to explore the dataset at varying levels of detail in different regions of the volume.Figure 4.5 shows how the parent histogram nodes in the hierarchy are subdivided into the children histogram nodes.In this example, we choose to explore the tooth while keeping the segment of tooth-holding materials and space intact at the first level.The second level of the hierarchy shows the segmentation of the solid tooth crown in the third arc.The third level contains segments of the tooth root and the shell of the crown.We can compose a visualization that covers the whole tooth with these segments at different scales as shown on the right of that figure.", "rank": 190, "paragraph_comparative_number": 2, "entities": [], "id": "p_190"}, "sentences": [{"end": 81524, "text": "Any cut through this segmentation hierarchy covers the entire dataset.", "rank": 834, "start": 81454, "IsComparative": "0", "id": "st_834"}, {"end": 81641, "text": "We can traverse this hierarchy to explore the dataset at varying levels of detail in different regions of the volume.", "rank": 835, "start": 81524, "IsComparative": "1", "id": "st_835"}, {"end": 81755, "text": "Figure 4.5 shows how the parent histogram nodes in the hierarchy are subdivided into the children histogram nodes.", "rank": 836, "start": 81641, "IsComparative": "0", "id": "st_836"}, {"end": 81892, "text": "In this example, we choose to explore the tooth while keeping the segment of tooth-holding materials and space intact at the first level.", "rank": 837, "start": 81755, "IsComparative": "1", "id": "st_837"}, {"end": 81991, "text": "The second level of the hierarchy shows the segmentation of the solid tooth crown in the third arc.", "rank": 838, "start": 81892, "IsComparative": "0", "id": "st_838"}, {"end": 82070, "text": "The third level contains segments of the tooth root and the shell of the crown.", "rank": 839, "start": 81991, "IsComparative": "0", "id": "st_839"}, {"end": 82206, "text": "We can compose a visualization that covers the whole tooth with these segments at different scales as shown on the right of that figure.", "rank": 840, "start": 82070, "IsComparative": "0", "id": "st_840"}]}, {"paragraph_info": {"end": 82604, "start": 82206, "text": "This multilevel segmentation hierarchy provides a mechanism for users to compose visualizations by flexibly combining segments at different scales.Given the shapes of the histogram segments or corresponding volume regions, users can efficiently decide where to explore and refine.In the next section we show how information-theoretic measures can aid in the intuitive segmentation of the hierarchy.", "rank": 191, "paragraph_comparative_number": 2, "entities": [], "id": "p_191"}, "sentences": [{"end": 82353, "text": "This multilevel segmentation hierarchy provides a mechanism for users to compose visualizations by flexibly combining segments at different scales.", "rank": 841, "start": 82206, "IsComparative": "0", "id": "st_841"}, {"end": 82486, "text": "Given the shapes of the histogram segments or corresponding volume regions, users can efficiently decide where to explore and refine.", "rank": 842, "start": 82353, "IsComparative": "1", "id": "st_842"}, {"end": 82604, "text": "In the next section we show how information-theoretic measures can aid in the intuitive segmentation of the hierarchy.", "rank": 843, "start": 82486, "IsComparative": "1", "id": "st_843"}]}, {"paragraph_info": {"end": 82629, "start": 82604, "text": "4.3.2 Information Content", "rank": 192, "paragraph_comparative_number": 0, "entities": [], "id": "p_192"}, "sentences": [{"end": 82629, "text": "4.3.2 Information Content", "rank": 844, "start": 82604, "IsComparative": "0", "id": "st_844"}]}, {"paragraph_info": {"end": 83219, "start": 82629, "text": "We evaluate the information content of a segment or a subdivision to aid the ex- ploration.In addition to the users intuition and domain knowledge, information con- tent can serve as an auxiliary guide when traversing the segmentation hierarchy.The use of information-theoretic measures is increasingly popular in visualization.Kim and JaJa <81> build information-aware octrees to extract isosurfaces.Ja nicke et al.<63, 65, 66> and Chen et al.<18> apply information theoretic measures to visualize flow.Ruiz et al.<135> compose automatic transfer functions based on information divergence.", "rank": 193, "paragraph_comparative_number": 2, "entities": [], "id": "p_193"}, "sentences": [{"end": 82720, "text": "We evaluate the information content of a segment or a subdivision to aid the ex- ploration.", "rank": 845, "start": 82629, "IsComparative": "0", "id": "st_845"}, {"end": 82874, "text": "In addition to the users intuition and domain knowledge, information con- tent can serve as an auxiliary guide when traversing the segmentation hierarchy.", "rank": 846, "start": 82720, "IsComparative": "0", "id": "st_846"}, {"end": 82957, "text": "The use of information-theoretic measures is increasingly popular in visualization.", "rank": 847, "start": 82874, "IsComparative": "1", "id": "st_847"}, {"end": 83030, "text": "Kim and JaJa <81> build information-aware octrees to extract isosurfaces.", "rank": 848, "start": 82957, "IsComparative": "0", "id": "st_848"}, {"end": 83045, "text": "Ja nicke et al.", "rank": 849, "start": 83030, "IsComparative": "0", "id": "st_849"}, {"end": 83073, "text": "<63, 65, 66> and Chen et al.", "rank": 850, "start": 83045, "IsComparative": "0", "id": "st_850"}, {"end": 83133, "text": "<18> apply information theoretic measures to visualize flow.", "rank": 851, "start": 83073, "IsComparative": "0", "id": "st_851"}, {"end": 83144, "text": "Ruiz et al.", "rank": 852, "start": 83133, "IsComparative": "0", "id": "st_852"}, {"end": 83219, "text": "<135> compose automatic transfer functions based on information divergence.", "rank": 853, "start": 83144, "IsComparative": "1", "id": "st_853"}]}, {"paragraph_info": {"end": 83581, "start": 83219, "text": "We compute the entropy at each segment and evaluate the information gain at each subdivision of the segmentation hierarchy.Our goal is to guide users to explore segments that are more informative.To assist user exploration, we characterize the segments and the subdivision with two different information theoretic measures: (a) Entropy, and (b) Information Gain.", "rank": 194, "paragraph_comparative_number": 2, "entities": [], "id": "p_194"}, "sentences": [{"end": 83342, "text": "We compute the entropy at each segment and evaluate the information gain at each subdivision of the segmentation hierarchy.", "rank": 854, "start": 83219, "IsComparative": "0", "id": "st_854"}, {"end": 83415, "text": "Our goal is to guide users to explore segments that are more informative.", "rank": 855, "start": 83342, "IsComparative": "1", "id": "st_855"}, {"end": 83581, "text": "To assist user exploration, we characterize the segments and the subdivision with two different information theoretic measures: (a) Entropy, and (b) Information Gain.", "rank": 856, "start": 83415, "IsComparative": "1", "id": "st_856"}]}, {"paragraph_info": {"end": 84017, "start": 83581, "text": "Segment Entropy: We use entropy to characterize the complexity of a segment.We extract sub-volumes, V , from the dataset according to the segments (the nodes in the hierarchy).We compute the entropy in the sub-volumes, H(V), as follows: where vi is a voxel in V, p(vi) is the probability of vi.This classic Shannon en- tropy measures how many bits are required to encode V .A high number of bits required represents a higher complexity.", "rank": 195, "paragraph_comparative_number": 1, "entities": [], "id": "p_195"}, "sentences": [{"end": 83657, "text": "Segment Entropy: We use entropy to characterize the complexity of a segment.", "rank": 857, "start": 83581, "IsComparative": "0", "id": "st_857"}, {"end": 83757, "text": "We extract sub-volumes, V , from the dataset according to the segments (the nodes in the hierarchy).", "rank": 858, "start": 83657, "IsComparative": "0", "id": "st_858"}, {"end": 83875, "text": "We compute the entropy in the sub-volumes, H(V), as follows: where vi is a voxel in V, p(vi) is the probability of vi.", "rank": 859, "start": 83757, "IsComparative": "1", "id": "st_859"}, {"end": 83955, "text": "This classic Shannon en- tropy measures how many bits are required to encode V .", "rank": 860, "start": 83875, "IsComparative": "0", "id": "st_860"}, {"end": 84017, "text": "A high number of bits required represents a higher complexity.", "rank": 861, "start": 83955, "IsComparative": "0", "id": "st_861"}]}, {"paragraph_info": {"end": 84436, "start": 84017, "text": "In Figure 4.6(a), we color the segments of the Tooth dataset according to their entropy.It shows that the tooth contains a higher entropy than the empty space and tooth-holding material.However, when we further subdivide the tooth in Figure 4.6(b) the entropies of different components start converging and it becomes less clear which segment should be further explored.To address this we evaluate the information gain.", "rank": 196, "paragraph_comparative_number": 0, "entities": [], "id": "p_196"}, "sentences": [{"end": 84105, "text": "In Figure 4.6(a), we color the segments of the Tooth dataset according to their entropy.", "rank": 862, "start": 84017, "IsComparative": "0", "id": "st_862"}, {"end": 84203, "text": "It shows that the tooth contains a higher entropy than the empty space and tooth-holding material.", "rank": 863, "start": 84105, "IsComparative": "0", "id": "st_863"}, {"end": 84387, "text": "However, when we further subdivide the tooth in Figure 4.6(b) the entropies of different components start converging and it becomes less clear which segment should be further explored.", "rank": 864, "start": 84203, "IsComparative": "0", "id": "st_864"}, {"end": 84436, "text": "To address this we evaluate the information gain.", "rank": 865, "start": 84387, "IsComparative": "0", "id": "st_865"}]}, {"paragraph_info": {"end": 85409, "start": 84436, "text": "Information Gain: We use information gain to evaluate the effect of subdividing a segment.The information gain is the reduction in entropy after a subdivision.When the entropy reduction is low, it means that the subdivision does not sufficiently reduce the complexity of the segment.However, if the entropy reduction is high, it suggests that the complexity is lowered in the sub-segments, which is likely to happen as result of separation of two different structures into the two sub-segments.This measure has been widely used in building decision trees <129>, where the attribute with the highest information gain subdivides the training data.We compute this by subtracting the entropy of the children nodes from the parent node: where Vj are the sub-volumes of V.We normalize this gain by the entropy before the subdivision.Figure 4.6(b) shows how information gain can distinguish segments with similar entropies  the dentine boundary is separated from the enamel crown.", "rank": 197, "paragraph_comparative_number": 3, "entities": [], "id": "p_197"}, "sentences": [{"end": 84526, "text": "Information Gain: We use information gain to evaluate the effect of subdividing a segment.", "rank": 866, "start": 84436, "IsComparative": "0", "id": "st_866"}, {"end": 84595, "text": "The information gain is the reduction in entropy after a subdivision.", "rank": 867, "start": 84526, "IsComparative": "1", "id": "st_867"}, {"end": 84719, "text": "When the entropy reduction is low, it means that the subdivision does not sufficiently reduce the complexity of the segment.", "rank": 868, "start": 84595, "IsComparative": "0", "id": "st_868"}, {"end": 84930, "text": "However, if the entropy reduction is high, it suggests that the complexity is lowered in the sub-segments, which is likely to happen as result of separation of two different structures into the two sub-segments.", "rank": 869, "start": 84719, "IsComparative": "1", "id": "st_869"}, {"end": 85081, "text": "This measure has been widely used in building decision trees <129>, where the attribute with the highest information gain subdivides the training data.", "rank": 870, "start": 84930, "IsComparative": "1", "id": "st_870"}, {"end": 85202, "text": "We compute this by subtracting the entropy of the children nodes from the parent node: where Vj are the sub-volumes of V.", "rank": 871, "start": 85081, "IsComparative": "0", "id": "st_871"}, {"end": 85263, "text": "We normalize this gain by the entropy before the subdivision.", "rank": 872, "start": 85202, "IsComparative": "0", "id": "st_872"}, {"end": 85409, "text": "Figure 4.6(b) shows how information gain can distinguish segments with similar entropies  the dentine boundary is separated from the enamel crown.", "rank": 873, "start": 85263, "IsComparative": "0", "id": "st_873"}]}, {"paragraph_info": {"end": 85438, "start": 85409, "text": "4.3.3 Interactive Exploration", "rank": 198, "paragraph_comparative_number": 0, "entities": [], "id": "p_198"}, "sentences": [{"end": 85438, "text": "4.3.3 Interactive Exploration", "rank": 874, "start": 85409, "IsComparative": "0", "id": "st_874"}]}, {"paragraph_info": {"end": 85872, "start": 85438, "text": "We use the segmentation hierarchy to guide volume exploration.The users in- teract with segments at different levels and compose visualizations on the intensity- gradient histogram.The main interactions in this procedure are subdividing or hid- ing a segment.Hand editing of segments is not necessary and optional.No manual translation, rotation, resizing, or reshaping of segments is required in the results pre- sented in this work.", "rank": 199, "paragraph_comparative_number": 0, "entities": [], "id": "p_199"}, "sentences": [{"end": 85500, "text": "We use the segmentation hierarchy to guide volume exploration.", "rank": 875, "start": 85438, "IsComparative": "0", "id": "st_875"}, {"end": 85619, "text": "The users in- teract with segments at different levels and compose visualizations on the intensity- gradient histogram.", "rank": 876, "start": 85500, "IsComparative": "0", "id": "st_876"}, {"end": 85697, "text": "The main interactions in this procedure are subdividing or hid- ing a segment.", "rank": 877, "start": 85619, "IsComparative": "0", "id": "st_877"}, {"end": 85752, "text": "Hand editing of segments is not necessary and optional.", "rank": 878, "start": 85697, "IsComparative": "0", "id": "st_878"}, {"end": 85872, "text": "No manual translation, rotation, resizing, or reshaping of segments is required in the results pre- sented in this work.", "rank": 879, "start": 85752, "IsComparative": "0", "id": "st_879"}]}, {"paragraph_info": {"end": 86678, "start": 85872, "text": "We present the dataset in a bi- segment configuration to start the exploration.Similar to other related work, we overlay the segments on the intensity-gradient histogram for the users to relate to the volume regions.By default, we color the segments using a randomly-generated color map.Clicking on any segment subdivides it into two components.Users can visualize the entropy or information gain using a color- coded visualization with an appropriate key press.Users may also choose to change the colors and opacities of each segment.These interactions allow a user to inspect and focus on regions of interest.We also provide shortcuts to clear the opacity of any segment to allow the user to easily cull away any segment.we decided to cull-away those segments and their subtrees are not further explored.", "rank": 200, "paragraph_comparative_number": 3, "entities": [], "id": "p_200"}, "sentences": [{"end": 85951, "text": "We present the dataset in a bi- segment configuration to start the exploration.", "rank": 880, "start": 85872, "IsComparative": "0", "id": "st_880"}, {"end": 86088, "text": "Similar to other related work, we overlay the segments on the intensity-gradient histogram for the users to relate to the volume regions.", "rank": 881, "start": 85951, "IsComparative": "0", "id": "st_881"}, {"end": 86159, "text": "By default, we color the segments using a randomly-generated color map.", "rank": 882, "start": 86088, "IsComparative": "0", "id": "st_882"}, {"end": 86217, "text": "Clicking on any segment subdivides it into two components.", "rank": 883, "start": 86159, "IsComparative": "1", "id": "st_883"}, {"end": 86334, "text": "Users can visualize the entropy or information gain using a color- coded visualization with an appropriate key press.", "rank": 884, "start": 86217, "IsComparative": "0", "id": "st_884"}, {"end": 86407, "text": "Users may also choose to change the colors and opacities of each segment.", "rank": 885, "start": 86334, "IsComparative": "0", "id": "st_885"}, {"end": 86483, "text": "These interactions allow a user to inspect and focus on regions of interest.", "rank": 886, "start": 86407, "IsComparative": "0", "id": "st_886"}, {"end": 86595, "text": "We also provide shortcuts to clear the opacity of any segment to allow the user to easily cull away any segment.", "rank": 887, "start": 86483, "IsComparative": "1", "id": "st_887"}, {"end": 86678, "text": "we decided to cull-away those segments and their subtrees are not further explored.", "rank": 888, "start": 86595, "IsComparative": "1", "id": "st_888"}]}, {"paragraph_info": {"end": 88205, "start": 86678, "text": "We show how to exhaustively explore the Tooth dataset and compose a boundary vi- sualization similar to the user-specified visualization in Figure 4.1(a).The supplementary video shows this visualization can be constructed in less than a minute.The exploration starts with the full dataset.The initial segments in step 1 divide the tooth from the rest of data, the first leftmost arc in the histogram.We focus on the tooth from step 2 onwards.Step 2 shows the crown and the root.Step 3 segments the shell of the crown in yellow.Step 4 shows the second arc is the root of the tooth and separates it from noise (this is best seen in the video).We first select the root and then remove the noise.Step 5 divides the root into the solid blob-like dentine component and its boundary.We keep the dentine boundary and move on to the tooth crown represented by the third and rightmost arc in step 6.Step 7 divides the arc, the left half shows the boundary between the enamel and the dentine and the right half shows the solid enamel component.We show the boundary by hiding the solid component and move on to explore the last noise-like segment between the first and second arcs in step 7.In step 8, the lower half of the noise-like component shows the noise, however the top half shows the boundary of the pulp along with a small piece of the tooth-holding material at the back.We hide the noise, then further segment the pulp boundary in step 9.This allows us to remove the tooth-holding material and arrive at our final visualization.", "rank": 201, "paragraph_comparative_number": 5, "entities": [], "id": "p_201"}, "sentences": [{"end": 86832, "text": "We show how to exhaustively explore the Tooth dataset and compose a boundary vi- sualization similar to the user-specified visualization in Figure 4.1(a).", "rank": 889, "start": 86678, "IsComparative": "0", "id": "st_889"}, {"end": 86922, "text": "The supplementary video shows this visualization can be constructed in less than a minute.", "rank": 890, "start": 86832, "IsComparative": "0", "id": "st_890"}, {"end": 86967, "text": "The exploration starts with the full dataset.", "rank": 891, "start": 86922, "IsComparative": "0", "id": "st_891"}, {"end": 87078, "text": "The initial segments in step 1 divide the tooth from the rest of data, the first leftmost arc in the histogram.", "rank": 892, "start": 86967, "IsComparative": "0", "id": "st_892"}, {"end": 87120, "text": "We focus on the tooth from step 2 onwards.", "rank": 893, "start": 87078, "IsComparative": "1", "id": "st_893"}, {"end": 87156, "text": "Step 2 shows the crown and the root.", "rank": 894, "start": 87120, "IsComparative": "0", "id": "st_894"}, {"end": 87205, "text": "Step 3 segments the shell of the crown in yellow.", "rank": 895, "start": 87156, "IsComparative": "0", "id": "st_895"}, {"end": 87319, "text": "Step 4 shows the second arc is the root of the tooth and separates it from noise (this is best seen in the video).", "rank": 896, "start": 87205, "IsComparative": "0", "id": "st_896"}, {"end": 87370, "text": "We first select the root and then remove the noise.", "rank": 897, "start": 87319, "IsComparative": "0", "id": "st_897"}, {"end": 87454, "text": "Step 5 divides the root into the solid blob-like dentine component and its boundary.", "rank": 898, "start": 87370, "IsComparative": "1", "id": "st_898"}, {"end": 87567, "text": "We keep the dentine boundary and move on to the tooth crown represented by the third and rightmost arc in step 6.", "rank": 899, "start": 87454, "IsComparative": "0", "id": "st_899"}, {"end": 87711, "text": "Step 7 divides the arc, the left half shows the boundary between the enamel and the dentine and the right half shows the solid enamel component.", "rank": 900, "start": 87567, "IsComparative": "0", "id": "st_900"}, {"end": 87857, "text": "We show the boundary by hiding the solid component and move on to explore the last noise-like segment between the first and second arcs in step 7.", "rank": 901, "start": 87711, "IsComparative": "1", "id": "st_901"}, {"end": 88047, "text": "In step 8, the lower half of the noise-like component shows the noise, however the top half shows the boundary of the pulp along with a small piece of the tooth-holding material at the back.", "rank": 902, "start": 87857, "IsComparative": "1", "id": "st_902"}, {"end": 88115, "text": "We hide the noise, then further segment the pulp boundary in step 9.", "rank": 903, "start": 88047, "IsComparative": "0", "id": "st_903"}, {"end": 88205, "text": "This allows us to remove the tooth-holding material and arrive at our final visualization.", "rank": 904, "start": 88115, "IsComparative": "1", "id": "st_904"}]}, {"paragraph_info": {"end": 88216, "start": 88205, "text": "4.4 Results", "rank": 202, "paragraph_comparative_number": 0, "entities": [], "id": "p_202"}, "sentences": [{"end": 88216, "text": "4.4 Results", "rank": 905, "start": 88205, "IsComparative": "0", "id": "st_905"}]}, {"paragraph_info": {"end": 88293, "start": 88216, "text": "We apply this exploration approach to visualize a variety of volume datasets:", "rank": 203, "paragraph_comparative_number": 1, "entities": [], "id": "p_203"}, "sentences": [{"end": 88293, "text": "We apply this exploration approach to visualize a variety of volume datasets:", "rank": 906, "start": 88216, "IsComparative": "1", "id": "st_906"}]}, {"paragraph_info": {"end": 89081, "start": 88293, "text": "Implementation and Experimental Setup: We compute a six-level normalized-cut hi- erarchy for each histogram by using Cour et al.s <25> normalized cut software in Matlab.We only store the finest level of the segmentation and access the rest according to a binary- tree order.We visualize the segments as freeform components on a 2D intensity-gradient transfer function.We implement our application with Qt and the NVIDIA CUDA SDK volume rendering example.The preprocessing in Matlab takes about 15 seconds per his- togram.This preprocessing can be avoided completely if we can perform normalized cut with an accelerated eigensolver at exploration time as discussed in Section 4.5.We per- formed all experiments on a Linux workstation with a Intel Xeon 5140 and a NVIDIA GeForce 260GTX GPU.", "rank": 204, "paragraph_comparative_number": 4, "entities": [], "id": "p_204"}, "sentences": [{"end": 88462, "text": "Implementation and Experimental Setup: We compute a six-level normalized-cut hi- erarchy for each histogram by using Cour et al.s <25> normalized cut software in Matlab.", "rank": 907, "start": 88293, "IsComparative": "1", "id": "st_907"}, {"end": 88567, "text": "We only store the finest level of the segmentation and access the rest according to a binary- tree order.", "rank": 908, "start": 88462, "IsComparative": "1", "id": "st_908"}, {"end": 88661, "text": "We visualize the segments as freeform components on a 2D intensity-gradient transfer function.", "rank": 909, "start": 88567, "IsComparative": "0", "id": "st_909"}, {"end": 88747, "text": "We implement our application with Qt and the NVIDIA CUDA SDK volume rendering example.", "rank": 910, "start": 88661, "IsComparative": "1", "id": "st_910"}, {"end": 88814, "text": "The preprocessing in Matlab takes about 15 seconds per his- togram.", "rank": 911, "start": 88747, "IsComparative": "1", "id": "st_911"}, {"end": 88972, "text": "This preprocessing can be avoided completely if we can perform normalized cut with an accelerated eigensolver at exploration time as discussed in Section 4.5.", "rank": 912, "start": 88814, "IsComparative": "0", "id": "st_912"}, {"end": 89081, "text": "We per- formed all experiments on a Linux workstation with a Intel Xeon 5140 and a NVIDIA GeForce 260GTX GPU.", "rank": 913, "start": 88972, "IsComparative": "0", "id": "st_913"}]}, {"paragraph_info": {"end": 89602, "start": 89081, "text": "For each dataset, we show a visualization and the corresponding exploration hier- archy.The numbering shows the order of the subdivision steps along the hierarchy.We illustrate the key steps and their corresponding visualizations on the left side of each fig- ure.We also highlight segments corresponding to interesting structures of the datasets.The supplementary video shows the interactive composition process.Our results show our approach follows human intuition in segmenting histograms into meaningful compo- nents.", "rank": 205, "paragraph_comparative_number": 3, "entities": [], "id": "p_205"}, "sentences": [{"end": 89169, "text": "For each dataset, we show a visualization and the corresponding exploration hier- archy.", "rank": 914, "start": 89081, "IsComparative": "0", "id": "st_914"}, {"end": 89244, "text": "The numbering shows the order of the subdivision steps along the hierarchy.", "rank": 915, "start": 89169, "IsComparative": "1", "id": "st_915"}, {"end": 89345, "text": "We illustrate the key steps and their corresponding visualizations on the left side of each fig- ure.", "rank": 916, "start": 89244, "IsComparative": "1", "id": "st_916"}, {"end": 89428, "text": "We also highlight segments corresponding to interesting structures of the datasets.", "rank": 917, "start": 89345, "IsComparative": "0", "id": "st_917"}, {"end": 89494, "text": "The supplementary video shows the interactive composition process.", "rank": 918, "start": 89428, "IsComparative": "0", "id": "st_918"}, {"end": 89602, "text": "Our results show our approach follows human intuition in segmenting histograms into meaningful compo- nents.", "rank": 919, "start": 89494, "IsComparative": "1", "id": "st_919"}]}, {"paragraph_info": {"end": 90126, "start": 89602, "text": "Engine: The engine blocks histogram shows a distinctive arc-like region that represents the main engine block and the space around it.The segmentation separates this solid arc region from the other scattered arc with high intensity and gradient in the histogram.The high intensity and high gradient arc represents the internal structures and is shown in Figure 4.8(b).Figure 4.8(a) shows the arc region that represents the space and the engine block regions shows a high information gain.We subdivide the arc to separate the", "rank": 206, "paragraph_comparative_number": 1, "entities": [], "id": "p_206"}, "sentences": [{"end": 89736, "text": "Engine: The engine blocks histogram shows a distinctive arc-like region that represents the main engine block and the space around it.", "rank": 920, "start": 89602, "IsComparative": "1", "id": "st_920"}, {"end": 89864, "text": "The segmentation separates this solid arc region from the other scattered arc with high intensity and gradient in the histogram.", "rank": 921, "start": 89736, "IsComparative": "0", "id": "st_921"}, {"end": 89970, "text": "The high intensity and high gradient arc represents the internal structures and is shown in Figure 4.8(b).", "rank": 922, "start": 89864, "IsComparative": "0", "id": "st_922"}, {"end": 90090, "text": "Figure 4.8(a) shows the arc region that represents the space and the engine block regions shows a high information gain.", "rank": 923, "start": 89970, "IsComparative": "0", "id": "st_923"}, {"end": 90126, "text": "We subdivide the arc to separate the", "rank": 924, "start": 90090, "IsComparative": "0", "id": "st_924"}]}, {"paragraph_info": {"end": 90157, "start": 90126, "text": "4.5 Conclusions and Future Work", "rank": 207, "paragraph_comparative_number": 1, "entities": [], "id": "p_207"}, "sentences": [{"end": 90157, "text": "4.5 Conclusions and Future Work", "rank": 925, "start": 90126, "IsComparative": "1", "id": "st_925"}]}, {"paragraph_info": {"end": 91344, "start": 90157, "text": "In this chapter we present a hierarchy of normalized-cut-assisted visual segmentation of an intensity-gradient histogram to assist in the volume exploration process.In contrast with existing approaches in Figure 4.1(b) and (c), our top-down segmentation approach produces fewer segments and a superior coverage.Our visual approach also well approximates user-specified visualizations in Figure 4.1(a).We address the information challenge by using a visual segmentation of intensity-gradient histograms to locate various meaningful volumetric segments.These segments completely cover the intensity-gradient domain in both the that any cut in the segmentation hierarchy covers the entire dataset.Exploring along this hierarchy addresses the completeness challenge.We assist the volumetric data explo- ration process by using information-theoretic measures.The users can identify meaning-image space and the scale space.We show ful components and material boundaries through a concise interactive exploration proce- dure.These interactions address the semantic challenge by allowing users to adaptively explore the dataset and associate their knowledge with the corresponding data segments.", "rank": 208, "paragraph_comparative_number": 6, "entities": [], "id": "p_208"}, "sentences": [{"end": 90322, "text": "In this chapter we present a hierarchy of normalized-cut-assisted visual segmentation of an intensity-gradient histogram to assist in the volume exploration process.", "rank": 926, "start": 90157, "IsComparative": "0", "id": "st_926"}, {"end": 90468, "text": "In contrast with existing approaches in Figure 4.1(b) and (c), our top-down segmentation approach produces fewer segments and a superior coverage.", "rank": 927, "start": 90322, "IsComparative": "1", "id": "st_927"}, {"end": 90558, "text": "Our visual approach also well approximates user-specified visualizations in Figure 4.1(a).", "rank": 928, "start": 90468, "IsComparative": "1", "id": "st_928"}, {"end": 90708, "text": "We address the information challenge by using a visual segmentation of intensity-gradient histograms to locate various meaningful volumetric segments.", "rank": 929, "start": 90558, "IsComparative": "1", "id": "st_929"}, {"end": 90851, "text": "These segments completely cover the intensity-gradient domain in both the that any cut in the segmentation hierarchy covers the entire dataset.", "rank": 930, "start": 90708, "IsComparative": "1", "id": "st_930"}, {"end": 90919, "text": "Exploring along this hierarchy addresses the completeness challenge.", "rank": 931, "start": 90851, "IsComparative": "0", "id": "st_931"}, {"end": 91011, "text": "We assist the volumetric data explo- ration process by using information-theoretic measures.", "rank": 932, "start": 90919, "IsComparative": "1", "id": "st_932"}, {"end": 91074, "text": "The users can identify meaning-image space and the scale space.", "rank": 933, "start": 91011, "IsComparative": "0", "id": "st_933"}, {"end": 91175, "text": "We show ful components and material boundaries through a concise interactive exploration proce- dure.", "rank": 934, "start": 91074, "IsComparative": "0", "id": "st_934"}, {"end": 91344, "text": "These interactions address the semantic challenge by allowing users to adaptively explore the dataset and associate their knowledge with the corresponding data segments.", "rank": 935, "start": 91175, "IsComparative": "1", "id": "st_935"}]}, {"paragraph_info": {"end": 91435, "start": 91344, "text": "Chapter 5 Personalizing the Brain Atlas through Gene Expression Correlates 5.1 Introduction", "rank": 209, "paragraph_comparative_number": 0, "entities": [], "id": "p_209"}, "sentences": [{"end": 91435, "text": "Chapter 5 Personalizing the Brain Atlas through Gene Expression Correlates 5.1 Introduction", "rank": 936, "start": 91344, "IsComparative": "0", "id": "st_936"}]}, {"paragraph_info": {"end": 91928, "start": 91435, "text": "Segmentation of biological volumes is a long-standing challenge.In this chapter we show how we can use massive data arising from gene expression profiles of hundreds to thousands of genes to complement and enhance existing methods.In contrast to previous work on using data from a single image (such as a volumetric MR image) with atlas-based segmentation of brain images, our work shows how to use correlation data from multiple gene-expression profile volumes to personalize the brain atlas.", "rank": 210, "paragraph_comparative_number": 2, "entities": [], "id": "p_210"}, "sentences": [{"end": 91499, "text": "Segmentation of biological volumes is a long-standing challenge.", "rank": 937, "start": 91435, "IsComparative": "1", "id": "st_937"}, {"end": 91666, "text": "In this chapter we show how we can use massive data arising from gene expression profiles of hundreds to thousands of genes to complement and enhance existing methods.", "rank": 938, "start": 91499, "IsComparative": "0", "id": "st_938"}, {"end": 91928, "text": "In contrast to previous work on using data from a single image (such as a volumetric MR image) with atlas-based segmentation of brain images, our work shows how to use correlation data from multiple gene-expression profile volumes to personalize the brain atlas.", "rank": 939, "start": 91666, "IsComparative": "1", "id": "st_939"}]}, {"paragraph_info": {"end": 93092, "start": 91928, "text": "Analysis of gene expression patterns in a three-dimensional context has revealed interesting results about the roles of specific genes in development and disease.Most studies to date have analyzed the expression of single genes within specific organs (such as heart, brain, or entire embryos) across stages of development or disease states.The spatial localization of individual genes can be determined through fluorescent in situ hy- bridization (FISH), followed by confocal microscopy, optical transmission tomography, or by imaging serial sections of (frozen or paraffin-embedded) tissue.A global view of gene expression across multiple genes can be obtained through microarray analysis of dissected tissue, either by selecting specific tissue types or through voxelization.In the latter approach, sections of immobilized tissue are segmented into spatially registered cubes (voxels) which are then subjected to microarray analyses.Voxelization is particu- larly appealing since the segmentation process is not biased by prior knowledge about the tissue being analyzed, making it possible to use the gene expression data to uncover novel morphological features.", "rank": 211, "paragraph_comparative_number": 1, "entities": [], "id": "p_211"}, "sentences": [{"end": 92090, "text": "Analysis of gene expression patterns in a three-dimensional context has revealed interesting results about the roles of specific genes in development and disease.", "rank": 940, "start": 91928, "IsComparative": "0", "id": "st_940"}, {"end": 92268, "text": "Most studies to date have analyzed the expression of single genes within specific organs (such as heart, brain, or entire embryos) across stages of development or disease states.", "rank": 941, "start": 92090, "IsComparative": "0", "id": "st_941"}, {"end": 92519, "text": "The spatial localization of individual genes can be determined through fluorescent in situ hy- bridization (FISH), followed by confocal microscopy, optical transmission tomography, or by imaging serial sections of (frozen or paraffin-embedded) tissue.", "rank": 942, "start": 92268, "IsComparative": "0", "id": "st_942"}, {"end": 92705, "text": "A global view of gene expression across multiple genes can be obtained through microarray analysis of dissected tissue, either by selecting specific tissue types or through voxelization.", "rank": 943, "start": 92519, "IsComparative": "1", "id": "st_943"}, {"end": 92863, "text": "In the latter approach, sections of immobilized tissue are segmented into spatially registered cubes (voxels) which are then subjected to microarray analyses.", "rank": 944, "start": 92705, "IsComparative": "0", "id": "st_944"}, {"end": 93092, "text": "Voxelization is particu- larly appealing since the segmentation process is not biased by prior knowledge about the tissue being analyzed, making it possible to use the gene expression data to uncover novel morphological features.", "rank": 945, "start": 92863, "IsComparative": "0", "id": "st_945"}]}, {"paragraph_info": {"end": 93565, "start": 93092, "text": "Neurological disorders, such as autism, epilepsy, and schizophrenia are widely believed to have a basis in specific genes.Neurologists assess the presence or absence of candidate gene expressions in different brain regions to gain insights into these dis- eases <151>.While the relationship of the diseases and candidate gene expression profiles are not always well understood, it is important to facilitate this spatial-genomics explo- ration process through visual tools.", "rank": 212, "paragraph_comparative_number": 3, "entities": [], "id": "p_212"}, "sentences": [{"end": 93214, "text": "Neurological disorders, such as autism, epilepsy, and schizophrenia are widely believed to have a basis in specific genes.", "rank": 946, "start": 93092, "IsComparative": "1", "id": "st_946"}, {"end": 93360, "text": "Neurologists assess the presence or absence of candidate gene expressions in different brain regions to gain insights into these dis- eases <151>.", "rank": 947, "start": 93214, "IsComparative": "1", "id": "st_947"}, {"end": 93565, "text": "While the relationship of the diseases and candidate gene expression profiles are not always well understood, it is important to facilitate this spatial-genomics explo- ration process through visual tools.", "rank": 948, "start": 93360, "IsComparative": "1", "id": "st_948"}]}, {"paragraph_info": {"end": 94181, "start": 93565, "text": "New medical technologies can now characterize the state of a person with increas- ing precision at the molecular level to the genomic level to the organ level <89>.This wealth of personal medical information is now enabling the study of customized treat- ment for each patient through massive data-driven knowledge discovery.Genomic data is one of the most important components in this precision and personalized medicine revolu- tion.In this chapter we develop data-driven visual computing techniques for the analysis and visual understanding of multiple gene expression profile data to personalize the brain atlas.", "rank": 213, "paragraph_comparative_number": 3, "entities": [], "id": "p_213"}, "sentences": [{"end": 93729, "text": "New medical technologies can now characterize the state of a person with increas- ing precision at the molecular level to the genomic level to the organ level <89>.", "rank": 949, "start": 93565, "IsComparative": "1", "id": "st_949"}, {"end": 93890, "text": "This wealth of personal medical information is now enabling the study of customized treat- ment for each patient through massive data-driven knowledge discovery.", "rank": 950, "start": 93729, "IsComparative": "1", "id": "st_950"}, {"end": 94000, "text": "Genomic data is one of the most important components in this precision and personalized medicine revolu- tion.", "rank": 951, "start": 93890, "IsComparative": "0", "id": "st_951"}, {"end": 94181, "text": "In this chapter we develop data-driven visual computing techniques for the analysis and visual understanding of multiple gene expression profile data to personalize the brain atlas.", "rank": 952, "start": 94000, "IsComparative": "1", "id": "st_952"}]}, {"paragraph_info": {"end": 94825, "start": 94181, "text": "Allen Mouse Brain Dataset The Allen Mouse Brain Atlas <96> provides a set spa- tial gene expression profiles in adult and developing mouse brains.Many gene com- parison and visualization tools <152> have been published by the Allen brain institute for facilitating the use of this wealth of spatial genomic data.In addition to the gene expression profiles, it also provides an annotated reference atlas.In this chapter, we use a subset of the Allen Developing Mouse Brain dataset from the 2013 SciVis con- test (http://sciviscontest.ieeevis.org/).Our dataset contains 1600 gene expression profiles of developing mouse brains at stage 5 (E18.5).", "rank": 214, "paragraph_comparative_number": 3, "entities": [], "id": "p_214"}, "sentences": [{"end": 94327, "text": "Allen Mouse Brain Dataset The Allen Mouse Brain Atlas <96> provides a set spa- tial gene expression profiles in adult and developing mouse brains.", "rank": 953, "start": 94181, "IsComparative": "0", "id": "st_953"}, {"end": 94493, "text": "Many gene com- parison and visualization tools <152> have been published by the Allen brain institute for facilitating the use of this wealth of spatial genomic data.", "rank": 954, "start": 94327, "IsComparative": "1", "id": "st_954"}, {"end": 94584, "text": "In addition to the gene expression profiles, it also provides an annotated reference atlas.", "rank": 955, "start": 94493, "IsComparative": "1", "id": "st_955"}, {"end": 94728, "text": "In this chapter, we use a subset of the Allen Developing Mouse Brain dataset from the 2013 SciVis con- test (http://sciviscontest.ieeevis.org/).", "rank": 956, "start": 94584, "IsComparative": "0", "id": "st_956"}, {"end": 94825, "text": "Our dataset contains 1600 gene expression profiles of developing mouse brains at stage 5 (E18.5).", "rank": 957, "start": 94728, "IsComparative": "1", "id": "st_957"}]}, {"paragraph_info": {"end": 95202, "start": 94825, "text": "Contributions The main contribution of this chapter is in presenting a data-driven ap- proach for identifying geometric features of brain structures from spatial gene expression profiles.Specifically, we show a simple pipeline for retrieving correlated genes expres- sion profiles, extracting surfaces of the expressed regions, and personalizing a targeted reference structure.", "rank": 215, "paragraph_comparative_number": 1, "entities": [], "id": "p_215"}, "sentences": [{"end": 95012, "text": "Contributions The main contribution of this chapter is in presenting a data-driven ap- proach for identifying geometric features of brain structures from spatial gene expression profiles.", "rank": 958, "start": 94825, "IsComparative": "0", "id": "st_958"}, {"end": 95202, "text": "Specifically, we show a simple pipeline for retrieving correlated genes expres- sion profiles, extracting surfaces of the expressed regions, and personalizing a targeted reference structure.", "rank": 959, "start": 95012, "IsComparative": "1", "id": "st_959"}]}, {"paragraph_info": {"end": 95345, "start": 95202, "text": "Learn an expression Personalize the reference surface Retrieve gene expression profiles surface from the genes with the gene expression surface", "rank": 216, "paragraph_comparative_number": 0, "entities": [], "id": "p_216"}, "sentences": [{"end": 95345, "text": "Learn an expression Personalize the reference surface Retrieve gene expression profiles surface from the genes with the gene expression surface", "rank": 960, "start": 95202, "IsComparative": "0", "id": "st_960"}]}, {"paragraph_info": {"end": 95706, "start": 95345, "text": "Figure 5.1: We personalize the brain atlas by learning from gene expression profiles.Given a reference structure, we first retrieve a set of relevant gene expression profiles (step 1), and then we extract an expression surface from the genes (step 2), and we finally refine the reference surface to match the extracted gene expression boundary surface (step 3).", "rank": 217, "paragraph_comparative_number": 1, "entities": [], "id": "p_217"}, "sentences": [{"end": 95430, "text": "Figure 5.1: We personalize the brain atlas by learning from gene expression profiles.", "rank": 961, "start": 95345, "IsComparative": "0", "id": "st_961"}, {"end": 95706, "text": "Given a reference structure, we first retrieve a set of relevant gene expression profiles (step 1), and then we extract an expression surface from the genes (step 2), and we finally refine the reference surface to match the extracted gene expression boundary surface (step 3).", "rank": 962, "start": 95430, "IsComparative": "1", "id": "st_962"}]}, {"paragraph_info": {"end": 95718, "start": 95706, "text": "5.2 Overview", "rank": 218, "paragraph_comparative_number": 0, "entities": [], "id": "p_218"}, "sentences": [{"end": 95718, "text": "5.2 Overview", "rank": 963, "start": 95706, "IsComparative": "0", "id": "st_963"}]}, {"paragraph_info": {"end": 95911, "start": 95718, "text": "In this chapter, we extract the gene activity boundaries of a given 3D brain structure from a set of volumetric gene expression profiles.This data-driven procedure consists of three main steps:", "rank": 219, "paragraph_comparative_number": 1, "entities": [], "id": "p_219"}, "sentences": [{"end": 95855, "text": "In this chapter, we extract the gene activity boundaries of a given 3D brain structure from a set of volumetric gene expression profiles.", "rank": 964, "start": 95718, "IsComparative": "1", "id": "st_964"}, {"end": 95911, "text": "This data-driven procedure consists of three main steps:", "rank": 965, "start": 95855, "IsComparative": "0", "id": "st_965"}]}, {"paragraph_info": {"end": 96004, "start": 95911, "text": "1.Retrieve a set of genes that are highly correlated with the targeted reference struc- ture.", "rank": 220, "paragraph_comparative_number": 1, "entities": [], "id": "p_220"}, "sentences": [{"end": 95913, "text": "1.", "rank": 966, "start": 95911, "IsComparative": "1", "id": "st_966"}, {"end": 96004, "text": "Retrieve a set of genes that are highly correlated with the targeted reference struc- ture.", "rank": 967, "start": 95913, "IsComparative": "0", "id": "st_967"}]}, {"paragraph_info": {"end": 96151, "start": 96004, "text": "2.Construct a coherent normal vector field from the gene expression profiles, and extract a surface that represents the gene expression boundaries.", "rank": 221, "paragraph_comparative_number": 2, "entities": [], "id": "p_221"}, "sentences": [{"end": 96006, "text": "2.", "rank": 968, "start": 96004, "IsComparative": "1", "id": "st_968"}, {"end": 96151, "text": "Construct a coherent normal vector field from the gene expression profiles, and extract a surface that represents the gene expression boundaries.", "rank": 969, "start": 96006, "IsComparative": "1", "id": "st_969"}]}, {"paragraph_info": {"end": 96253, "start": 96151, "text": "3.Personalize the surface of the reference structure to match the extracted gene ex- pression surface.", "rank": 222, "paragraph_comparative_number": 1, "entities": [], "id": "p_222"}, "sentences": [{"end": 96153, "text": "3.", "rank": 970, "start": 96151, "IsComparative": "1", "id": "st_970"}, {"end": 96253, "text": "Personalize the surface of the reference structure to match the extracted gene ex- pression surface.", "rank": 971, "start": 96153, "IsComparative": "0", "id": "st_971"}]}, {"paragraph_info": {"end": 96300, "start": 96253, "text": "5.3 Selecting Relevant Gene Expression Profiles", "rank": 223, "paragraph_comparative_number": 0, "entities": [], "id": "p_223"}, "sentences": [{"end": 96300, "text": "5.3 Selecting Relevant Gene Expression Profiles", "rank": 972, "start": 96253, "IsComparative": "0", "id": "st_972"}]}, {"paragraph_info": {"end": 96905, "start": 96300, "text": "In order to discover high-quality and meaningful boundaries from the gene expres- sion profiles, we need to first limit the process to a handful of the most relevant genes that are highly expressed in the target region of interest.Given a target brain structure, we first use the volumetric anatomic mouse brain atlas <96> to construct a reference binary volume mask, m. Voxels inside the target structure are labeled by ones and voxels outside the structure are labeled by zeroes.For example, Figure 5.2 shows a visualization of the rostral midbrain tectum (MTt) structure in the middle of a mouse brain.", "rank": 224, "paragraph_comparative_number": 1, "entities": [], "id": "p_224"}, "sentences": [{"end": 96531, "text": "In order to discover high-quality and meaningful boundaries from the gene expres- sion profiles, we need to first limit the process to a handful of the most relevant genes that are highly expressed in the target region of interest.", "rank": 973, "start": 96300, "IsComparative": "1", "id": "st_973"}, {"end": 96781, "text": "Given a target brain structure, we first use the volumetric anatomic mouse brain atlas <96> to construct a reference binary volume mask, m. Voxels inside the target structure are labeled by ones and voxels outside the structure are labeled by zeroes.", "rank": 974, "start": 96531, "IsComparative": "0", "id": "st_974"}, {"end": 96905, "text": "For example, Figure 5.2 shows a visualization of the rostral midbrain tectum (MTt) structure in the middle of a mouse brain.", "rank": 975, "start": 96781, "IsComparative": "0", "id": "st_975"}]}, {"paragraph_info": {"end": 97338, "start": 96905, "text": "We compute the expression level, L(g,m) of a gene g and a structure mask m by 70 computing the dot product between the gene-expression volume and the binary structure mask volume.The gene expression profiles are volumetric scalar fields of the expressed energy.We normalize g by its total energy to ensure gene expression profiles with differ- ent energy levels are comparable.L(g,m) shows the correlation of gene g with structure m.", "rank": 225, "paragraph_comparative_number": 1, "entities": [], "id": "p_225"}, "sentences": [{"end": 97084, "text": "We compute the expression level, L(g,m) of a gene g and a structure mask m by 70 computing the dot product between the gene-expression volume and the binary structure mask volume.", "rank": 976, "start": 96905, "IsComparative": "0", "id": "st_976"}, {"end": 97166, "text": "The gene expression profiles are volumetric scalar fields of the expressed energy.", "rank": 977, "start": 97084, "IsComparative": "0", "id": "st_977"}, {"end": 97282, "text": "We normalize g by its total energy to ensure gene expression profiles with differ- ent energy levels are comparable.", "rank": 978, "start": 97166, "IsComparative": "1", "id": "st_978"}, {"end": 97338, "text": "L(g,m) shows the correlation of gene g with structure m.", "rank": 979, "start": 97282, "IsComparative": "0", "id": "st_979"}]}, {"paragraph_info": {"end": 97593, "start": 97338, "text": "We retrieve a set of genes, G = gi gn, with the highest L(g,m) in the structure m, where L(g, m) = g  m and g = g .These gene energy distributions will be used to show us the boundaries of the gene activities.Figure 5.3 shows the four most active genes in", "rank": 226, "paragraph_comparative_number": 1, "entities": [], "id": "p_226"}, "sentences": [{"end": 97453, "text": "We retrieve a set of genes, G = gi gn, with the highest L(g,m) in the structure m, where L(g, m) = g  m and g = g .", "rank": 980, "start": 97338, "IsComparative": "0", "id": "st_980"}, {"end": 97547, "text": "These gene energy distributions will be used to show us the boundaries of the gene activities.", "rank": 981, "start": 97453, "IsComparative": "0", "id": "st_981"}, {"end": 97593, "text": "Figure 5.3 shows the four most active genes in", "rank": 982, "start": 97547, "IsComparative": "1", "id": "st_982"}]}, {"paragraph_info": {"end": 97696, "start": 97593, "text": "the structure MTt.We retrieve five (n = 5) active gene expression profiles for each of our experiments.", "rank": 227, "paragraph_comparative_number": 1, "entities": [], "id": "p_227"}, "sentences": [{"end": 97611, "text": "the structure MTt.", "rank": 983, "start": 97593, "IsComparative": "0", "id": "st_983"}, {"end": 97696, "text": "We retrieve five (n = 5) active gene expression profiles for each of our experiments.", "rank": 984, "start": 97611, "IsComparative": "1", "id": "st_984"}]}, {"paragraph_info": {"end": 97765, "start": 97696, "text": "5.4 Extracting the Segmentation Surface from Gene Expression Profiles", "rank": 228, "paragraph_comparative_number": 0, "entities": [], "id": "p_228"}, "sentences": [{"end": 97765, "text": "5.4 Extracting the Segmentation Surface from Gene Expression Profiles", "rank": 985, "start": 97696, "IsComparative": "0", "id": "st_985"}]}, {"paragraph_info": {"end": 97973, "start": 97765, "text": "We extract the surface that conforms to the selected gene expression patterns.We use the highly expressed genes for this surface extraction process to ensure they are con- sistent with the targeted structure.", "rank": 229, "paragraph_comparative_number": 0, "entities": [], "id": "p_229"}, "sentences": [{"end": 97843, "text": "We extract the surface that conforms to the selected gene expression patterns.", "rank": 986, "start": 97765, "IsComparative": "0", "id": "st_986"}, {"end": 97973, "text": "We use the highly expressed genes for this surface extraction process to ensure they are con- sistent with the targeted structure.", "rank": 987, "start": 97843, "IsComparative": "0", "id": "st_987"}]}, {"paragraph_info": {"end": 98338, "start": 97973, "text": "First, we construct a coherent vector field from the scalar fields of the gene expres- sion profiles.Then, we use this vector field to derive a gradient field of gene expressions.High-gradient regions in scalar fields characterize boundaries <86, 120> between regions.Our goal is to extract the surface that passes through the high-gradient gene expression regions.", "rank": 230, "paragraph_comparative_number": 3, "entities": [], "id": "p_230"}, "sentences": [{"end": 98074, "text": "First, we construct a coherent vector field from the scalar fields of the gene expres- sion profiles.", "rank": 988, "start": 97973, "IsComparative": "1", "id": "st_988"}, {"end": 98152, "text": "Then, we use this vector field to derive a gradient field of gene expressions.", "rank": 989, "start": 98074, "IsComparative": "1", "id": "st_989"}, {"end": 98241, "text": "High-gradient regions in scalar fields characterize boundaries <86, 120> between regions.", "rank": 990, "start": 98152, "IsComparative": "0", "id": "st_990"}, {"end": 98338, "text": "Our goal is to extract the surface that passes through the high-gradient gene expression regions.", "rank": 991, "start": 98241, "IsComparative": "1", "id": "st_991"}]}, {"paragraph_info": {"end": 98372, "start": 98338, "text": "5.4.1 Coherent Normal Vector Field", "rank": 231, "paragraph_comparative_number": 0, "entities": [], "id": "p_231"}, "sentences": [{"end": 98372, "text": "5.4.1 Coherent Normal Vector Field", "rank": 992, "start": 98338, "IsComparative": "0", "id": "st_992"}]}, {"paragraph_info": {"end": 98800, "start": 98372, "text": "We use a voting approach to identify coherent normal directions from the highly expressed genes.Note that it is insufficient to identify high gradient regions of each gene expression profile and then aggregate them, because the gradients may have different orientations and represent different surfaces.Normal vectors or tensors have been used to vote in robust curvature computation <155, 119> and surface reconstruction <154>.", "rank": 232, "paragraph_comparative_number": 1, "entities": [], "id": "p_232"}, "sentences": [{"end": 98468, "text": "We use a voting approach to identify coherent normal directions from the highly expressed genes.", "rank": 993, "start": 98372, "IsComparative": "0", "id": "st_993"}, {"end": 98675, "text": "Note that it is insufficient to identify high gradient regions of each gene expression profile and then aggregate them, because the gradients may have different orientations and represent different surfaces.", "rank": 994, "start": 98468, "IsComparative": "1", "id": "st_994"}, {"end": 98800, "text": "Normal vectors or tensors have been used to vote in robust curvature computation <155, 119> and surface reconstruction <154>.", "rank": 995, "start": 98675, "IsComparative": "0", "id": "st_995"}]}, {"paragraph_info": {"end": 99279, "start": 98800, "text": "We construct a vector field of normal directions from each gene expression profile and then vote with the normals to determine the coherent directions.We construct the normals by computing the gradient of the gene-expression scalar field, gi, along the x,y,z directions.The voting process sums the normal vectors at each voxel and produces an aggregated coherent vector field, N.The magnitudes of the normal vectors are high in coherent regions and low in the incoherent regions.", "rank": 233, "paragraph_comparative_number": 1, "entities": [], "id": "p_233"}, "sentences": [{"end": 98951, "text": "We construct a vector field of normal directions from each gene expression profile and then vote with the normals to determine the coherent directions.", "rank": 996, "start": 98800, "IsComparative": "0", "id": "st_996"}, {"end": 99070, "text": "We construct the normals by computing the gradient of the gene-expression scalar field, gi, along the x,y,z directions.", "rank": 997, "start": 98951, "IsComparative": "1", "id": "st_997"}, {"end": 99179, "text": "The voting process sums the normal vectors at each voxel and produces an aggregated coherent vector field, N.", "rank": 998, "start": 99070, "IsComparative": "0", "id": "st_998"}, {"end": 99279, "text": "The magnitudes of the normal vectors are high in coherent regions and low in the incoherent regions.", "rank": 999, "start": 99179, "IsComparative": "0", "id": "st_999"}]}, {"paragraph_info": {"end": 99661, "start": 99279, "text": "Let us consider the vector and scalar components of the coherent vector field N. Let n be a unit vector field representing the directions of the vector field N. Let s be the scalar field of the corresponding gradient magnitudes.We use n and s to extract an extremal surface <154> in the next step.Figure 5.4 shows visualizations of coherent vector field N and the scalar field s = N", "rank": 234, "paragraph_comparative_number": 1, "entities": [], "id": "p_234"}, "sentences": [{"end": 99507, "text": "Let us consider the vector and scalar components of the coherent vector field N. Let n be a unit vector field representing the directions of the vector field N. Let s be the scalar field of the corresponding gradient magnitudes.", "rank": 1000, "start": 99279, "IsComparative": "0", "id": "st_1000"}, {"end": 99576, "text": "We use n and s to extract an extremal surface <154> in the next step.", "rank": 1001, "start": 99507, "IsComparative": "0", "id": "st_1001"}, {"end": 99661, "text": "Figure 5.4 shows visualizations of coherent vector field N and the scalar field s = N", "rank": 1002, "start": 99576, "IsComparative": "1", "id": "st_1002"}]}, {"paragraph_info": {"end": 99722, "start": 99661, "text": "5.4.2 Extracting the Bounding Surface of the Gene Expressions", "rank": 235, "paragraph_comparative_number": 1, "entities": [], "id": "p_235"}, "sentences": [{"end": 99722, "text": "5.4.2 Extracting the Bounding Surface of the Gene Expressions", "rank": 1003, "start": 99661, "IsComparative": "1", "id": "st_1003"}]}, {"paragraph_info": {"end": 99989, "start": 99722, "text": "We find the gene expression boundaries by extracting the surface that passes through the gene expression gradient peaks.This surface can be extracted by the extremal surface method with the vector field, n, and the gradient field, s.A point is on the extremal surface", "rank": 236, "paragraph_comparative_number": 0, "entities": [], "id": "p_236"}, "sentences": [{"end": 99842, "text": "We find the gene expression boundaries by extracting the surface that passes through the gene expression gradient peaks.", "rank": 1004, "start": 99722, "IsComparative": "0", "id": "st_1004"}, {"end": 99955, "text": "This surface can be extracted by the extremal surface method with the vector field, n, and the gradient field, s.", "rank": 1005, "start": 99842, "IsComparative": "0", "id": "st_1005"}, {"end": 99989, "text": "A point is on the extremal surface", "rank": 1006, "start": 99955, "IsComparative": "0", "id": "st_1006"}]}, {"paragraph_info": {"end": 100072, "start": 99989, "text": "5.5 Personalizing the Reference Structure to the Gene Expression Bound- ary Surface", "rank": 237, "paragraph_comparative_number": 0, "entities": [], "id": "p_237"}, "sentences": [{"end": 100072, "text": "5.5 Personalizing the Reference Structure to the Gene Expression Bound- ary Surface", "rank": 1007, "start": 99989, "IsComparative": "0", "id": "st_1007"}]}, {"paragraph_info": {"end": 100346, "start": 100072, "text": "We personalize the reference structure with the gene expression boundary surface by deforming the reference structure to match the latter.Given a binary reference structure volume mask m, we first extract an iso-surface at iso-value 0.5 to represent the reference structure.", "rank": 238, "paragraph_comparative_number": 1, "entities": [], "id": "p_238"}, "sentences": [{"end": 100210, "text": "We personalize the reference structure with the gene expression boundary surface by deforming the reference structure to match the latter.", "rank": 1008, "start": 100072, "IsComparative": "0", "id": "st_1008"}, {"end": 100346, "text": "Given a binary reference structure volume mask m, we first extract an iso-surface at iso-value 0.5 to represent the reference structure.", "rank": 1009, "start": 100210, "IsComparative": "1", "id": "st_1009"}]}, {"paragraph_info": {"end": 100757, "start": 100346, "text": "For each vertex on the reference surface, we find the corresponding closest point on the gene expression surface.Many distance field computation algorithms with spatial data structures <6> and GPU computing <30, 146, 147> can perform an accelerated proximity search for this.Figure 5.6(a) shows a visualization of the distance distribution between the reference surface and the gene expression boundary surface.", "rank": 239, "paragraph_comparative_number": 1, "entities": [], "id": "p_239"}, "sentences": [{"end": 100459, "text": "For each vertex on the reference surface, we find the corresponding closest point on the gene expression surface.", "rank": 1010, "start": 100346, "IsComparative": "0", "id": "st_1010"}, {"end": 100621, "text": "Many distance field computation algorithms with spatial data structures <6> and GPU computing <30, 146, 147> can perform an accelerated proximity search for this.", "rank": 1011, "start": 100459, "IsComparative": "1", "id": "st_1011"}, {"end": 100757, "text": "Figure 5.6(a) shows a visualization of the distance distribution between the reference surface and the gene expression boundary surface.", "rank": 1012, "start": 100621, "IsComparative": "0", "id": "st_1012"}]}, {"paragraph_info": {"end": 101009, "start": 100757, "text": "We warp the reference surface to the gene expression surface by moving the refer- ence vertices to their closest corresponding points on the gene expression surface.Fig- ure 5.6(b) shows a comparison of the original and personalized reference surfaces.", "rank": 240, "paragraph_comparative_number": 2, "entities": [], "id": "p_240"}, "sentences": [{"end": 100922, "text": "We warp the reference surface to the gene expression surface by moving the refer- ence vertices to their closest corresponding points on the gene expression surface.", "rank": 1013, "start": 100757, "IsComparative": "1", "id": "st_1013"}, {"end": 101009, "text": "Fig- ure 5.6(b) shows a comparison of the original and personalized reference surfaces.", "rank": 1014, "start": 100922, "IsComparative": "1", "id": "st_1014"}]}, {"paragraph_info": {"end": 101020, "start": 101009, "text": "5.6 Results", "rank": 241, "paragraph_comparative_number": 0, "entities": [], "id": "p_241"}, "sentences": [{"end": 101020, "text": "5.6 Results", "rank": 1015, "start": 101009, "IsComparative": "0", "id": "st_1015"}]}, {"paragraph_info": {"end": 101556, "start": 101020, "text": "In this section, we present the results of our approach.For each example brain structure, we show the reference structure, the relevant gene expression profiles, the gene expression surface and the surface of our personalized reference structure.We overlay the wireframes of the reference structures to show the deformation.We first show exam- ples with reference structures that are similar to the gene expression surfaces, and then discuss cases in which the gene expression surfaces deviate from the reference brain atlas structures.", "rank": 242, "paragraph_comparative_number": 1, "entities": [], "id": "p_242"}, "sentences": [{"end": 101076, "text": "In this section, we present the results of our approach.", "rank": 1016, "start": 101020, "IsComparative": "0", "id": "st_1016"}, {"end": 101266, "text": "For each example brain structure, we show the reference structure, the relevant gene expression profiles, the gene expression surface and the surface of our personalized reference structure.", "rank": 1017, "start": 101076, "IsComparative": "1", "id": "st_1017"}, {"end": 101344, "text": "We overlay the wireframes of the reference structures to show the deformation.", "rank": 1018, "start": 101266, "IsComparative": "0", "id": "st_1018"}, {"end": 101556, "text": "We first show exam- ples with reference structures that are similar to the gene expression surfaces, and then discuss cases in which the gene expression surfaces deviate from the reference brain atlas structures.", "rank": 1019, "start": 101344, "IsComparative": "0", "id": "st_1019"}]}, {"paragraph_info": {"end": 101580, "start": 101556, "text": "5.6.1 Experimental Setup", "rank": 243, "paragraph_comparative_number": 0, "entities": [], "id": "p_243"}, "sentences": [{"end": 101580, "text": "5.6.1 Experimental Setup", "rank": 1020, "start": 101556, "IsComparative": "0", "id": "st_1020"}]}, {"paragraph_info": {"end": 102075, "start": 101580, "text": "We have implemented our approach on the Linux platform with Python.The nor- mal voting and gradient computation have been implemented with NumPy.Iso-surface extraction and distances from surfaces are computated using VTK.We have run our ex- periments on a workstation with an Intel Xeon 2.33 GHz CPU and an NVIDIA GeForce GTX 295 GPU.The computation time for retrieving correlated genes, extracting the gene expression surface, and personalizing the reference structure is less than two seconds.", "rank": 244, "paragraph_comparative_number": 3, "entities": [], "id": "p_244"}, "sentences": [{"end": 101647, "text": "We have implemented our approach on the Linux platform with Python.", "rank": 1021, "start": 101580, "IsComparative": "1", "id": "st_1021"}, {"end": 101725, "text": "The nor- mal voting and gradient computation have been implemented with NumPy.", "rank": 1022, "start": 101647, "IsComparative": "0", "id": "st_1022"}, {"end": 101801, "text": "Iso-surface extraction and distances from surfaces are computated using VTK.", "rank": 1023, "start": 101725, "IsComparative": "0", "id": "st_1023"}, {"end": 101914, "text": "We have run our ex- periments on a workstation with an Intel Xeon 2.33 GHz CPU and an NVIDIA GeForce GTX 295 GPU.", "rank": 1024, "start": 101801, "IsComparative": "1", "id": "st_1024"}, {"end": 102075, "text": "The computation time for retrieving correlated genes, extracting the gene expression surface, and personalizing the reference structure is less than two seconds.", "rank": 1025, "start": 101914, "IsComparative": "1", "id": "st_1025"}]}, {"paragraph_info": {"end": 102151, "start": 102075, "text": "5.6.2 Structures whose Gene Expression Surfaces largely agree with the Atlas", "rank": 245, "paragraph_comparative_number": 1, "entities": [], "id": "p_245"}, "sentences": [{"end": 102151, "text": "5.6.2 Structures whose Gene Expression Surfaces largely agree with the Atlas", "rank": 1026, "start": 102075, "IsComparative": "1", "id": "st_1026"}]}, {"paragraph_info": {"end": 102666, "start": 102151, "text": "Central Subpallium The subpallium is the major basal subdivision of the embryonic telencephalon; it is related to the control of motor, cognitive and emotional responses.Figure 5.7(a) shows this structure.Figures 5.7 (b-e) show the relevant highly expressed genes.Figure 5.7 (e) shows the gene expression surface and Figure 5.7 (f) shows the personalized surface of the reference structure.In this example, the expressions of the three genes, Foxp1, Pde10a, and Drd2, span different parts of the targeted structure.", "rank": 246, "paragraph_comparative_number": 2, "entities": [], "id": "p_246"}, "sentences": [{"end": 102321, "text": "Central Subpallium The subpallium is the major basal subdivision of the embryonic telencephalon; it is related to the control of motor, cognitive and emotional responses.", "rank": 1027, "start": 102151, "IsComparative": "1", "id": "st_1027"}, {"end": 102356, "text": "Figure 5.7(a) shows this structure.", "rank": 1028, "start": 102321, "IsComparative": "0", "id": "st_1028"}, {"end": 102415, "text": "Figures 5.7 (b-e) show the relevant highly expressed genes.", "rank": 1029, "start": 102356, "IsComparative": "0", "id": "st_1029"}, {"end": 102541, "text": "Figure 5.7 (e) shows the gene expression surface and Figure 5.7 (f) shows the personalized surface of the reference structure.", "rank": 1030, "start": 102415, "IsComparative": "0", "id": "st_1030"}, {"end": 102666, "text": "In this example, the expressions of the three genes, Foxp1, Pde10a, and Drd2, span different parts of the targeted structure.", "rank": 1031, "start": 102541, "IsComparative": "1", "id": "st_1031"}]}, {"paragraph_info": {"end": 103229, "start": 102666, "text": "Alar plate of Prosomere 2 The Alar plate of Prosomere 2 is a neural structure in the developing mouse forebrain.The prosomere is a part of the thalamus, which is respon- sible for sensory perception and regulation of motor functions.Figure 5.8(a) shows this structure.Figures 5.8 (b-e) show the relevant highly expressed genes.Figure 5.8 (e) shows the gene expression surface and Figure 5.8 (f) shows the personalized surface of the reference structure.The expression of gene Prox1 is highly localized.Genes Ntng1 and Gbx2 show more tube like expression patterns.", "rank": 247, "paragraph_comparative_number": 2, "entities": [], "id": "p_247"}, "sentences": [{"end": 102778, "text": "Alar plate of Prosomere 2 The Alar plate of Prosomere 2 is a neural structure in the developing mouse forebrain.", "rank": 1032, "start": 102666, "IsComparative": "1", "id": "st_1032"}, {"end": 102899, "text": "The prosomere is a part of the thalamus, which is respon- sible for sensory perception and regulation of motor functions.", "rank": 1033, "start": 102778, "IsComparative": "1", "id": "st_1033"}, {"end": 102934, "text": "Figure 5.8(a) shows this structure.", "rank": 1034, "start": 102899, "IsComparative": "0", "id": "st_1034"}, {"end": 102993, "text": "Figures 5.8 (b-e) show the relevant highly expressed genes.", "rank": 1035, "start": 102934, "IsComparative": "0", "id": "st_1035"}, {"end": 103119, "text": "Figure 5.8 (e) shows the gene expression surface and Figure 5.8 (f) shows the personalized surface of the reference structure.", "rank": 1036, "start": 102993, "IsComparative": "0", "id": "st_1036"}, {"end": 103168, "text": "The expression of gene Prox1 is highly localized.", "rank": 1037, "start": 103119, "IsComparative": "0", "id": "st_1037"}, {"end": 103229, "text": "Genes Ntng1 and Gbx2 show more tube like expression patterns.", "rank": 1038, "start": 103168, "IsComparative": "0", "id": "st_1038"}]}, {"paragraph_info": {"end": 103752, "start": 103229, "text": "Rostral Secondary Prosencephalon This mouse forebrain development region con- tains the preoptic area and the rostral hypothalamus, which controls much of a mouses basic behavior, including feeding.Figure 5.9(a) shows this structure.Figures 5.9 (b-e) show the relevant highly expressed genes.Figure 5.9 (e) shows the gene expression sur- face and Figure 5.9 (f) shows the personalized surface of the reference structure.The personalization deforms the reference surface unevenly according to expressions of the three genes.", "rank": 248, "paragraph_comparative_number": 2, "entities": [], "id": "p_248"}, "sentences": [{"end": 103427, "text": "Rostral Secondary Prosencephalon This mouse forebrain development region con- tains the preoptic area and the rostral hypothalamus, which controls much of a mouses basic behavior, including feeding.", "rank": 1039, "start": 103229, "IsComparative": "0", "id": "st_1039"}, {"end": 103462, "text": "Figure 5.9(a) shows this structure.", "rank": 1040, "start": 103427, "IsComparative": "0", "id": "st_1040"}, {"end": 103521, "text": "Figures 5.9 (b-e) show the relevant highly expressed genes.", "rank": 1041, "start": 103462, "IsComparative": "0", "id": "st_1041"}, {"end": 103649, "text": "Figure 5.9 (e) shows the gene expression sur- face and Figure 5.9 (f) shows the personalized surface of the reference structure.", "rank": 1042, "start": 103521, "IsComparative": "1", "id": "st_1042"}, {"end": 103752, "text": "The personalization deforms the reference surface unevenly according to expressions of the three genes.", "rank": 1043, "start": 103649, "IsComparative": "1", "id": "st_1043"}]}, {"paragraph_info": {"end": 103803, "start": 103752, "text": "5.6.3 Structures with Small Gene Expression Regions", "rank": 249, "paragraph_comparative_number": 1, "entities": [], "id": "p_249"}, "sentences": [{"end": 103803, "text": "5.6.3 Structures with Small Gene Expression Regions", "rank": 1044, "start": 103752, "IsComparative": "1", "id": "st_1044"}]}, {"paragraph_info": {"end": 103972, "start": 103803, "text": "We have found structures with limited gene expressed regions whose gene expres- sion surfaces are not similar to the surface of the reference structure.In Figure 5.10(a)", "rank": 250, "paragraph_comparative_number": 1, "entities": [], "id": "p_250"}, "sentences": [{"end": 103955, "text": "We have found structures with limited gene expressed regions whose gene expres- sion surfaces are not similar to the surface of the reference structure.", "rank": 1045, "start": 103803, "IsComparative": "1", "id": "st_1045"}, {"end": 103972, "text": "In Figure 5.10(a)", "rank": 1046, "start": 103955, "IsComparative": "0", "id": "st_1046"}]}, {"paragraph_info": {"end": 104022, "start": 103972, "text": "5.6.4 High Gene Expressions in Multiple Structures", "rank": 251, "paragraph_comparative_number": 1, "entities": [], "id": "p_251"}, "sentences": [{"end": 104022, "text": "5.6.4 High Gene Expressions in Multiple Structures", "rank": 1047, "start": 103972, "IsComparative": "1", "id": "st_1047"}]}, {"paragraph_info": {"end": 104532, "start": 104022, "text": "In contrast with the previous scenario, we have also found structures with high gene expressions across multiple structures.For example in the hindbrain of a mouse, the experts have identified 11 structures.We found that many gene expression profiles span across multiple hindbrain structures as shown in Figure 5.11 (a) and (b).In this case, when we extract gene expression surfaces for each of the individual structures, we get surfaces that span across multiple hindbrain structures as in Figure 5.11 (c-f).", "rank": 252, "paragraph_comparative_number": 3, "entities": [], "id": "p_252"}, "sentences": [{"end": 104146, "text": "In contrast with the previous scenario, we have also found structures with high gene expressions across multiple structures.", "rank": 1048, "start": 104022, "IsComparative": "1", "id": "st_1048"}, {"end": 104229, "text": "For example in the hindbrain of a mouse, the experts have identified 11 structures.", "rank": 1049, "start": 104146, "IsComparative": "1", "id": "st_1049"}, {"end": 104351, "text": "We found that many gene expression profiles span across multiple hindbrain structures as shown in Figure 5.11 (a) and (b).", "rank": 1050, "start": 104229, "IsComparative": "0", "id": "st_1050"}, {"end": 104532, "text": "In this case, when we extract gene expression surfaces for each of the individual structures, we get surfaces that span across multiple hindbrain structures as in Figure 5.11 (c-f).", "rank": 1051, "start": 104351, "IsComparative": "1", "id": "st_1051"}]}, {"paragraph_info": {"end": 104563, "start": 104532, "text": "5.7 Conclusions and Discussions", "rank": 253, "paragraph_comparative_number": 1, "entities": [], "id": "p_253"}, "sentences": [{"end": 104563, "text": "5.7 Conclusions and Discussions", "rank": 1052, "start": 104532, "IsComparative": "1", "id": "st_1052"}]}, {"paragraph_info": {"end": 105627, "start": 104563, "text": "We have presented a data-driven approach for personalizing the brain atlas with many gene expression profiles.We first retrieve the relevant genes for a reference brain structure, then we extract a coherent expression boundary from these genes and use this surface of the expression boundary to personalize the reference brain structure.In the surface extraction process, we perform normal voting to identify gene expression direc- tions that are coherent across multiple gene expression profiles.From these directions, we extract an extremal surface for personalizing the reference brain structure.In our ex- periments, we have found some gene expression surfaces that are similar and some that are different from the reference brain structures.Our surface extraction approach shows the localization of spread of these gene expressions and visualizes their comparison with the reference structures.We believe our approach suggests a way in which data from multiple gene expression profiles could augment brain atlases, and in fact atlases of the entire organisms.", "rank": 254, "paragraph_comparative_number": 4, "entities": [], "id": "p_254"}, "sentences": [{"end": 104673, "text": "We have presented a data-driven approach for personalizing the brain atlas with many gene expression profiles.", "rank": 1053, "start": 104563, "IsComparative": "0", "id": "st_1053"}, {"end": 104900, "text": "We first retrieve the relevant genes for a reference brain structure, then we extract a coherent expression boundary from these genes and use this surface of the expression boundary to personalize the reference brain structure.", "rank": 1054, "start": 104673, "IsComparative": "0", "id": "st_1054"}, {"end": 105060, "text": "In the surface extraction process, we perform normal voting to identify gene expression direc- tions that are coherent across multiple gene expression profiles.", "rank": 1055, "start": 104900, "IsComparative": "1", "id": "st_1055"}, {"end": 105162, "text": "From these directions, we extract an extremal surface for personalizing the reference brain structure.", "rank": 1056, "start": 105060, "IsComparative": "0", "id": "st_1056"}, {"end": 105309, "text": "In our ex- periments, we have found some gene expression surfaces that are similar and some that are different from the reference brain structures.", "rank": 1057, "start": 105162, "IsComparative": "1", "id": "st_1057"}, {"end": 105462, "text": "Our surface extraction approach shows the localization of spread of these gene expressions and visualizes their comparison with the reference structures.", "rank": 1058, "start": 105309, "IsComparative": "1", "id": "st_1058"}, {"end": 105627, "text": "We believe our approach suggests a way in which data from multiple gene expression profiles could augment brain atlases, and in fact atlases of the entire organisms.", "rank": 1059, "start": 105462, "IsComparative": "1", "id": "st_1059"}]}, {"paragraph_info": {"end": 105636, "start": 105627, "text": "Chapter 6", "rank": 255, "paragraph_comparative_number": 0, "entities": [], "id": "p_255"}, "sentences": [{"end": 105636, "text": "Chapter 6", "rank": 1060, "start": 105627, "IsComparative": "0", "id": "st_1060"}]}, {"paragraph_info": {"end": 105705, "start": 105636, "text": "Fast Trajectory Clustering using the Kernel Distance 6.1 Introduction", "rank": 256, "paragraph_comparative_number": 0, "entities": [], "id": "p_256"}, "sentences": [{"end": 105705, "text": "Fast Trajectory Clustering using the Kernel Distance 6.1 Introduction", "rank": 1061, "start": 105636, "IsComparative": "0", "id": "st_1061"}]}, {"paragraph_info": {"end": 106958, "start": 105705, "text": "The study of time-varying geospatial patterns is important for many disciplines.The study of such patterns can greatly enhance our understanding of evolving spatial interactions and relationships amongst moving entities at varying scales of space and time.The advances and availability of tracking devices, such as RFID tags, GPS signals, as well as tracking from aerial and satellite imagery has led to an explosive growth of location-tagged data of people <175>, animals <169>, vehicles <127, 175>, and weather data <114>.For example, climate scientists study historical hurricane patterns to help predict future hurricane tracks.The study of animal movements reveal their migratory behavior and can help in protecting endangered species from poaching.Understanding vehicular traffic patterns can lead to more informed urban planning.While we are now able to track the movements of billions of entities every second, the sheer size of this data has far surpassed our ability to meaningfully analyze it.It is crucial for us to develop highly efficient algorithms if we are to make sense out of this enormous and growing body of geospatial trajectory data.In this chapter we present a novel approach to compare and cluster these geospatial trajectories.", "rank": 257, "paragraph_comparative_number": 7, "entities": [], "id": "p_257"}, "sentences": [{"end": 105785, "text": "The study of time-varying geospatial patterns is important for many disciplines.", "rank": 1062, "start": 105705, "IsComparative": "0", "id": "st_1062"}, {"end": 105961, "text": "The study of such patterns can greatly enhance our understanding of evolving spatial interactions and relationships amongst moving entities at varying scales of space and time.", "rank": 1063, "start": 105785, "IsComparative": "1", "id": "st_1063"}, {"end": 106229, "text": "The advances and availability of tracking devices, such as RFID tags, GPS signals, as well as tracking from aerial and satellite imagery has led to an explosive growth of location-tagged data of people <175>, animals <169>, vehicles <127, 175>, and weather data <114>.", "rank": 1064, "start": 105961, "IsComparative": "1", "id": "st_1064"}, {"end": 106337, "text": "For example, climate scientists study historical hurricane patterns to help predict future hurricane tracks.", "rank": 1065, "start": 106229, "IsComparative": "1", "id": "st_1065"}, {"end": 106459, "text": "The study of animal movements reveal their migratory behavior and can help in protecting endangered species from poaching.", "rank": 1066, "start": 106337, "IsComparative": "1", "id": "st_1066"}, {"end": 106541, "text": "Understanding vehicular traffic patterns can lead to more informed urban planning.", "rank": 1067, "start": 106459, "IsComparative": "1", "id": "st_1067"}, {"end": 106709, "text": "While we are now able to track the movements of billions of entities every second, the sheer size of this data has far surpassed our ability to meaningfully analyze it.", "rank": 1068, "start": 106541, "IsComparative": "0", "id": "st_1068"}, {"end": 106861, "text": "It is crucial for us to develop highly efficient algorithms if we are to make sense out of this enormous and growing body of geospatial trajectory data.", "rank": 1069, "start": 106709, "IsComparative": "1", "id": "st_1069"}, {"end": 106958, "text": "In this chapter we present a novel approach to compare and cluster these geospatial trajectories.", "rank": 1070, "start": 106861, "IsComparative": "1", "id": "st_1070"}]}, {"paragraph_info": {"end": 106974, "start": 106958, "text": "6.1.1 Challenges", "rank": 258, "paragraph_comparative_number": 0, "entities": [], "id": "p_258"}, "sentences": [{"end": 106974, "text": "6.1.1 Challenges", "rank": 1071, "start": 106958, "IsComparative": "0", "id": "st_1071"}]}, {"paragraph_info": {"end": 107490, "start": 106974, "text": "The fundamental challenge in trajectory clustering is to efficiently compute the dis- tance between two trajectories.This traditionally has been a quadratic operation in the number of points of the two trajectories as we have to compute the distances between all pairs of points between the two trajectories.For example, the computation of the Fre chet distance, which measures the minimum distance between the points in two trajectories, requires an O(n2) solution for polygonal curves <1> and discrete points <29>.", "rank": 259, "paragraph_comparative_number": 3, "entities": [], "id": "p_259"}, "sentences": [{"end": 107091, "text": "The fundamental challenge in trajectory clustering is to efficiently compute the dis- tance between two trajectories.", "rank": 1072, "start": 106974, "IsComparative": "1", "id": "st_1072"}, {"end": 107282, "text": "This traditionally has been a quadratic operation in the number of points of the two trajectories as we have to compute the distances between all pairs of points between the two trajectories.", "rank": 1073, "start": 107091, "IsComparative": "1", "id": "st_1073"}, {"end": 107490, "text": "For example, the computation of the Fre chet distance, which measures the minimum distance between the points in two trajectories, requires an O(n2) solution for polygonal curves <1> and discrete points <29>.", "rank": 1074, "start": 107282, "IsComparative": "1", "id": "st_1074"}]}, {"paragraph_info": {"end": 107911, "start": 107490, "text": "In this chapter, we develop a new framework to compare geospatial trajectories around approximate kernel distances <139, 75>.In our approach we use the approximate kernel distance to transform the set of points in a trajectory to a single high-dimensional feature vector through a randomized mapping procedure.We compare the shapes of the trajectories by the distance between their respective high-dimensional embeddings.", "rank": 260, "paragraph_comparative_number": 2, "entities": [], "id": "p_260"}, "sentences": [{"end": 107615, "text": "In this chapter, we develop a new framework to compare geospatial trajectories around approximate kernel distances <139, 75>.", "rank": 1075, "start": 107490, "IsComparative": "0", "id": "st_1075"}, {"end": 107800, "text": "In our approach we use the approximate kernel distance to transform the set of points in a trajectory to a single high-dimensional feature vector through a randomized mapping procedure.", "rank": 1076, "start": 107615, "IsComparative": "1", "id": "st_1076"}, {"end": 107911, "text": "We compare the shapes of the trajectories by the distance between their respective high-dimensional embeddings.", "rank": 1077, "start": 107800, "IsComparative": "1", "id": "st_1077"}]}, {"paragraph_info": {"end": 107930, "start": 107911, "text": "6.1.2 Contributions", "rank": 261, "paragraph_comparative_number": 0, "entities": [], "id": "p_261"}, "sentences": [{"end": 107930, "text": "6.1.2 Contributions", "rank": 1078, "start": 107911, "IsComparative": "0", "id": "st_1078"}]}, {"paragraph_info": {"end": 108278, "start": 107930, "text": "1.Weintroducetheuseofthekerneldistanceforclusteringgeospatialtrajectories.We show that the formulation of the approximate kernel distance allows us to compactly represent trajectories as high-dimensional feature vectors.This transformation al- lows us to leverage a wealth of point-based clustering algorithms for analyzing geospatial trajectories.", "rank": 262, "paragraph_comparative_number": 3, "entities": [], "id": "p_262"}, "sentences": [{"end": 107932, "text": "1.", "rank": 1079, "start": 107930, "IsComparative": "1", "id": "st_1079"}, {"end": 108150, "text": "Weintroducetheuseofthekerneldistanceforclusteringgeospatialtrajectories.We show that the formulation of the approximate kernel distance allows us to compactly represent trajectories as high-dimensional feature vectors.", "rank": 1080, "start": 107932, "IsComparative": "1", "id": "st_1080"}, {"end": 108278, "text": "This transformation al- lows us to leverage a wealth of point-based clustering algorithms for analyzing geospatial trajectories.", "rank": 1081, "start": 108150, "IsComparative": "1", "id": "st_1081"}]}, {"paragraph_info": {"end": 108743, "start": 108278, "text": "2.We use the kernel distance framework and k-means clustering to perform effective shape and spatial clustering.We also show how to update the trajectory feature vectors to accommodate streaming trajectory data.While we use the popular k- means algorithm for our clustering, our framework allows us to use any clustering method.An advantage of the kernel distance approach is that along with the dis- tance, we also get a measure of similarity between trajectories.", "rank": 263, "paragraph_comparative_number": 3, "entities": [], "id": "p_263"}, "sentences": [{"end": 108280, "text": "2.", "rank": 1082, "start": 108278, "IsComparative": "1", "id": "st_1082"}, {"end": 108390, "text": "We use the kernel distance framework and k-means clustering to perform effective shape and spatial clustering.", "rank": 1083, "start": 108280, "IsComparative": "0", "id": "st_1083"}, {"end": 108489, "text": "We also show how to update the trajectory feature vectors to accommodate streaming trajectory data.", "rank": 1084, "start": 108390, "IsComparative": "1", "id": "st_1084"}, {"end": 108606, "text": "While we use the popular k- means algorithm for our clustering, our framework allows us to use any clustering method.", "rank": 1085, "start": 108489, "IsComparative": "1", "id": "st_1085"}, {"end": 108743, "text": "An advantage of the kernel distance approach is that along with the dis- tance, we also get a measure of similarity between trajectories.", "rank": 1086, "start": 108606, "IsComparative": "0", "id": "st_1086"}]}, {"paragraph_info": {"end": 109066, "start": 108743, "text": "3.Our approximate kernel distance framework for trajectory clustering is fairly flexi- ble.In addition to k-means clustering, we also show how to incorporate automatic community detection in our framework.Such graph-based clustering approaches, facilitate discovery of clusters that are of general shapes and distributions.", "rank": 264, "paragraph_comparative_number": 4, "entities": [], "id": "p_264"}, "sentences": [{"end": 108745, "text": "3.", "rank": 1087, "start": 108743, "IsComparative": "1", "id": "st_1087"}, {"end": 108834, "text": "Our approximate kernel distance framework for trajectory clustering is fairly flexi- ble.", "rank": 1088, "start": 108745, "IsComparative": "1", "id": "st_1088"}, {"end": 108948, "text": "In addition to k-means clustering, we also show how to incorporate automatic community detection in our framework.", "rank": 1089, "start": 108834, "IsComparative": "1", "id": "st_1089"}, {"end": 109066, "text": "Such graph-based clustering approaches, facilitate discovery of clusters that are of general shapes and distributions.", "rank": 1090, "start": 108948, "IsComparative": "1", "id": "st_1090"}]}, {"paragraph_info": {"end": 109596, "start": 109066, "text": "4.We show that our approach is significantly more efficient than the state-of-the-art approaches in analyzing geospatial trajectories.Our approach only took about one minute to process 24K air traffic trajectories of 2 million points, while TR- ACLUS <95> took more than 5.5 hours.Our approach is also scalable and we were able to incrementally process almost half a million taxi trajectories collec- tively comprising 11 million points in 15 minutes.Our datasets are significantly larger than those reported in the previous work.", "rank": 265, "paragraph_comparative_number": 4, "entities": [], "id": "p_265"}, "sentences": [{"end": 109068, "text": "4.", "rank": 1091, "start": 109066, "IsComparative": "1", "id": "st_1091"}, {"end": 109200, "text": "We show that our approach is significantly more efficient than the state-of-the-art approaches in analyzing geospatial trajectories.", "rank": 1092, "start": 109068, "IsComparative": "0", "id": "st_1092"}, {"end": 109347, "text": "Our approach only took about one minute to process 24K air traffic trajectories of 2 million points, while TR- ACLUS <95> took more than 5.5 hours.", "rank": 1093, "start": 109200, "IsComparative": "1", "id": "st_1093"}, {"end": 109517, "text": "Our approach is also scalable and we were able to incrementally process almost half a million taxi trajectories collec- tively comprising 11 million points in 15 minutes.", "rank": 1094, "start": 109347, "IsComparative": "1", "id": "st_1094"}, {"end": 109596, "text": "Our datasets are significantly larger than those reported in the previous work.", "rank": 1095, "start": 109517, "IsComparative": "1", "id": "st_1095"}]}, {"paragraph_info": {"end": 109608, "start": 109596, "text": "6.2 Overview", "rank": 266, "paragraph_comparative_number": 0, "entities": [], "id": "p_266"}, "sentences": [{"end": 109608, "text": "6.2 Overview", "rank": 1096, "start": 109596, "IsComparative": "0", "id": "st_1096"}]}, {"paragraph_info": {"end": 110354, "start": 109608, "text": "In this chapter, we introduce an approach to cluster geospatial trajectories by using the kernel distance.Figure 6.1 illustrates the steps of our approach.Given trajectories input P and Q, the kernel distance framework projects each trajectory onto a randomly drawn i.i.d.sample of points from a normal distribution, and obtain fixed-length feature vectors (P) and (Q).We cluster the trajectories by clustering their feature vectors.We first compare and cluster the feature vectors according to their shape.Then we take a small uniform sample of points from each of the similarly-shaped trajectories to perform clustering according to their spatial locations.The resulting clusters contain similarly shaped trajectories that are located together.", "rank": 267, "paragraph_comparative_number": 5, "entities": [], "id": "p_267"}, "sentences": [{"end": 109714, "text": "In this chapter, we introduce an approach to cluster geospatial trajectories by using the kernel distance.", "rank": 1097, "start": 109608, "IsComparative": "0", "id": "st_1097"}, {"end": 109763, "text": "Figure 6.1 illustrates the steps of our approach.", "rank": 1098, "start": 109714, "IsComparative": "1", "id": "st_1098"}, {"end": 109880, "text": "Given trajectories input P and Q, the kernel distance framework projects each trajectory onto a randomly drawn i.i.d.", "rank": 1099, "start": 109763, "IsComparative": "0", "id": "st_1099"}, {"end": 109977, "text": "sample of points from a normal distribution, and obtain fixed-length feature vectors (P) and (Q).", "rank": 1100, "start": 109880, "IsComparative": "1", "id": "st_1100"}, {"end": 110041, "text": "We cluster the trajectories by clustering their feature vectors.", "rank": 1101, "start": 109977, "IsComparative": "1", "id": "st_1101"}, {"end": 110115, "text": "We first compare and cluster the feature vectors according to their shape.", "rank": 1102, "start": 110041, "IsComparative": "1", "id": "st_1102"}, {"end": 110267, "text": "Then we take a small uniform sample of points from each of the similarly-shaped trajectories to perform clustering according to their spatial locations.", "rank": 1103, "start": 110115, "IsComparative": "1", "id": "st_1103"}, {"end": 110354, "text": "The resulting clusters contain similarly shaped trajectories that are located together.", "rank": 1104, "start": 110267, "IsComparative": "0", "id": "st_1104"}]}, {"paragraph_info": {"end": 111245, "start": 110354, "text": "We present the details of our approach in the following sections.Section 6.3 reviews the theories and the process of transforming trajectories into feature vectors.Section 6.4 shows how to cluster the trajectories with the k-means algorithm.Section 6.5 shows our shape and spatial clustering procedure, and Section 6.6 describes how to update the feature vectors for incremental clustering in a streaming fashion.Section 6.7 show results of clustering trajectories with k-means.In addition to k-means, we show how to use com- munity detection algorithms with the approximate kernel distance framework to address some deficiencies of k-means.Section 6.9 show results of clustering trajectories with community detection.We present our performance and compare our results with exist- ing techniques in the literature in Section 6.10.We conclude with discussions and future work in Section 6.11.", "rank": 268, "paragraph_comparative_number": 4, "entities": [], "id": "p_268"}, "sentences": [{"end": 110419, "text": "We present the details of our approach in the following sections.", "rank": 1105, "start": 110354, "IsComparative": "1", "id": "st_1105"}, {"end": 110518, "text": "Section 6.3 reviews the theories and the process of transforming trajectories into feature vectors.", "rank": 1106, "start": 110419, "IsComparative": "1", "id": "st_1106"}, {"end": 110595, "text": "Section 6.4 shows how to cluster the trajectories with the k-means algorithm.", "rank": 1107, "start": 110518, "IsComparative": "0", "id": "st_1107"}, {"end": 110767, "text": "Section 6.5 shows our shape and spatial clustering procedure, and Section 6.6 describes how to update the feature vectors for incremental clustering in a streaming fashion.", "rank": 1108, "start": 110595, "IsComparative": "1", "id": "st_1108"}, {"end": 110832, "text": "Section 6.7 show results of clustering trajectories with k-means.", "rank": 1109, "start": 110767, "IsComparative": "0", "id": "st_1109"}, {"end": 110995, "text": "In addition to k-means, we show how to use com- munity detection algorithms with the approximate kernel distance framework to address some deficiencies of k-means.", "rank": 1110, "start": 110832, "IsComparative": "0", "id": "st_1110"}, {"end": 111072, "text": "Section 6.9 show results of clustering trajectories with community detection.", "rank": 1111, "start": 110995, "IsComparative": "0", "id": "st_1111"}, {"end": 111184, "text": "We present our performance and compare our results with exist- ing techniques in the literature in Section 6.10.", "rank": 1112, "start": 111072, "IsComparative": "1", "id": "st_1112"}, {"end": 111245, "text": "We conclude with discussions and future work in Section 6.11.", "rank": 1113, "start": 111184, "IsComparative": "0", "id": "st_1113"}]}, {"paragraph_info": {"end": 111276, "start": 111245, "text": "6.3 Approximate Kernel Distance", "rank": 269, "paragraph_comparative_number": 0, "entities": [], "id": "p_269"}, "sentences": [{"end": 111276, "text": "6.3 Approximate Kernel Distance", "rank": 1114, "start": 111245, "IsComparative": "0", "id": "st_1114"}]}, {"paragraph_info": {"end": 112265, "start": 111276, "text": "In this section, we define kernel distance and describe a well-known procedure to approximate it efficiently.In the context of this chapter, a kernel is symmetric similarity measure K : Rd  Rd  R+ between pairs of points in Rd .Nearby points have a larger similarity value than points further away.One popular kernel is the Gaussian kernel, K(p,q)  epq2/2.Given two point sets P and Q with n and m points, respectively, we define the similarity function (P,Q) and compute the kernel distance Dk(P,Q) as follows: ping offers a number of advantages.The linearity of dot products allows us to represent nonlinear shapes, such as trajectories, as a single feature vector, (P) = pP (p), and the kernel distance Dk (P, Q) = (P)  (Q) H (the Euclidean distance).In essence, the embedding linearizes the metric by mapping the input (nonlinear) space into a vector space.Therefore, kernel methods have been widely used in the machine learning litera- ture to recognize non-linear structures in data.", "rank": 270, "paragraph_comparative_number": 1, "entities": [], "id": "p_270"}, "sentences": [{"end": 111385, "text": "In this section, we define kernel distance and describe a well-known procedure to approximate it efficiently.", "rank": 1115, "start": 111276, "IsComparative": "0", "id": "st_1115"}, {"end": 111504, "text": "In the context of this chapter, a kernel is symmetric similarity measure K : Rd  Rd  R+ between pairs of points in Rd .", "rank": 1116, "start": 111385, "IsComparative": "0", "id": "st_1116"}, {"end": 111574, "text": "Nearby points have a larger similarity value than points further away.", "rank": 1117, "start": 111504, "IsComparative": "0", "id": "st_1117"}, {"end": 111632, "text": "One popular kernel is the Gaussian kernel, K(p,q)  epq2/2.", "rank": 1118, "start": 111574, "IsComparative": "0", "id": "st_1118"}, {"end": 111823, "text": "Given two point sets P and Q with n and m points, respectively, we define the similarity function (P,Q) and compute the kernel distance Dk(P,Q) as follows: ping offers a number of advantages.", "rank": 1119, "start": 111632, "IsComparative": "0", "id": "st_1119"}, {"end": 112030, "text": "The linearity of dot products allows us to represent nonlinear shapes, such as trajectories, as a single feature vector, (P) = pP (p), and the kernel distance Dk (P, Q) = (P)  (Q) H (the Euclidean distance).", "rank": 1120, "start": 111823, "IsComparative": "1", "id": "st_1120"}, {"end": 112137, "text": "In essence, the embedding linearizes the metric by mapping the input (nonlinear) space into a vector space.", "rank": 1121, "start": 112030, "IsComparative": "0", "id": "st_1121"}, {"end": 112265, "text": "Therefore, kernel methods have been widely used in the machine learning litera- ture to recognize non-linear structures in data.", "rank": 1122, "start": 112137, "IsComparative": "0", "id": "st_1122"}]}, {"paragraph_info": {"end": 112943, "start": 112265, "text": "The feature map, described above, is not readily usable for computational purposes since the feature space H is usually infinite dimensional.However, it is often possi- ble to construct a -dimensional feature map that approximates the kernel sufficiently well.Rahimi and Recht <130> address this problem for shift-invariant kernels (where K(p,q) = k(pq)).Their randomized Fourier feature map is based on Bochners theo- rem which states that for properly scaled shift-invariant kernel, its Fourier transform g() is a proper probability distribution.If (p) = ejT p, Rahimi and Recht <130> showed that (p)(q) is an unbiased estimator of k(pq) when  is drawn from g.In par- ticular,", "rank": 271, "paragraph_comparative_number": 2, "entities": [], "id": "p_271"}, "sentences": [{"end": 112406, "text": "The feature map, described above, is not readily usable for computational purposes since the feature space H is usually infinite dimensional.", "rank": 1123, "start": 112265, "IsComparative": "0", "id": "st_1123"}, {"end": 112525, "text": "However, it is often possi- ble to construct a -dimensional feature map that approximates the kernel sufficiently well.", "rank": 1124, "start": 112406, "IsComparative": "0", "id": "st_1124"}, {"end": 112620, "text": "Rahimi and Recht <130> address this problem for shift-invariant kernels (where K(p,q) = k(pq)).", "rank": 1125, "start": 112525, "IsComparative": "1", "id": "st_1125"}, {"end": 112813, "text": "Their randomized Fourier feature map is based on Bochners theo- rem which states that for properly scaled shift-invariant kernel, its Fourier transform g() is a proper probability distribution.", "rank": 1126, "start": 112620, "IsComparative": "1", "id": "st_1126"}, {"end": 112927, "text": "If (p) = ejT p, Rahimi and Recht <130> showed that (p)(q) is an unbiased estimator of k(pq) when  is drawn from g.", "rank": 1127, "start": 112813, "IsComparative": "0", "id": "st_1127"}, {"end": 112943, "text": "In par- ticular,", "rank": 1128, "start": 112927, "IsComparative": "0", "id": "st_1128"}]}, {"paragraph_info": {"end": 113191, "start": 112943, "text": "In this chapter, we use the Gaussian kernel in all our computations.Since it is a shift-invariant kernel, we can use the randomized Fourier feature approach to perform the embedding.For this kernel, we sample the  vector from a normal distribution.", "rank": 272, "paragraph_comparative_number": 1, "entities": [], "id": "p_272"}, "sentences": [{"end": 113011, "text": "In this chapter, we use the Gaussian kernel in all our computations.", "rank": 1129, "start": 112943, "IsComparative": "1", "id": "st_1129"}, {"end": 113125, "text": "Since it is a shift-invariant kernel, we can use the randomized Fourier feature approach to perform the embedding.", "rank": 1130, "start": 113011, "IsComparative": "0", "id": "st_1130"}, {"end": 113191, "text": "For this kernel, we sample the  vector from a normal distribution.", "rank": 1131, "start": 113125, "IsComparative": "0", "id": "st_1131"}]}, {"paragraph_info": {"end": 113245, "start": 113191, "text": "6.3.1 Clustering Trajectories with the Kernel Distance", "rank": 273, "paragraph_comparative_number": 0, "entities": [], "id": "p_273"}, "sentences": [{"end": 113245, "text": "6.3.1 Clustering Trajectories with the Kernel Distance", "rank": 1132, "start": 113191, "IsComparative": "0", "id": "st_1132"}]}, {"paragraph_info": {"end": 113518, "start": 113245, "text": "We can cluster trajectories with the kernel distance by clustering their feature vec- tors with existing Euclidean clustering algorithms.(P,Q) can be computed efficiently by a dot product of the approximated feature vectors of   (P) and   (Q), where   (P) =  p  P   ( p ) ,", "rank": 274, "paragraph_comparative_number": 2, "entities": [], "id": "p_274"}, "sentences": [{"end": 113382, "text": "We can cluster trajectories with the kernel distance by clustering their feature vec- tors with existing Euclidean clustering algorithms.", "rank": 1133, "start": 113245, "IsComparative": "1", "id": "st_1133"}, {"end": 113518, "text": "(P,Q) can be computed efficiently by a dot product of the approximated feature vectors of   (P) and   (Q), where   (P) =  p  P   ( p ) ,", "rank": 1134, "start": 113382, "IsComparative": "1", "id": "st_1134"}]}, {"paragraph_info": {"end": 113983, "start": 113518, "text": "In light of the above identity, it is not difficult to see that the Euclidean distance of feature vectors,   (P) and   (Q), yields the kernel distance between the two trajec- tories <75>.We can perform kernel-distance-based clustering of trajectories by using a wealth of Euclidean clustering algorithms.Furthermore, these feature vectors only have to be computed once for many repeated distance calculations.This is extremely efficient for clustering applications.", "rank": 275, "paragraph_comparative_number": 2, "entities": [], "id": "p_275"}, "sentences": [{"end": 113705, "text": "In light of the above identity, it is not difficult to see that the Euclidean distance of feature vectors,   (P) and   (Q), yields the kernel distance between the two trajec- tories <75>.", "rank": 1135, "start": 113518, "IsComparative": "1", "id": "st_1135"}, {"end": 113822, "text": "We can perform kernel-distance-based clustering of trajectories by using a wealth of Euclidean clustering algorithms.", "rank": 1136, "start": 113705, "IsComparative": "1", "id": "st_1136"}, {"end": 113927, "text": "Furthermore, these feature vectors only have to be computed once for many repeated distance calculations.", "rank": 1137, "start": 113822, "IsComparative": "0", "id": "st_1137"}, {"end": 113983, "text": "This is extremely efficient for clustering applications.", "rank": 1138, "start": 113927, "IsComparative": "0", "id": "st_1138"}]}, {"paragraph_info": {"end": 114515, "start": 113983, "text": "We model the continuity of the trajectories by adding the velocity to the trajectory points.We compute the discrete differences of points (dx,dy) in a trajectory and represent each point by a 4D vector (x,y,dx,dy), where x,y represent the point location, and dx,dy represent the velocity.Note that the dimensionality of embedding, , or the running time of the kernel distance approximation does not depend on the dimension of the trajectory points.The extra attributes do not incur any overhead after the kernel transform operation.", "rank": 276, "paragraph_comparative_number": 2, "entities": [], "id": "p_276"}, "sentences": [{"end": 114075, "text": "We model the continuity of the trajectories by adding the velocity to the trajectory points.", "rank": 1139, "start": 113983, "IsComparative": "1", "id": "st_1139"}, {"end": 114271, "text": "We compute the discrete differences of points (dx,dy) in a trajectory and represent each point by a 4D vector (x,y,dx,dy), where x,y represent the point location, and dx,dy represent the velocity.", "rank": 1140, "start": 114075, "IsComparative": "0", "id": "st_1140"}, {"end": 114431, "text": "Note that the dimensionality of embedding, , or the running time of the kernel distance approximation does not depend on the dimension of the trajectory points.", "rank": 1141, "start": 114271, "IsComparative": "1", "id": "st_1141"}, {"end": 114515, "text": "The extra attributes do not incur any overhead after the kernel transform operation.", "rank": 1142, "start": 114431, "IsComparative": "0", "id": "st_1142"}]}, {"paragraph_info": {"end": 114563, "start": 114515, "text": "6.3.2 Evaluating the Approximate Kernel Distance", "rank": 277, "paragraph_comparative_number": 0, "entities": [], "id": "p_277"}, "sentences": [{"end": 114563, "text": "6.3.2 Evaluating the Approximate Kernel Distance", "rank": 1143, "start": 114515, "IsComparative": "0", "id": "st_1143"}]}, {"paragraph_info": {"end": 115064, "start": 114563, "text": "In our approach we use the kernel distance that compares the trajectories by com- puting a Gaussian-weighted sum of differences between all pairs of points in the two trajectories.The exact kernel distance is computed as in Equation (2) with the Gaus- sian kernel.For the approximate kernel distance computation we use  = 0.2, = 0.2 for all the experiments in this chapter.Figure 6.2 shows the error distribution and the performance of the approximate kernel distance versus the exact kernel distance.", "rank": 278, "paragraph_comparative_number": 2, "entities": [], "id": "p_278"}, "sentences": [{"end": 114743, "text": "In our approach we use the kernel distance that compares the trajectories by com- puting a Gaussian-weighted sum of differences between all pairs of points in the two trajectories.", "rank": 1144, "start": 114563, "IsComparative": "1", "id": "st_1144"}, {"end": 114827, "text": "The exact kernel distance is computed as in Equation (2) with the Gaus- sian kernel.", "rank": 1145, "start": 114743, "IsComparative": "0", "id": "st_1145"}, {"end": 114936, "text": "For the approximate kernel distance computation we use  = 0.2, = 0.2 for all the experiments in this chapter.", "rank": 1146, "start": 114827, "IsComparative": "0", "id": "st_1146"}, {"end": 115064, "text": "Figure 6.2 shows the error distribution and the performance of the approximate kernel distance versus the exact kernel distance.", "rank": 1147, "start": 114936, "IsComparative": "1", "id": "st_1147"}]}, {"paragraph_info": {"end": 115466, "start": 115064, "text": "The error plot, shown in Figure 6.2(a), is generated by comparing 100 real air traffic trajectories sampled from our dataset.Notice that the error of the approximate kernel distances is very low for similar trajectories, which is important for building clusters.The error grows only as the distance increases.The root mean square error is about 5% showing that the quality of the approximation is high.", "rank": 279, "paragraph_comparative_number": 1, "entities": [], "id": "p_279"}, "sentences": [{"end": 115189, "text": "The error plot, shown in Figure 6.2(a), is generated by comparing 100 real air traffic trajectories sampled from our dataset.", "rank": 1148, "start": 115064, "IsComparative": "0", "id": "st_1148"}, {"end": 115326, "text": "Notice that the error of the approximate kernel distances is very low for similar trajectories, which is important for building clusters.", "rank": 1149, "start": 115189, "IsComparative": "1", "id": "st_1149"}, {"end": 115373, "text": "The error grows only as the distance increases.", "rank": 1150, "start": 115326, "IsComparative": "0", "id": "st_1150"}, {"end": 115466, "text": "The root mean square error is about 5% showing that the quality of the approximation is high.", "rank": 1151, "start": 115373, "IsComparative": "0", "id": "st_1151"}]}, {"paragraph_info": {"end": 115750, "start": 115466, "text": "The performance plot, Figure 6.2(b), is generated by comparing random trajectories of size n as shown on the x-axis.The running time for computing the exact kernel distance scales up quadratically, while the running time for computing the approximate kernel distance is almost linear.", "rank": 280, "paragraph_comparative_number": 0, "entities": [], "id": "p_280"}, "sentences": [{"end": 115582, "text": "The performance plot, Figure 6.2(b), is generated by comparing random trajectories of size n as shown on the x-axis.", "rank": 1152, "start": 115466, "IsComparative": "0", "id": "st_1152"}, {"end": 115750, "text": "The running time for computing the exact kernel distance scales up quadratically, while the running time for computing the approximate kernel distance is almost linear.", "rank": 1153, "start": 115582, "IsComparative": "0", "id": "st_1153"}]}, {"paragraph_info": {"end": 115793, "start": 115750, "text": "6.4 Clustering Feature Vectors with k-means", "rank": 281, "paragraph_comparative_number": 1, "entities": [], "id": "p_281"}, "sentences": [{"end": 115793, "text": "6.4 Clustering Feature Vectors with k-means", "rank": 1154, "start": 115750, "IsComparative": "1", "id": "st_1154"}]}, {"paragraph_info": {"end": 116129, "start": 115793, "text": "This approximate kernel distance approach can be directly used with a member of off-the-shelf clustering algorithms.We use synthetic examples to show the distribution of the high-dimensional feature points.We first generate clusters of synthetic trajectories, project them onto the high-dimensional feature space, and then cluster them.", "rank": 282, "paragraph_comparative_number": 1, "entities": [], "id": "p_282"}, "sentences": [{"end": 115909, "text": "This approximate kernel distance approach can be directly used with a member of off-the-shelf clustering algorithms.", "rank": 1155, "start": 115793, "IsComparative": "0", "id": "st_1155"}, {"end": 115999, "text": "We use synthetic examples to show the distribution of the high-dimensional feature points.", "rank": 1156, "start": 115909, "IsComparative": "1", "id": "st_1156"}, {"end": 116129, "text": "We first generate clusters of synthetic trajectories, project them onto the high-dimensional feature space, and then cluster them.", "rank": 1157, "start": 115999, "IsComparative": "0", "id": "st_1157"}]}, {"paragraph_info": {"end": 116446, "start": 116129, "text": "We use the midpoint displacement algorithm from fractal generation <109> to create trajectories of different shapes.For each trajectory, we rotate and translate it to create clusters of minor variations.These varying trajectories form clusters for our experiments.Figure 6.3(a) shows an example of these trajectories.", "rank": 283, "paragraph_comparative_number": 2, "entities": [], "id": "p_283"}, "sentences": [{"end": 116245, "text": "We use the midpoint displacement algorithm from fractal generation <109> to create trajectories of different shapes.", "rank": 1158, "start": 116129, "IsComparative": "1", "id": "st_1158"}, {"end": 116332, "text": "For each trajectory, we rotate and translate it to create clusters of minor variations.", "rank": 1159, "start": 116245, "IsComparative": "0", "id": "st_1159"}, {"end": 116393, "text": "These varying trajectories form clusters for our experiments.", "rank": 1160, "start": 116332, "IsComparative": "1", "id": "st_1160"}, {"end": 116446, "text": "Figure 6.3(a) shows an example of these trajectories.", "rank": 1161, "start": 116393, "IsComparative": "0", "id": "st_1161"}]}, {"paragraph_info": {"end": 116721, "start": 116446, "text": "We project these trajectories onto a set of random basis as described in Section 6.3.In Figure 6.3(b), we visualize the distribution of the high-dimensional feature points by projecting them onto the first two principal components from the principal component analysis (PCA).", "rank": 284, "paragraph_comparative_number": 1, "entities": [], "id": "p_284"}, "sentences": [{"end": 116531, "text": "We project these trajectories onto a set of random basis as described in Section 6.3.", "rank": 1162, "start": 116446, "IsComparative": "0", "id": "st_1162"}, {"end": 116721, "text": "In Figure 6.3(b), we visualize the distribution of the high-dimensional feature points by projecting them onto the first two principal components from the principal component analysis (PCA).", "rank": 1163, "start": 116531, "IsComparative": "1", "id": "st_1163"}]}, {"paragraph_info": {"end": 117081, "start": 116721, "text": "In Figure 6.3(c), we visualize the approximate kernel distance among the synthetic trajectories by a distance matrix, where low distances are in blue and high distances are in red.The matrix is sorted in the order of the clusters; the distances should ideally be low around the diagonal (same cluster) and high around off diagonal regions (different clusters).", "rank": 285, "paragraph_comparative_number": 0, "entities": [], "id": "p_285"}, "sentences": [{"end": 116901, "text": "In Figure 6.3(c), we visualize the approximate kernel distance among the synthetic trajectories by a distance matrix, where low distances are in blue and high distances are in red.", "rank": 1164, "start": 116721, "IsComparative": "0", "id": "st_1164"}, {"end": 117081, "text": "The matrix is sorted in the order of the clusters; the distances should ideally be low around the diagonal (same cluster) and high around off diagonal regions (different clusters).", "rank": 1165, "start": 116901, "IsComparative": "0", "id": "st_1165"}]}, {"paragraph_info": {"end": 117281, "start": 117081, "text": "Datasets with good separations such as the presented example can be effectively clustered by a simple clustering algorithm, such as the k-means.Results of k-means clustering is shown in Figure 6.3(d).", "rank": 286, "paragraph_comparative_number": 0, "entities": [], "id": "p_286"}, "sentences": [{"end": 117225, "text": "Datasets with good separations such as the presented example can be effectively clustered by a simple clustering algorithm, such as the k-means.", "rank": 1166, "start": 117081, "IsComparative": "0", "id": "st_1166"}, {"end": 117281, "text": "Results of k-means clustering is shown in Figure 6.3(d).", "rank": 1167, "start": 117225, "IsComparative": "0", "id": "st_1167"}]}, {"paragraph_info": {"end": 117648, "start": 117281, "text": "Figure 6.4 shows k-means clustering of 2000 air traffic trajectories with the kernel distance approach.It identifies clusters around the hub airports.However, some of the clusters produced by this naive k-means approach contain disconnected components on this real dataset.We next discuss how to address this issue by shape and spatial clustering of the trajectories.", "rank": 287, "paragraph_comparative_number": 1, "entities": [], "id": "p_287"}, "sentences": [{"end": 117384, "text": "Figure 6.4 shows k-means clustering of 2000 air traffic trajectories with the kernel distance approach.", "rank": 1168, "start": 117281, "IsComparative": "0", "id": "st_1168"}, {"end": 117431, "text": "It identifies clusters around the hub airports.", "rank": 1169, "start": 117384, "IsComparative": "0", "id": "st_1169"}, {"end": 117554, "text": "However, some of the clusters produced by this naive k-means approach contain disconnected components on this real dataset.", "rank": 1170, "start": 117431, "IsComparative": "0", "id": "st_1170"}, {"end": 117648, "text": "We next discuss how to address this issue by shape and spatial clustering of the trajectories.", "rank": 1171, "start": 117554, "IsComparative": "1", "id": "st_1171"}]}, {"paragraph_info": {"end": 117696, "start": 117648, "text": "6.5 Shape and Spatial Clustering of Trajectories", "rank": 288, "paragraph_comparative_number": 0, "entities": [], "id": "p_288"}, "sentences": [{"end": 117696, "text": "6.5 Shape and Spatial Clustering of Trajectories", "rank": 1172, "start": 117648, "IsComparative": "0", "id": "st_1172"}]}, {"paragraph_info": {"end": 118045, "start": 117696, "text": "We introduce a two-step procedure to cluster the shapes and the locations of the trajectories.The shape step leverages the shape matching abilities of the kernel distance framework and the spatial step ensures the disjointed clusters are separated.We construct and cluster the shape and spatial feature vectors of the trajectories as in Procedure 2.", "rank": 289, "paragraph_comparative_number": 1, "entities": [], "id": "p_289"}, "sentences": [{"end": 117790, "text": "We introduce a two-step procedure to cluster the shapes and the locations of the trajectories.", "rank": 1173, "start": 117696, "IsComparative": "0", "id": "st_1173"}, {"end": 117944, "text": "The shape step leverages the shape matching abilities of the kernel distance framework and the spatial step ensures the disjointed clusters are separated.", "rank": 1174, "start": 117790, "IsComparative": "0", "id": "st_1174"}, {"end": 118045, "text": "We construct and cluster the shape and spatial feature vectors of the trajectories as in Procedure 2.", "rank": 1175, "start": 117944, "IsComparative": "1", "id": "st_1175"}]}, {"paragraph_info": {"end": 118339, "start": 118045, "text": "T is a set containing N trajectories P1,...,PN.s and l are the desired numbers of shape and spatial clusters.C is a set of cluster labels for each trajectory.VS and VL are the shape and spatial feature vectors for clustering.For notational ease, we assume there are n points in each trajectory.", "rank": 290, "paragraph_comparative_number": 1, "entities": [], "id": "p_290"}, "sentences": [{"end": 118092, "text": "T is a set containing N trajectories P1,...,PN.", "rank": 1176, "start": 118045, "IsComparative": "0", "id": "st_1176"}, {"end": 118154, "text": "s and l are the desired numbers of shape and spatial clusters.", "rank": 1177, "start": 118092, "IsComparative": "0", "id": "st_1177"}, {"end": 118203, "text": "C is a set of cluster labels for each trajectory.", "rank": 1178, "start": 118154, "IsComparative": "0", "id": "st_1178"}, {"end": 118270, "text": "VS and VL are the shape and spatial feature vectors for clustering.", "rank": 1179, "start": 118203, "IsComparative": "1", "id": "st_1179"}, {"end": 118339, "text": "For notational ease, we assume there are n points in each trajectory.", "rank": 1180, "start": 118270, "IsComparative": "0", "id": "st_1180"}]}, {"paragraph_info": {"end": 118376, "start": 118339, "text": "6.6 Incremental and Stream Processing", "rank": 291, "paragraph_comparative_number": 0, "entities": [], "id": "p_291"}, "sentences": [{"end": 118376, "text": "6.6 Incremental and Stream Processing", "rank": 1181, "start": 118339, "IsComparative": "0", "id": "st_1181"}]}, {"paragraph_info": {"end": 118947, "start": 118376, "text": "Clustering trajectories with the kernel distance can be performed in an incremen- tal and/or streaming fashion.The summation nature of the feature vectors   (P) allow us to update them incrementally.In addition, since there is no need to store the raw trajectory locations after updating the feature vectors, this approach is also suitable for stream processing.Incremental and stream processing of trajectories is highly desirable for geospatial applications because new locations are continuously reported as tracked entities such as people, animals, and vehicles move.", "rank": 292, "paragraph_comparative_number": 2, "entities": [], "id": "p_292"}, "sentences": [{"end": 118487, "text": "Clustering trajectories with the kernel distance can be performed in an incremen- tal and/or streaming fashion.", "rank": 1182, "start": 118376, "IsComparative": "0", "id": "st_1182"}, {"end": 118575, "text": "The summation nature of the feature vectors   (P) allow us to update them incrementally.", "rank": 1183, "start": 118487, "IsComparative": "1", "id": "st_1183"}, {"end": 118738, "text": "In addition, since there is no need to store the raw trajectory locations after updating the feature vectors, this approach is also suitable for stream processing.", "rank": 1184, "start": 118575, "IsComparative": "1", "id": "st_1184"}, {"end": 118947, "text": "Incremental and stream processing of trajectories is highly desirable for geospatial applications because new locations are continuously reported as tracked entities such as people, animals, and vehicles move.", "rank": 1185, "start": 118738, "IsComparative": "0", "id": "st_1185"}]}, {"paragraph_info": {"end": 119675, "start": 118947, "text": "We update the feature vectors and clusters as discussed in Procedure 3.P = <P1PN> is the newly arrived set of trajectory points at timestep t. Vt1 and Ct1 are the sets of feature vectors and cluster labels from the previous timestep t  1.We compute a feature vector,   (Pt ), for trajectory P at time t by computing a weighted sum of the feature vector of the new points,   (P), and the feature vector of the trajectory at t  1,   (Pt1).We assign the weights, wt and wt1, in proportion to the number of points represented by   (P) and   (Pt1).If there is any new trajectory, we assign it to its closest cluster.We seed the k-means clustering procedure with cluster assignments of the previous timestep to accelerate convergence.", "rank": 293, "paragraph_comparative_number": 3, "entities": [], "id": "p_293"}, "sentences": [{"end": 119018, "text": "We update the feature vectors and clusters as discussed in Procedure 3.", "rank": 1186, "start": 118947, "IsComparative": "0", "id": "st_1186"}, {"end": 119185, "text": "P = <P1PN> is the newly arrived set of trajectory points at timestep t. Vt1 and Ct1 are the sets of feature vectors and cluster labels from the previous timestep t  1.", "rank": 1187, "start": 119018, "IsComparative": "0", "id": "st_1187"}, {"end": 119384, "text": "We compute a feature vector,   (Pt ), for trajectory P at time t by computing a weighted sum of the feature vector of the new points,   (P), and the feature vector of the trajectory at t  1,   (Pt1).", "rank": 1188, "start": 119185, "IsComparative": "1", "id": "st_1188"}, {"end": 119490, "text": "We assign the weights, wt and wt1, in proportion to the number of points represented by   (P) and   (Pt1).", "rank": 1189, "start": 119384, "IsComparative": "0", "id": "st_1189"}, {"end": 119558, "text": "If there is any new trajectory, we assign it to its closest cluster.", "rank": 1190, "start": 119490, "IsComparative": "1", "id": "st_1190"}, {"end": 119675, "text": "We seed the k-means clustering procedure with cluster assignments of the previous timestep to accelerate convergence.", "rank": 1191, "start": 119558, "IsComparative": "1", "id": "st_1191"}]}, {"paragraph_info": {"end": 119710, "start": 119675, "text": "6.7 Results with k-means Clustering", "rank": 294, "paragraph_comparative_number": 0, "entities": [], "id": "p_294"}, "sentences": [{"end": 119710, "text": "6.7 Results with k-means Clustering", "rank": 1192, "start": 119675, "IsComparative": "0", "id": "st_1192"}]}, {"paragraph_info": {"end": 120060, "start": 119710, "text": "We have validated our approach by using two very large datasets (1) air-traffic over the continental United States, and (2) vehicular traffic in an urban environment.Our application datasets of air-traffic (2M points) and taxis (11M points) are significantly larger than the data used in the previous work (100K points <98>) on trajectory clustering.", "rank": 295, "paragraph_comparative_number": 2, "entities": [], "id": "p_295"}, "sentences": [{"end": 119876, "text": "We have validated our approach by using two very large datasets (1) air-traffic over the continental United States, and (2) vehicular traffic in an urban environment.", "rank": 1193, "start": 119710, "IsComparative": "1", "id": "st_1193"}, {"end": 120060, "text": "Our application datasets of air-traffic (2M points) and taxis (11M points) are significantly larger than the data used in the previous work (100K points <98>) on trajectory clustering.", "rank": 1194, "start": 119876, "IsComparative": "1", "id": "st_1194"}]}, {"paragraph_info": {"end": 120384, "start": 120060, "text": "Experimental Platform We have performed all our experiments on a PC with an Intel Xeon 5140 2.5 GHz processor and 4 GB of memory.Our software was implemented on the Linux platform with Python and the Numpy numerical package for computing the kernel transform and the Pycluster <27> package for performing k-means clustering.", "rank": 296, "paragraph_comparative_number": 1, "entities": [], "id": "p_296"}, "sentences": [{"end": 120189, "text": "Experimental Platform We have performed all our experiments on a PC with an Intel Xeon 5140 2.5 GHz processor and 4 GB of memory.", "rank": 1195, "start": 120060, "IsComparative": "1", "id": "st_1195"}, {"end": 120384, "text": "Our software was implemented on the Linux platform with Python and the Numpy numerical package for computing the kernel transform and the Pycluster <27> package for performing k-means clustering.", "rank": 1196, "start": 120189, "IsComparative": "0", "id": "st_1196"}]}, {"paragraph_info": {"end": 121244, "start": 120384, "text": "Figure 6.6: San Francisco Taxi: (a) shows all of the 464 K taxi trajectories.(b) to (f) show the top clusters produced by our algorithm.(b) shows traffic in Northeastern San Francisco with connections to Oakland and Berkeley.(c) shows the traffic that passes the 101 highway with a cluster at San Mateo.The line pattern in (c) is due to faulty GPS data, however it does not affect our results, this shows our approach is reasonably robust to noise.(d) shows the traffic in downtown and Southern San Francisco.(e) shows a popular loop that connects the downtown to the San Francisco Airport.(f) shows the traffic in Western San Francisco.We adjust the transparency of the trajectories to visualize their relative densities in each figure, since (a) is dominated by clusters (b) and (d), some detailed patterns in the small cluster (c) may not be visible in (a).", "rank": 297, "paragraph_comparative_number": 4, "entities": [], "id": "p_297"}, "sentences": [{"end": 120461, "text": "Figure 6.6: San Francisco Taxi: (a) shows all of the 464 K taxi trajectories.", "rank": 1197, "start": 120384, "IsComparative": "0", "id": "st_1197"}, {"end": 120520, "text": "(b) to (f) show the top clusters produced by our algorithm.", "rank": 1198, "start": 120461, "IsComparative": "1", "id": "st_1198"}, {"end": 120609, "text": "(b) shows traffic in Northeastern San Francisco with connections to Oakland and Berkeley.", "rank": 1199, "start": 120520, "IsComparative": "1", "id": "st_1199"}, {"end": 120687, "text": "(c) shows the traffic that passes the 101 highway with a cluster at San Mateo.", "rank": 1200, "start": 120609, "IsComparative": "1", "id": "st_1200"}, {"end": 120832, "text": "The line pattern in (c) is due to faulty GPS data, however it does not affect our results, this shows our approach is reasonably robust to noise.", "rank": 1201, "start": 120687, "IsComparative": "1", "id": "st_1201"}, {"end": 120893, "text": "(d) shows the traffic in downtown and Southern San Francisco.", "rank": 1202, "start": 120832, "IsComparative": "0", "id": "st_1202"}, {"end": 120974, "text": "(e) shows a popular loop that connects the downtown to the San Francisco Airport.", "rank": 1203, "start": 120893, "IsComparative": "0", "id": "st_1203"}, {"end": 121021, "text": "(f) shows the traffic in Western San Francisco.", "rank": 1204, "start": 120974, "IsComparative": "0", "id": "st_1204"}, {"end": 121244, "text": "We adjust the transparency of the trajectories to visualize their relative densities in each figure, since (a) is dominated by clusters (b) and (d), some detailed patterns in the small cluster (c) may not be visible in (a).", "rank": 1205, "start": 121021, "IsComparative": "0", "id": "st_1205"}]}, {"paragraph_info": {"end": 121272, "start": 121244, "text": "6.7.1 US Air Traffic Dataset", "rank": 298, "paragraph_comparative_number": 0, "entities": [], "id": "p_298"}, "sentences": [{"end": 121272, "text": "6.7.1 US Air Traffic Dataset", "rank": 1206, "start": 121244, "IsComparative": "0", "id": "st_1206"}]}, {"paragraph_info": {"end": 121780, "start": 121272, "text": "The GE FlightQuest <41> dataset consists of a whole day of airplane flight trajec- tories over the United States airspace.There are a total of 24,843 flight tracks with well over two million GPS points.Clustering air traffic data helps us to understand the airspace usage and see patterns among flight routes.This is important for air traffic planners and authorities to improve the flight schedules, plan new routes, develop plans for avoiding congestion, and to keep air transportation flowing efficiently.", "rank": 299, "paragraph_comparative_number": 0, "entities": [], "id": "p_299"}, "sentences": [{"end": 121394, "text": "The GE FlightQuest <41> dataset consists of a whole day of airplane flight trajec- tories over the United States airspace.", "rank": 1207, "start": 121272, "IsComparative": "0", "id": "st_1207"}, {"end": 121474, "text": "There are a total of 24,843 flight tracks with well over two million GPS points.", "rank": 1208, "start": 121394, "IsComparative": "0", "id": "st_1208"}, {"end": 121581, "text": "Clustering air traffic data helps us to understand the airspace usage and see patterns among flight routes.", "rank": 1209, "start": 121474, "IsComparative": "0", "id": "st_1209"}, {"end": 121780, "text": "This is important for air traffic planners and authorities to improve the flight schedules, plan new routes, develop plans for avoiding congestion, and to keep air transportation flowing efficiently.", "rank": 1210, "start": 121581, "IsComparative": "0", "id": "st_1210"}]}, {"paragraph_info": {"end": 122684, "start": 121780, "text": "We use our shape and spatial clustering approach to cluster the flight trajectories 93 with s = 5 and l = 7.We first cluster the flight trajectories into different orientations then cluster them according to their locations.Figure 6.5(a) shows all 24K flight trajecto- ries.Figures 6.5(b)-(f) show the five shape clusters.The colors show the spatial clusters of the flights.As can be clearly seen, four of the five shape clusters separate North to South flight trajectories (Figure 6.5(b)), East to West flights (Figure 6.5(c)), Northeast to Southwest flights (Figure 6.5(d)), and Southeast to Northwest flights (Figure 6.5(e)).Figure 6.5(f) interestingly groups short flights in star-shaped clusters from popular hub airports, including Seattle and San Francisco in the West, Denver in the North, Dallas, Atlanta, and Miami in the South, and a host of airports from Washington, DC to Boston in the East.", "rank": 300, "paragraph_comparative_number": 3, "entities": [], "id": "p_300"}, "sentences": [{"end": 121888, "text": "We use our shape and spatial clustering approach to cluster the flight trajectories 93 with s = 5 and l = 7.", "rank": 1211, "start": 121780, "IsComparative": "1", "id": "st_1211"}, {"end": 122004, "text": "We first cluster the flight trajectories into different orientations then cluster them according to their locations.", "rank": 1212, "start": 121888, "IsComparative": "1", "id": "st_1212"}, {"end": 122054, "text": "Figure 6.5(a) shows all 24K flight trajecto- ries.", "rank": 1213, "start": 122004, "IsComparative": "0", "id": "st_1213"}, {"end": 122102, "text": "Figures 6.5(b)-(f) show the five shape clusters.", "rank": 1214, "start": 122054, "IsComparative": "0", "id": "st_1214"}, {"end": 122154, "text": "The colors show the spatial clusters of the flights.", "rank": 1215, "start": 122102, "IsComparative": "0", "id": "st_1215"}, {"end": 122408, "text": "As can be clearly seen, four of the five shape clusters separate North to South flight trajectories (Figure 6.5(b)), East to West flights (Figure 6.5(c)), Northeast to Southwest flights (Figure 6.5(d)), and Southeast to Northwest flights (Figure 6.5(e)).", "rank": 1216, "start": 122154, "IsComparative": "0", "id": "st_1216"}, {"end": 122684, "text": "Figure 6.5(f) interestingly groups short flights in star-shaped clusters from popular hub airports, including Seattle and San Francisco in the West, Denver in the North, Dallas, Atlanta, and Miami in the South, and a host of airports from Washington, DC to Boston in the East.", "rank": 1217, "start": 122408, "IsComparative": "1", "id": "st_1217"}]}, {"paragraph_info": {"end": 122716, "start": 122684, "text": "6.7.2 San Francisco Taxi Dataset", "rank": 301, "paragraph_comparative_number": 0, "entities": [], "id": "p_301"}, "sentences": [{"end": 122716, "text": "6.7.2 San Francisco Taxi Dataset", "rank": 1218, "start": 122684, "IsComparative": "0", "id": "st_1218"}]}, {"paragraph_info": {"end": 123451, "start": 122716, "text": "This dataset consists of a few weeks of taxi trajectories in San Francisco.There are a total of 464,000 trajectories and 11 million GPS locations.These taxi trajectories represent taxi routes while under hire by a passenger.Understanding traffic patterns is important for urban planning and road maintenance.Since the taxis can move freely in an urban environment, their trajectories are very different from the planned straight flight paths and the smoothly-curved hurricane tracks.The high variations amongst trajectories makes this a very challenging dataset.The taxi data is provided by cabspotting.org and has been collected by EPFL for studying mobile wireless networks <127>.It is avail- able from the CRAWDAD <91> data archive.", "rank": 302, "paragraph_comparative_number": 4, "entities": [], "id": "p_302"}, "sentences": [{"end": 122791, "text": "This dataset consists of a few weeks of taxi trajectories in San Francisco.", "rank": 1219, "start": 122716, "IsComparative": "0", "id": "st_1219"}, {"end": 122862, "text": "There are a total of 464,000 trajectories and 11 million GPS locations.", "rank": 1220, "start": 122791, "IsComparative": "1", "id": "st_1220"}, {"end": 122940, "text": "These taxi trajectories represent taxi routes while under hire by a passenger.", "rank": 1221, "start": 122862, "IsComparative": "0", "id": "st_1221"}, {"end": 123024, "text": "Understanding traffic patterns is important for urban planning and road maintenance.", "rank": 1222, "start": 122940, "IsComparative": "0", "id": "st_1222"}, {"end": 123199, "text": "Since the taxis can move freely in an urban environment, their trajectories are very different from the planned straight flight paths and the smoothly-curved hurricane tracks.", "rank": 1223, "start": 123024, "IsComparative": "1", "id": "st_1223"}, {"end": 123278, "text": "The high variations amongst trajectories makes this a very challenging dataset.", "rank": 1224, "start": 123199, "IsComparative": "0", "id": "st_1224"}, {"end": 123398, "text": "The taxi data is provided by cabspotting.org and has been collected by EPFL for studying mobile wireless networks <127>.", "rank": 1225, "start": 123278, "IsComparative": "1", "id": "st_1225"}, {"end": 123451, "text": "It is avail- able from the CRAWDAD <91> data archive.", "rank": 1226, "start": 123398, "IsComparative": "1", "id": "st_1226"}]}, {"paragraph_info": {"end": 123969, "start": 123451, "text": "We cluster this taxi dataset by using our incremental clustering approach with the kernel distance.We use the k-means algorithm to directly cluster the feature vectors of the taxi trajectories into five clusters.Figure 6.6(a) shows all 424K taxi trajectories.Figure 6.6(b) shows a cluster of Northeast San Francisco with connections to Oakland and Berkeley.Figure 6.6 (c) shows the 101 highway and a cluster at San Mateo.Figure 6.6(d) shows a cluster of traffic at Central and South San Francisco.Figure 6.6(e) shows a", "rank": 303, "paragraph_comparative_number": 4, "entities": [], "id": "p_303"}, "sentences": [{"end": 123550, "text": "We cluster this taxi dataset by using our incremental clustering approach with the kernel distance.", "rank": 1227, "start": 123451, "IsComparative": "1", "id": "st_1227"}, {"end": 123663, "text": "We use the k-means algorithm to directly cluster the feature vectors of the taxi trajectories into five clusters.", "rank": 1228, "start": 123550, "IsComparative": "1", "id": "st_1228"}, {"end": 123710, "text": "Figure 6.6(a) shows all 424K taxi trajectories.", "rank": 1229, "start": 123663, "IsComparative": "0", "id": "st_1229"}, {"end": 123808, "text": "Figure 6.6(b) shows a cluster of Northeast San Francisco with connections to Oakland and Berkeley.", "rank": 1230, "start": 123710, "IsComparative": "1", "id": "st_1230"}, {"end": 123872, "text": "Figure 6.6 (c) shows the 101 highway and a cluster at San Mateo.", "rank": 1231, "start": 123808, "IsComparative": "1", "id": "st_1231"}, {"end": 123948, "text": "Figure 6.6(d) shows a cluster of traffic at Central and South San Francisco.", "rank": 1232, "start": 123872, "IsComparative": "0", "id": "st_1232"}, {"end": 123969, "text": "Figure 6.6(e) shows a", "rank": 1233, "start": 123948, "IsComparative": "0", "id": "st_1233"}]}, {"paragraph_info": {"end": 124571, "start": 123969, "text": "Figure 6.7: Clustering of synthetic trajectories with community detection: (a) shows the trajectories.(b) shows the PCA plot of the trajectories.(c) shows the matrix of approx- imate kernel distance between the trajectories.(d) shows k-means cannot discover the correct clustering.(e) shows the multilevel community detection discovers the correct clustering.popular loop that connects the San Francisco downtown to the San Francisco Airport.Figure 6.6(f) shows a cluster in West San Francisco.This example shows our approach can meaningfully separate the city and suburban traffic of different shapes.", "rank": 304, "paragraph_comparative_number": 2, "entities": [], "id": "p_304"}, "sentences": [{"end": 124071, "text": "Figure 6.7: Clustering of synthetic trajectories with community detection: (a) shows the trajectories.", "rank": 1234, "start": 123969, "IsComparative": "0", "id": "st_1234"}, {"end": 124114, "text": "(b) shows the PCA plot of the trajectories.", "rank": 1235, "start": 124071, "IsComparative": "0", "id": "st_1235"}, {"end": 124193, "text": "(c) shows the matrix of approx- imate kernel distance between the trajectories.", "rank": 1236, "start": 124114, "IsComparative": "1", "id": "st_1236"}, {"end": 124250, "text": "(d) shows k-means cannot discover the correct clustering.", "rank": 1237, "start": 124193, "IsComparative": "0", "id": "st_1237"}, {"end": 124328, "text": "(e) shows the multilevel community detection discovers the correct clustering.", "rank": 1238, "start": 124250, "IsComparative": "0", "id": "st_1238"}, {"end": 124411, "text": "popular loop that connects the San Francisco downtown to the San Francisco Airport.", "rank": 1239, "start": 124328, "IsComparative": "0", "id": "st_1239"}, {"end": 124463, "text": "Figure 6.6(f) shows a cluster in West San Francisco.", "rank": 1240, "start": 124411, "IsComparative": "0", "id": "st_1240"}, {"end": 124571, "text": "This example shows our approach can meaningfully separate the city and suburban traffic of different shapes.", "rank": 1241, "start": 124463, "IsComparative": "1", "id": "st_1241"}]}, {"paragraph_info": {"end": 124884, "start": 124571, "text": "We compute the clustering of taxi trajectories by using the incremental update strat- egy.For each increment we loaded 4 million new points and constructed trajectories for clustering.We use the cluster assignments before the increment to seed the clustering process.Our performance is summarized in Section 6.10.", "rank": 305, "paragraph_comparative_number": 0, "entities": [], "id": "p_305"}, "sentences": [{"end": 124661, "text": "We compute the clustering of taxi trajectories by using the incremental update strat- egy.", "rank": 1242, "start": 124571, "IsComparative": "0", "id": "st_1242"}, {"end": 124755, "text": "For each increment we loaded 4 million new points and constructed trajectories for clustering.", "rank": 1243, "start": 124661, "IsComparative": "0", "id": "st_1243"}, {"end": 124838, "text": "We use the cluster assignments before the increment to seed the clustering process.", "rank": 1244, "start": 124755, "IsComparative": "0", "id": "st_1244"}, {"end": 124884, "text": "Our performance is summarized in Section 6.10.", "rank": 1245, "start": 124838, "IsComparative": "0", "id": "st_1245"}]}, {"paragraph_info": {"end": 124939, "start": 124884, "text": "6.8 Clustering Feature Vectors with Community Detection", "rank": 306, "paragraph_comparative_number": 1, "entities": [], "id": "p_306"}, "sentences": [{"end": 124939, "text": "6.8 Clustering Feature Vectors with Community Detection", "rank": 1246, "start": 124884, "IsComparative": "1", "id": "st_1246"}]}, {"paragraph_info": {"end": 125286, "start": 124939, "text": "While we have shown k-means shape and spatial clustering works well with the approximate kernel distance framework.k-means clustering is not without limitations.It is well known that k-means only works well in discovering evenly distributed spherical clusters of similar sizes.Furthermore the number of k clusters is sometimes not know in advance.", "rank": 307, "paragraph_comparative_number": 2, "entities": [], "id": "p_307"}, "sentences": [{"end": 125054, "text": "While we have shown k-means shape and spatial clustering works well with the approximate kernel distance framework.", "rank": 1247, "start": 124939, "IsComparative": "1", "id": "st_1247"}, {"end": 125100, "text": "k-means clustering is not without limitations.", "rank": 1248, "start": 125054, "IsComparative": "0", "id": "st_1248"}, {"end": 125216, "text": "It is well known that k-means only works well in discovering evenly distributed spherical clusters of similar sizes.", "rank": 1249, "start": 125100, "IsComparative": "0", "id": "st_1249"}, {"end": 125286, "text": "Furthermore the number of k clusters is sometimes not know in advance.", "rank": 1250, "start": 125216, "IsComparative": "1", "id": "st_1250"}]}, {"paragraph_info": {"end": 125814, "start": 125286, "text": "Figure 6.7 shows a synthetic example that k-means does not handle well.Note that the clusters are not distributed as evenly as the example in Figure 6.3 and they are of more heterogeneous shapes.Figure 6.7 (a) shows the trajectories.Figure 6.7(b) shows the PCA plot with points colored according to the clusters.Figure 6.7(c) shows a visualization of the distance matrix, the off-diagonal blue region shows members of different clusters may be similar.Figure 6.7(d) shows how the k-means approach fails to identify the clusters.", "rank": 308, "paragraph_comparative_number": 0, "entities": [], "id": "p_308"}, "sentences": [{"end": 125357, "text": "Figure 6.7 shows a synthetic example that k-means does not handle well.", "rank": 1251, "start": 125286, "IsComparative": "0", "id": "st_1251"}, {"end": 125481, "text": "Note that the clusters are not distributed as evenly as the example in Figure 6.3 and they are of more heterogeneous shapes.", "rank": 1252, "start": 125357, "IsComparative": "0", "id": "st_1252"}, {"end": 125519, "text": "Figure 6.7 (a) shows the trajectories.", "rank": 1253, "start": 125481, "IsComparative": "0", "id": "st_1253"}, {"end": 125598, "text": "Figure 6.7(b) shows the PCA plot with points colored according to the clusters.", "rank": 1254, "start": 125519, "IsComparative": "0", "id": "st_1254"}, {"end": 125738, "text": "Figure 6.7(c) shows a visualization of the distance matrix, the off-diagonal blue region shows members of different clusters may be similar.", "rank": 1255, "start": 125598, "IsComparative": "0", "id": "st_1255"}, {"end": 125814, "text": "Figure 6.7(d) shows how the k-means approach fails to identify the clusters.", "rank": 1256, "start": 125738, "IsComparative": "0", "id": "st_1256"}]}, {"paragraph_info": {"end": 126455, "start": 125814, "text": "We apply community detection <36> with the approximate kernel distance frame- work to address these deficiencies.Many community detection algorithms extract con- nected structures from graphs without the need for specifying the number of components.They seek connected clusters within graphs that maximize a certain quality metric, such as the graph modularity.Graph modularity <113> measures the unexpected fraction of the edges that fall within the given clusters minus the expected fraction of (random) edges.Since the community detection algorithms only operate on the edge strengths, they also make no assumption of the clusters shapes.", "rank": 309, "paragraph_comparative_number": 4, "entities": [], "id": "p_309"}, "sentences": [{"end": 125927, "text": "We apply community detection <36> with the approximate kernel distance frame- work to address these deficiencies.", "rank": 1257, "start": 125814, "IsComparative": "1", "id": "st_1257"}, {"end": 126063, "text": "Many community detection algorithms extract con- nected structures from graphs without the need for specifying the number of components.", "rank": 1258, "start": 125927, "IsComparative": "1", "id": "st_1258"}, {"end": 126175, "text": "They seek connected clusters within graphs that maximize a certain quality metric, such as the graph modularity.", "rank": 1259, "start": 126063, "IsComparative": "0", "id": "st_1259"}, {"end": 126326, "text": "Graph modularity <113> measures the unexpected fraction of the edges that fall within the given clusters minus the expected fraction of (random) edges.", "rank": 1260, "start": 126175, "IsComparative": "1", "id": "st_1260"}, {"end": 126455, "text": "Since the community detection algorithms only operate on the edge strengths, they also make no assumption of the clusters shapes.", "rank": 1261, "start": 126326, "IsComparative": "1", "id": "st_1261"}]}, {"paragraph_info": {"end": 126677, "start": 126455, "text": "We compute a k-nearest-neighbors graph of the high-dimensional feature points to approximate the data geometry.The edge weights between the vertices representing trajectories P and Q are modeled by the kernel e  (P),  (Q).", "rank": 310, "paragraph_comparative_number": 1, "entities": [], "id": "p_310"}, "sentences": [{"end": 126566, "text": "We compute a k-nearest-neighbors graph of the high-dimensional feature points to approximate the data geometry.", "rank": 1262, "start": 126455, "IsComparative": "1", "id": "st_1262"}, {"end": 126677, "text": "The edge weights between the vertices representing trajectories P and Q are modeled by the kernel e  (P),  (Q).", "rank": 1263, "start": 126566, "IsComparative": "0", "id": "st_1263"}]}, {"paragraph_info": {"end": 126955, "start": 126677, "text": "Figure 6.7(e) shows clusters detected by the multilevel community detection algo- rithm <11>.This is a fast bottom up algorithm that attempts to maximize the modularity by moving graph vertices between the communities iteratively.It runs in almost linear time for sparse graphs.", "rank": 311, "paragraph_comparative_number": 2, "entities": [], "id": "p_311"}, "sentences": [{"end": 126770, "text": "Figure 6.7(e) shows clusters detected by the multilevel community detection algo- rithm <11>.", "rank": 1264, "start": 126677, "IsComparative": "0", "id": "st_1264"}, {"end": 126907, "text": "This is a fast bottom up algorithm that attempts to maximize the modularity by moving graph vertices between the communities iteratively.", "rank": 1265, "start": 126770, "IsComparative": "1", "id": "st_1265"}, {"end": 126955, "text": "It runs in almost linear time for sparse graphs.", "rank": 1266, "start": 126907, "IsComparative": "1", "id": "st_1266"}]}, {"paragraph_info": {"end": 126991, "start": 126955, "text": "6.9 Results with Community Detection", "rank": 312, "paragraph_comparative_number": 1, "entities": [], "id": "p_312"}, "sentences": [{"end": 126991, "text": "6.9 Results with Community Detection", "rank": 1267, "start": 126955, "IsComparative": "1", "id": "st_1267"}]}, {"paragraph_info": {"end": 127359, "start": 126991, "text": "We detect different groups of Atlantic Ocean hurricane trajectories by combining approximate kernel distance and multilevel community detection.We use an updated Atlantic Hurricane dataset which consists of more data than the previous study <95>.Note that this dataset consists of more overlapping curves from different clusters than the air traffic and taxi datasets.", "rank": 313, "paragraph_comparative_number": 1, "entities": [], "id": "p_313"}, "sentences": [{"end": 127135, "text": "We detect different groups of Atlantic Ocean hurricane trajectories by combining approximate kernel distance and multilevel community detection.", "rank": 1268, "start": 126991, "IsComparative": "1", "id": "st_1268"}, {"end": 127237, "text": "We use an updated Atlantic Hurricane dataset which consists of more data than the previous study <95>.", "rank": 1269, "start": 127135, "IsComparative": "0", "id": "st_1269"}, {"end": 127359, "text": "Note that this dataset consists of more overlapping curves from different clusters than the air traffic and taxi datasets.", "rank": 1270, "start": 127237, "IsComparative": "0", "id": "st_1270"}]}, {"paragraph_info": {"end": 127391, "start": 127359, "text": "6.9.1 Atlantic Hurricane Dataset", "rank": 314, "paragraph_comparative_number": 0, "entities": [], "id": "p_314"}, "sentences": [{"end": 127391, "text": "6.9.1 Atlantic Hurricane Dataset", "rank": 1271, "start": 127359, "IsComparative": "0", "id": "st_1271"}]}, {"paragraph_info": {"end": 127714, "start": 127391, "text": "This dataset consists of the tracks of the Atlantic Ocean hurricanes.There are a total of 1476 trajectories with 42, 203 points.Clustering hurricane trajectories is important for studying hurricane formation and for predicting the path of new hurricanes.This dataset is provided by the NOAA National Hurricane Center <114>.", "rank": 315, "paragraph_comparative_number": 3, "entities": [], "id": "p_315"}, "sentences": [{"end": 127460, "text": "This dataset consists of the tracks of the Atlantic Ocean hurricanes.", "rank": 1272, "start": 127391, "IsComparative": "1", "id": "st_1272"}, {"end": 127519, "text": "There are a total of 1476 trajectories with 42, 203 points.", "rank": 1273, "start": 127460, "IsComparative": "1", "id": "st_1273"}, {"end": 127645, "text": "Clustering hurricane trajectories is important for studying hurricane formation and for predicting the path of new hurricanes.", "rank": 1274, "start": 127519, "IsComparative": "1", "id": "st_1274"}, {"end": 127714, "text": "This dataset is provided by the NOAA National Hurricane Center <114>.", "rank": 1275, "start": 127645, "IsComparative": "0", "id": "st_1275"}]}, {"paragraph_info": {"end": 127962, "start": 127714, "text": "We replace the k-means clustering algorithm in our approach with the multilevel community detection <11> algorithm.For each clustering step, we construct a k-nearest- neighbor (k = 50) graph of the trajectories with the approximate kernel distance.", "rank": 316, "paragraph_comparative_number": 1, "entities": [], "id": "p_316"}, "sentences": [{"end": 127829, "text": "We replace the k-means clustering algorithm in our approach with the multilevel community detection <11> algorithm.", "rank": 1276, "start": 127714, "IsComparative": "1", "id": "st_1276"}, {"end": 127962, "text": "For each clustering step, we construct a k-nearest- neighbor (k = 50) graph of the trajectories with the approximate kernel distance.", "rank": 1277, "start": 127829, "IsComparative": "0", "id": "st_1277"}]}, {"paragraph_info": {"end": 128855, "start": 127962, "text": "The multilevel community detection algorithm automatically detects five clusters from the hurricane trajectories.Figure 6.8(a) shows all the 1476 hurricane tracks.Fig- ures 6.8(b)-(f) show the five automatically detected communities.Figure 6.8(b) shows hurricanes flowing from South to North and without much curvature.Figure 6.8 (c) and (d) show hurricanes that weaken after landfall in the North East of the US.Figure 6.8 (c) shows hurricanes that flow from the South Atlantic Ocean and Figure 6.8 (d) shows hurricanes that flow from the Mexican Gulf.Figure 6.8 (e) shows the strong C shape hurricanes that flow from the South Atlantic Ocean, hit the US North East, then exit back to the Atlantic Ocean.Figure 6.8 (f) shows southern hurricanes that weaken immedi- ately after the landfall.These results show that our approach can separate trajectories into intuitive and meaningful clusters.", "rank": 317, "paragraph_comparative_number": 4, "entities": [], "id": "p_317"}, "sentences": [{"end": 128075, "text": "The multilevel community detection algorithm automatically detects five clusters from the hurricane trajectories.", "rank": 1278, "start": 127962, "IsComparative": "1", "id": "st_1278"}, {"end": 128125, "text": "Figure 6.8(a) shows all the 1476 hurricane tracks.", "rank": 1279, "start": 128075, "IsComparative": "0", "id": "st_1279"}, {"end": 128195, "text": "Fig- ures 6.8(b)-(f) show the five automatically detected communities.", "rank": 1280, "start": 128125, "IsComparative": "0", "id": "st_1280"}, {"end": 128281, "text": "Figure 6.8(b) shows hurricanes flowing from South to North and without much curvature.", "rank": 1281, "start": 128195, "IsComparative": "0", "id": "st_1281"}, {"end": 128375, "text": "Figure 6.8 (c) and (d) show hurricanes that weaken after landfall in the North East of the US.", "rank": 1282, "start": 128281, "IsComparative": "1", "id": "st_1282"}, {"end": 128515, "text": "Figure 6.8 (c) shows hurricanes that flow from the South Atlantic Ocean and Figure 6.8 (d) shows hurricanes that flow from the Mexican Gulf.", "rank": 1283, "start": 128375, "IsComparative": "0", "id": "st_1283"}, {"end": 128667, "text": "Figure 6.8 (e) shows the strong C shape hurricanes that flow from the South Atlantic Ocean, hit the US North East, then exit back to the Atlantic Ocean.", "rank": 1284, "start": 128515, "IsComparative": "0", "id": "st_1284"}, {"end": 128753, "text": "Figure 6.8 (f) shows southern hurricanes that weaken immedi- ately after the landfall.", "rank": 1285, "start": 128667, "IsComparative": "1", "id": "st_1285"}, {"end": 128855, "text": "These results show that our approach can separate trajectories into intuitive and meaningful clusters.", "rank": 1286, "start": 128753, "IsComparative": "1", "id": "st_1286"}]}, {"paragraph_info": {"end": 128886, "start": 128855, "text": "6.10 Comparison and Performance", "rank": 318, "paragraph_comparative_number": 0, "entities": [], "id": "p_318"}, "sentences": [{"end": 128886, "text": "6.10 Comparison and Performance", "rank": 1287, "start": 128855, "IsComparative": "0", "id": "st_1287"}]}, {"paragraph_info": {"end": 128916, "start": 128886, "text": "6.10.1 Comparison with TRACLUS", "rank": 319, "paragraph_comparative_number": 0, "entities": [], "id": "p_319"}, "sentences": [{"end": 128916, "text": "6.10.1 Comparison with TRACLUS", "rank": 1288, "start": 128886, "IsComparative": "0", "id": "st_1288"}]}, {"paragraph_info": {"end": 129252, "start": 128916, "text": "We compare the performance and resulting clusters of our kernel distance clustering approach against the popular TRACLUS software provided by Lee et al.<95>.We used the provided programs to estimate the optimal parameters for TRACLUS clustering and performed experiments on the Hurricane dataset and the US Air Traffic dataset.We report", "rank": 320, "paragraph_comparative_number": 1, "entities": [], "id": "p_320"}, "sentences": [{"end": 129068, "text": "We compare the performance and resulting clusters of our kernel distance clustering approach against the popular TRACLUS software provided by Lee et al.", "rank": 1289, "start": 128916, "IsComparative": "0", "id": "st_1289"}, {"end": 129073, "text": "<95>.", "rank": 1290, "start": 129068, "IsComparative": "1", "id": "st_1290"}, {"end": 129243, "text": "We used the provided programs to estimate the optimal parameters for TRACLUS clustering and performed experiments on the Hurricane dataset and the US Air Traffic dataset.", "rank": 1291, "start": 129073, "IsComparative": "0", "id": "st_1291"}, {"end": 129252, "text": "We report", "rank": 1292, "start": 129243, "IsComparative": "0", "id": "st_1292"}]}, {"paragraph_info": {"end": 129762, "start": 129252, "text": "Figure 6.9: TRACLUS Results: We show the clustering of the hurricane and air traffic datasets generated by TRACLUS <95> as a comparison.Using the suggested parameter, TRACLUS only discovers one trajectory for the hurricanes and ten trajectories for the flights.the timings of both parameter estimation and clustering.The results are summarized in Table 6.1.TRACLUS took about one minute to estimate the parameters (MinLns = 15,  = 26) and cluster the hurricane trajectories.Our approach took only a few seconds", "rank": 321, "paragraph_comparative_number": 3, "entities": [], "id": "p_321"}, "sentences": [{"end": 129388, "text": "Figure 6.9: TRACLUS Results: We show the clustering of the hurricane and air traffic datasets generated by TRACLUS <95> as a comparison.", "rank": 1293, "start": 129252, "IsComparative": "0", "id": "st_1293"}, {"end": 129513, "text": "Using the suggested parameter, TRACLUS only discovers one trajectory for the hurricanes and ten trajectories for the flights.", "rank": 1294, "start": 129388, "IsComparative": "1", "id": "st_1294"}, {"end": 129569, "text": "the timings of both parameter estimation and clustering.", "rank": 1295, "start": 129513, "IsComparative": "0", "id": "st_1295"}, {"end": 129609, "text": "The results are summarized in Table 6.1.", "rank": 1296, "start": 129569, "IsComparative": "0", "id": "st_1296"}, {"end": 129726, "text": "TRACLUS took about one minute to estimate the parameters (MinLns = 15,  = 26) and cluster the hurricane trajectories.", "rank": 1297, "start": 129609, "IsComparative": "1", "id": "st_1297"}, {"end": 129762, "text": "Our approach took only a few seconds", "rank": 1298, "start": 129726, "IsComparative": "1", "id": "st_1298"}]}, {"paragraph_info": {"end": 129826, "start": 129762, "text": "6.10.2 Performance of Incrementally Clustering Taxi Trajectories", "rank": 322, "paragraph_comparative_number": 1, "entities": [], "id": "p_322"}, "sentences": [{"end": 129826, "text": "6.10.2 Performance of Incrementally Clustering Taxi Trajectories", "rank": 1299, "start": 129762, "IsComparative": "1", "id": "st_1299"}]}, {"paragraph_info": {"end": 129981, "start": 129826, "text": "Our approach took about 15 minutes to incrementally cluster 11 million points and 464K trajectories.A summary of our performance is presented in Table 6.2.", "rank": 323, "paragraph_comparative_number": 2, "entities": [], "id": "p_323"}, "sentences": [{"end": 129926, "text": "Our approach took about 15 minutes to incrementally cluster 11 million points and 464K trajectories.", "rank": 1300, "start": 129826, "IsComparative": "1", "id": "st_1300"}, {"end": 129981, "text": "A summary of our performance is presented in Table 6.2.", "rank": 1301, "start": 129926, "IsComparative": "1", "id": "st_1301"}]}, {"paragraph_info": {"end": 130013, "start": 129981, "text": "6.11 Conclusions and Discussions", "rank": 324, "paragraph_comparative_number": 1, "entities": [], "id": "p_324"}, "sentences": [{"end": 130013, "text": "6.11 Conclusions and Discussions", "rank": 1302, "start": 129981, "IsComparative": "1", "id": "st_1302"}]}, {"paragraph_info": {"end": 130953, "start": 130013, "text": "In this chapter, we have presented an efficient and effective approach for cluster- ing geospatial trajectories by using the approximate kernel distance.This framework transforms trajectories into fixed-length feature vectors and it allows us to compute the approximate kernel distance by a simple dot product formulation.We have shown that this formulation is extremely efficient for clustering applications.We have combined the kernel distance and the k-means clustering methods to analyze geospatial trajectories.We have presented a two-step clustering procedure to effectively group trajectories accord- ing to their shape and spatial features.We have shown how to incrementally update the feature vectors for stream processing of evolving trajectories.In addition to k-means clus- tering, our approach can also be combined with community detection methods to discover unevenly distributed clusters and without the need of specifying k.", "rank": 325, "paragraph_comparative_number": 3, "entities": [], "id": "p_325"}, "sentences": [{"end": 130166, "text": "In this chapter, we have presented an efficient and effective approach for cluster- ing geospatial trajectories by using the approximate kernel distance.", "rank": 1303, "start": 130013, "IsComparative": "0", "id": "st_1303"}, {"end": 130335, "text": "This framework transforms trajectories into fixed-length feature vectors and it allows us to compute the approximate kernel distance by a simple dot product formulation.", "rank": 1304, "start": 130166, "IsComparative": "1", "id": "st_1304"}, {"end": 130422, "text": "We have shown that this formulation is extremely efficient for clustering applications.", "rank": 1305, "start": 130335, "IsComparative": "0", "id": "st_1305"}, {"end": 130529, "text": "We have combined the kernel distance and the k-means clustering methods to analyze geospatial trajectories.", "rank": 1306, "start": 130422, "IsComparative": "0", "id": "st_1306"}, {"end": 130661, "text": "We have presented a two-step clustering procedure to effectively group trajectories accord- ing to their shape and spatial features.", "rank": 1307, "start": 130529, "IsComparative": "1", "id": "st_1307"}, {"end": 130770, "text": "We have shown how to incrementally update the feature vectors for stream processing of evolving trajectories.", "rank": 1308, "start": 130661, "IsComparative": "0", "id": "st_1308"}, {"end": 130953, "text": "In addition to k-means clus- tering, our approach can also be combined with community detection methods to discover unevenly distributed clusters and without the need of specifying k.", "rank": 1309, "start": 130770, "IsComparative": "1", "id": "st_1309"}]}, {"paragraph_info": {"end": 131314, "start": 130953, "text": "In our experiments, we show that we can cluster trajectories with millions of data points.We show results for clustering hurricane patterns, air traffic patterns, and taxi traffic patterns.Our performance is several orders of magnitude faster than the previous results <95> and shows more meaningful clusters that most of us will find interesting and appealing.", "rank": 326, "paragraph_comparative_number": 1, "entities": [], "id": "p_326"}, "sentences": [{"end": 131043, "text": "In our experiments, we show that we can cluster trajectories with millions of data points.", "rank": 1310, "start": 130953, "IsComparative": "0", "id": "st_1310"}, {"end": 131142, "text": "We show results for clustering hurricane patterns, air traffic patterns, and taxi traffic patterns.", "rank": 1311, "start": 131043, "IsComparative": "0", "id": "st_1311"}, {"end": 131314, "text": "Our performance is several orders of magnitude faster than the previous results <95> and shows more meaningful clusters that most of us will find interesting and appealing.", "rank": 1312, "start": 131142, "IsComparative": "1", "id": "st_1312"}]}, {"paragraph_info": {"end": 131351, "start": 131314, "text": "Chapter 7 Conclusions and Future Work", "rank": 327, "paragraph_comparative_number": 1, "entities": [], "id": "p_327"}, "sentences": [{"end": 131351, "text": "Chapter 7 Conclusions and Future Work", "rank": 1313, "start": 131314, "IsComparative": "1", "id": "st_1313"}]}, {"paragraph_info": {"end": 132362, "start": 131351, "text": "In this dissertation, we have shown data-driven methods for visualizing large scientific datasets.Our work has spanned the increase in dimensionality across 2D, 3D, and multi-dimensions for different applications.We have shown how to identify and vi- sualize salient regions from very large 2D landscape images.By visually segmenting the intensity-gradient histograms, we extract meaningful structures from 3D volumetric datasets.When we visualize thousands of spatially-mapped 3D gene expression profiles, we first identify the coherently expressed genes within different brain structures.Then, we extract expression surfaces for visualizing the coherent gene expressions.We show how to combine the approximate kernel distance framework with clustering and commu- nity detection algorithms to identify common patterns among the time-varying geospatial trajectories.We believe these are the first steps towards extracting visual knowledge from huge scientific datasets with many spatial and temporal dimensions.", "rank": 328, "paragraph_comparative_number": 2, "entities": [], "id": "p_328"}, "sentences": [{"end": 131449, "text": "In this dissertation, we have shown data-driven methods for visualizing large scientific datasets.", "rank": 1314, "start": 131351, "IsComparative": "0", "id": "st_1314"}, {"end": 131564, "text": "Our work has spanned the increase in dimensionality across 2D, 3D, and multi-dimensions for different applications.", "rank": 1315, "start": 131449, "IsComparative": "1", "id": "st_1315"}, {"end": 131662, "text": "We have shown how to identify and vi- sualize salient regions from very large 2D landscape images.", "rank": 1316, "start": 131564, "IsComparative": "0", "id": "st_1316"}, {"end": 131781, "text": "By visually segmenting the intensity-gradient histograms, we extract meaningful structures from 3D volumetric datasets.", "rank": 1317, "start": 131662, "IsComparative": "0", "id": "st_1317"}, {"end": 131941, "text": "When we visualize thousands of spatially-mapped 3D gene expression profiles, we first identify the coherently expressed genes within different brain structures.", "rank": 1318, "start": 131781, "IsComparative": "1", "id": "st_1318"}, {"end": 132024, "text": "Then, we extract expression surfaces for visualizing the coherent gene expressions.", "rank": 1319, "start": 131941, "IsComparative": "0", "id": "st_1319"}, {"end": 132217, "text": "We show how to combine the approximate kernel distance framework with clustering and commu- nity detection algorithms to identify common patterns among the time-varying geospatial trajectories.", "rank": 1320, "start": 132024, "IsComparative": "0", "id": "st_1320"}, {"end": 132362, "text": "We believe these are the first steps towards extracting visual knowledge from huge scientific datasets with many spatial and temporal dimensions.", "rank": 1321, "start": 132217, "IsComparative": "0", "id": "st_1321"}]}, {"paragraph_info": {"end": 132377, "start": 132362, "text": "7.1 Future work", "rank": 329, "paragraph_comparative_number": 0, "entities": [], "id": "p_329"}, "sentences": [{"end": 132377, "text": "7.1 Future work", "rank": 1322, "start": 132362, "IsComparative": "0", "id": "st_1322"}]}, {"paragraph_info": {"end": 133451, "start": 132377, "text": "Very Large Images In this dissertation we have focused on large-scale landscape im- ages that have been acquired by stitching together of a large number of photographs.However, very large scale images are finding use in a number of different areas.For example, semiconductor wafer manufacturers are using terapixel images for quality in- spection of their chips for detecting circuit anomalies.As another example, latest gen- eration microscopes stitch together volumes of very high resolution, multi-slice imagery that depicts the entire life-cycle of a number of parasites.As yet another example, as- tronomers are exploring the farthest reaches of the universe through the use of terapixel imagery.Our system is currently targeted for analyzing landscape images using color and appearance.The key to analyzing other domain-specific images is to design appropriate descriptors that characterize similarity across regions of interests.The descriptors should allow fast discovery of locally distinct regions as well as accurate identification of the globally unique regions.", "rank": 330, "paragraph_comparative_number": 5, "entities": [], "id": "p_330"}, "sentences": [{"end": 132545, "text": "Very Large Images In this dissertation we have focused on large-scale landscape im- ages that have been acquired by stitching together of a large number of photographs.", "rank": 1323, "start": 132377, "IsComparative": "0", "id": "st_1323"}, {"end": 132625, "text": "However, very large scale images are finding use in a number of different areas.", "rank": 1324, "start": 132545, "IsComparative": "1", "id": "st_1324"}, {"end": 132771, "text": "For example, semiconductor wafer manufacturers are using terapixel images for quality in- spection of their chips for detecting circuit anomalies.", "rank": 1325, "start": 132625, "IsComparative": "1", "id": "st_1325"}, {"end": 132952, "text": "As another example, latest gen- eration microscopes stitch together volumes of very high resolution, multi-slice imagery that depicts the entire life-cycle of a number of parasites.", "rank": 1326, "start": 132771, "IsComparative": "1", "id": "st_1326"}, {"end": 133078, "text": "As yet another example, as- tronomers are exploring the farthest reaches of the universe through the use of terapixel imagery.", "rank": 1327, "start": 132952, "IsComparative": "1", "id": "st_1327"}, {"end": 133169, "text": "Our system is currently targeted for analyzing landscape images using color and appearance.", "rank": 1328, "start": 133078, "IsComparative": "1", "id": "st_1328"}, {"end": 133313, "text": "The key to analyzing other domain-specific images is to design appropriate descriptors that characterize similarity across regions of interests.", "rank": 1329, "start": 133169, "IsComparative": "0", "id": "st_1329"}, {"end": 133451, "text": "The descriptors should allow fast discovery of locally distinct regions as well as accurate identification of the globally unique regions.", "rank": 1330, "start": 133313, "IsComparative": "0", "id": "st_1330"}]}, {"paragraph_info": {"end": 134185, "start": 133451, "text": "Volumetric Datasets We believe our hierarchical volume exploration approach natu- rally extends to larger datasets.The key is to perform the normalized-cut segmentation on-demand.This is critical for visualizing a large dataset because it can limit the sub- divisions and segmentation to only the necessary ones.The hierarchical nature ensures that the complexity of subdividing volumes does not grow.Another possible avenue of advancement is to study other, more sophisticated measures of information content for the volumetric subdivisions.The general entropy characterizes the worst-case uncer- tainty.We believe this may be improved by considering the spatial structure in the volume datasets.We plan to pursue this in the future.", "rank": 331, "paragraph_comparative_number": 3, "entities": [], "id": "p_331"}, "sentences": [{"end": 133566, "text": "Volumetric Datasets We believe our hierarchical volume exploration approach natu- rally extends to larger datasets.", "rank": 1331, "start": 133451, "IsComparative": "1", "id": "st_1331"}, {"end": 133630, "text": "The key is to perform the normalized-cut segmentation on-demand.", "rank": 1332, "start": 133566, "IsComparative": "0", "id": "st_1332"}, {"end": 133763, "text": "This is critical for visualizing a large dataset because it can limit the sub- divisions and segmentation to only the necessary ones.", "rank": 1333, "start": 133630, "IsComparative": "1", "id": "st_1333"}, {"end": 133852, "text": "The hierarchical nature ensures that the complexity of subdividing volumes does not grow.", "rank": 1334, "start": 133763, "IsComparative": "0", "id": "st_1334"}, {"end": 133993, "text": "Another possible avenue of advancement is to study other, more sophisticated measures of information content for the volumetric subdivisions.", "rank": 1335, "start": 133852, "IsComparative": "0", "id": "st_1335"}, {"end": 134056, "text": "The general entropy characterizes the worst-case uncer- tainty.", "rank": 1336, "start": 133993, "IsComparative": "0", "id": "st_1336"}, {"end": 134148, "text": "We believe this may be improved by considering the spatial structure in the volume datasets.", "rank": 1337, "start": 134056, "IsComparative": "1", "id": "st_1337"}, {"end": 134185, "text": "We plan to pursue this in the future.", "rank": 1338, "start": 134148, "IsComparative": "0", "id": "st_1338"}]}, {"paragraph_info": {"end": 135007, "start": 134185, "text": "High-dimensional Brain Images In addition to extracting and visualizing gene expres- sion boundaries for a single structure at a single time point, we are interested in developing visualizations for tracking the structures physical and genetic changes in the development process.We started our pipeline with a specific brain structure; it would be interesting to construct a completely data-driven atlas by learning patterns from thousands of gene expression profiles.Another direction would be to analyze and visualize genetic infor- mation with images of different modalities, such as, MR, fMR, and EEG scan.With the development of exciting brain imaging and mapping technologies, we are interested in developing analytic and visualization tools to help improve our understanding of the most complex organ in our bodies.", "rank": 332, "paragraph_comparative_number": 3, "entities": [], "id": "p_332"}, "sentences": [{"end": 134464, "text": "High-dimensional Brain Images In addition to extracting and visualizing gene expres- sion boundaries for a single structure at a single time point, we are interested in developing visualizations for tracking the structures physical and genetic changes in the development process.", "rank": 1339, "start": 134185, "IsComparative": "1", "id": "st_1339"}, {"end": 134653, "text": "We started our pipeline with a specific brain structure; it would be interesting to construct a completely data-driven atlas by learning patterns from thousands of gene expression profiles.", "rank": 1340, "start": 134464, "IsComparative": "1", "id": "st_1340"}, {"end": 134795, "text": "Another direction would be to analyze and visualize genetic infor- mation with images of different modalities, such as, MR, fMR, and EEG scan.", "rank": 1341, "start": 134653, "IsComparative": "0", "id": "st_1341"}, {"end": 135007, "text": "With the development of exciting brain imaging and mapping technologies, we are interested in developing analytic and visualization tools to help improve our understanding of the most complex organ in our bodies.", "rank": 1342, "start": 134795, "IsComparative": "1", "id": "st_1342"}]}, {"paragraph_info": {"end": 135724, "start": 135007, "text": "Time-varying Geospatial Trajectories We are interested in developing kernel-distance- based techniques for data mining applications.We chose popular Gaussian kernel with the Euclidean distance as an example, but many other positive definite kernels can also be applied within this kernel distance framework.One possibility is to extend the Gaus- sian kernel with Generalized Radial Basis functions by using another distance function (like 2 distance).This is known to have better discriminating power in certain problem domains.We are currently working on achieving efficient feature maps for these kernels.It will be interesting to explore this space for mining rich data types such as time-series data and networks.", "rank": 333, "paragraph_comparative_number": 5, "entities": [], "id": "p_333"}, "sentences": [{"end": 135139, "text": "Time-varying Geospatial Trajectories We are interested in developing kernel-distance- based techniques for data mining applications.", "rank": 1343, "start": 135007, "IsComparative": "0", "id": "st_1343"}, {"end": 135314, "text": "We chose popular Gaussian kernel with the Euclidean distance as an example, but many other positive definite kernels can also be applied within this kernel distance framework.", "rank": 1344, "start": 135139, "IsComparative": "1", "id": "st_1344"}, {"end": 135458, "text": "One possibility is to extend the Gaus- sian kernel with Generalized Radial Basis functions by using another distance function (like 2 distance).", "rank": 1345, "start": 135314, "IsComparative": "1", "id": "st_1345"}, {"end": 135535, "text": "This is known to have better discriminating power in certain problem domains.", "rank": 1346, "start": 135458, "IsComparative": "1", "id": "st_1346"}, {"end": 135614, "text": "We are currently working on achieving efficient feature maps for these kernels.", "rank": 1347, "start": 135535, "IsComparative": "1", "id": "st_1347"}, {"end": 135724, "text": "It will be interesting to explore this space for mining rich data types such as time-series data and networks.", "rank": 1348, "start": 135614, "IsComparative": "1", "id": "st_1348"}]}, {"paragraph_info": {"end": 136225, "start": 135724, "text": "The main limitation of our approach lies in the high dimensionality of our feature vectors.While we have shown the effectiveness and the stream processing capabilities of the kernel distance framework, the k-means clustering algorithm may not be effective for high dimensional data.We have shown how to address some of the k-means deficien- cies by using community detection algorithms, yet performing community detection in a streaming fashion is not straight forward.This is part of our future work.", "rank": 334, "paragraph_comparative_number": 2, "entities": [], "id": "p_334"}, "sentences": [{"end": 135815, "text": "The main limitation of our approach lies in the high dimensionality of our feature vectors.", "rank": 1349, "start": 135724, "IsComparative": "1", "id": "st_1349"}, {"end": 136006, "text": "While we have shown the effectiveness and the stream processing capabilities of the kernel distance framework, the k-means clustering algorithm may not be effective for high dimensional data.", "rank": 1350, "start": 135815, "IsComparative": "0", "id": "st_1350"}, {"end": 136193, "text": "We have shown how to address some of the k-means deficien- cies by using community detection algorithms, yet performing community detection in a streaming fashion is not straight forward.", "rank": 1351, "start": 136006, "IsComparative": "0", "id": "st_1351"}, {"end": 136225, "text": "This is part of our future work.", "rank": 1352, "start": 136193, "IsComparative": "1", "id": "st_1352"}]}, {"paragraph_info": {"end": 136253, "start": 136225, "text": "7.2 Additional Contributions", "rank": 335, "paragraph_comparative_number": 0, "entities": [], "id": "p_335"}, "sentences": [{"end": 136253, "text": "7.2 Additional Contributions", "rank": 1353, "start": 136225, "IsComparative": "0", "id": "st_1353"}]}, {"paragraph_info": {"end": 137062, "start": 136253, "text": "In addition to the work described in this dissertation <54, 55, 56, 57>, we have also contributed to other related areas during the course of this research.In the area of computational biology visualization, we have applied computational saliency to extract important timesteps from molecular simulations <82, 123>.We have summarized time- varying molecular dynamics simulations <121> with a data-driven 2D layout.We have also characterized stem cells by using their shape morphology and classified them by using support vector machines for bio-imaging applications <77>.In the area of computer graphics, we have developed a time-varying 3D social photography system <122> using smartphones.We have used the graphics-specific functions on a GPU to accelerate the generation of Poisson disk distributions <58>.", "rank": 336, "paragraph_comparative_number": 3, "entities": [], "id": "p_336"}, "sentences": [{"end": 136409, "text": "In addition to the work described in this dissertation <54, 55, 56, 57>, we have also contributed to other related areas during the course of this research.", "rank": 1354, "start": 136253, "IsComparative": "0", "id": "st_1354"}, {"end": 136568, "text": "In the area of computational biology visualization, we have applied computational saliency to extract important timesteps from molecular simulations <82, 123>.", "rank": 1355, "start": 136409, "IsComparative": "1", "id": "st_1355"}, {"end": 136667, "text": "We have summarized time- varying molecular dynamics simulations <121> with a data-driven 2D layout.", "rank": 1356, "start": 136568, "IsComparative": "0", "id": "st_1356"}, {"end": 136824, "text": "We have also characterized stem cells by using their shape morphology and classified them by using support vector machines for bio-imaging applications <77>.", "rank": 1357, "start": 136667, "IsComparative": "1", "id": "st_1357"}, {"end": 136944, "text": "In the area of computer graphics, we have developed a time-varying 3D social photography system <122> using smartphones.", "rank": 1358, "start": 136824, "IsComparative": "0", "id": "st_1358"}, {"end": 137062, "text": "We have used the graphics-specific functions on a GPU to accelerate the generation of Poisson disk distributions <58>.", "rank": 1359, "start": 136944, "IsComparative": "1", "id": "st_1359"}]}]}